[
    [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 11.200000000000001,
            "text": " Hi everyone, welcome back.",
            "tokens": [
                50364,
                2421,
                1518,
                11,
                2928,
                646,
                13,
                50924
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2145630121231079,
            "compression_ratio": 1.5735294117647058,
            "no_speech_prob": 0.10722173750400543
        },
        {
            "id": 1,
            "seek": 0,
            "start": 11.200000000000001,
            "end": 16.080000000000002,
            "text": " Today I think that these two lectures today are really exciting because they start to",
            "tokens": [
                50924,
                2692,
                286,
                519,
                300,
                613,
                732,
                16564,
                965,
                366,
                534,
                4670,
                570,
                436,
                722,
                281,
                51168
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2145630121231079,
            "compression_ratio": 1.5735294117647058,
            "no_speech_prob": 0.10722173750400543
        },
        {
            "id": 2,
            "seek": 0,
            "start": 16.080000000000002,
            "end": 21.04,
            "text": " move beyond a lot of what we've talked about in the class so far, which is focusing a",
            "tokens": [
                51168,
                1286,
                4399,
                257,
                688,
                295,
                437,
                321,
                600,
                2825,
                466,
                294,
                264,
                1508,
                370,
                1400,
                11,
                597,
                307,
                8416,
                257,
                51416
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2145630121231079,
            "compression_ratio": 1.5735294117647058,
            "no_speech_prob": 0.10722173750400543
        },
        {
            "id": 3,
            "seek": 0,
            "start": 21.04,
            "end": 23.32,
            "text": " lot on really static data sets.",
            "tokens": [
                51416,
                688,
                322,
                534,
                13437,
                1412,
                6352,
                13,
                51530
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2145630121231079,
            "compression_ratio": 1.5735294117647058,
            "no_speech_prob": 0.10722173750400543
        },
        {
            "id": 4,
            "seek": 0,
            "start": 23.32,
            "end": 27.68,
            "text": " And specifically in today, in this lecture right now, I'm going to start to talk about how",
            "tokens": [
                51530,
                400,
                4682,
                294,
                965,
                11,
                294,
                341,
                7991,
                558,
                586,
                11,
                286,
                478,
                516,
                281,
                722,
                281,
                751,
                466,
                577,
                51748
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2145630121231079,
            "compression_ratio": 1.5735294117647058,
            "no_speech_prob": 0.10722173750400543
        },
        {
            "id": 5,
            "seek": 2768,
            "start": 27.68,
            "end": 32.8,
            "text": " we can learn about this very long-standing field of how we can specifically marry two",
            "tokens": [
                50364,
                321,
                393,
                1466,
                466,
                341,
                588,
                938,
                12,
                8618,
                2519,
                295,
                577,
                321,
                393,
                4682,
                9747,
                732,
                50620
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19143632910717492,
            "compression_ratio": 1.7004219409282701,
            "no_speech_prob": 0.008945376612246037
        },
        {
            "id": 6,
            "seek": 2768,
            "start": 32.8,
            "end": 38.16,
            "text": " topics, the first topic being reinforcement learning, which has existed for many, many",
            "tokens": [
                50620,
                8378,
                11,
                264,
                700,
                4829,
                885,
                29280,
                2539,
                11,
                597,
                575,
                13135,
                337,
                867,
                11,
                867,
                50888
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19143632910717492,
            "compression_ratio": 1.7004219409282701,
            "no_speech_prob": 0.008945376612246037
        },
        {
            "id": 7,
            "seek": 2768,
            "start": 38.16,
            "end": 43.12,
            "text": " decades together with a lot of the very recent advances in deep learning, which you've",
            "tokens": [
                50888,
                7878,
                1214,
                365,
                257,
                688,
                295,
                264,
                588,
                5162,
                25297,
                294,
                2452,
                2539,
                11,
                597,
                291,
                600,
                51136
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19143632910717492,
            "compression_ratio": 1.7004219409282701,
            "no_speech_prob": 0.008945376612246037
        },
        {
            "id": 8,
            "seek": 2768,
            "start": 43.12,
            "end": 47.120000000000005,
            "text": " already started learning about as part of this course.",
            "tokens": [
                51136,
                1217,
                1409,
                2539,
                466,
                382,
                644,
                295,
                341,
                1164,
                13,
                51336
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19143632910717492,
            "compression_ratio": 1.7004219409282701,
            "no_speech_prob": 0.008945376612246037
        },
        {
            "id": 9,
            "seek": 2768,
            "start": 47.120000000000005,
            "end": 52.36,
            "text": " Now this marriage of these two fields is actually really fascinating to me, particularly",
            "tokens": [
                51336,
                823,
                341,
                7194,
                295,
                613,
                732,
                7909,
                307,
                767,
                534,
                10343,
                281,
                385,
                11,
                4098,
                51598
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19143632910717492,
            "compression_ratio": 1.7004219409282701,
            "no_speech_prob": 0.008945376612246037
        },
        {
            "id": 10,
            "seek": 5236,
            "start": 52.36,
            "end": 57.96,
            "text": " because like I said, it moves away from this whole paradigm of, or really this whole",
            "tokens": [
                50364,
                570,
                411,
                286,
                848,
                11,
                309,
                6067,
                1314,
                490,
                341,
                1379,
                24709,
                295,
                11,
                420,
                534,
                341,
                1379,
                50644
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 11,
            "seek": 5236,
            "start": 57.96,
            "end": 61.2,
            "text": " paradigm that we've been exposed to in the class thus far.",
            "tokens": [
                50644,
                24709,
                300,
                321,
                600,
                668,
                9495,
                281,
                294,
                264,
                1508,
                8807,
                1400,
                13,
                50806
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 12,
            "seek": 5236,
            "start": 61.2,
            "end": 67.28,
            "text": " And that paradigm is really how we can build a deep learning model using some data set,",
            "tokens": [
                50806,
                400,
                300,
                24709,
                307,
                534,
                577,
                321,
                393,
                1322,
                257,
                2452,
                2539,
                2316,
                1228,
                512,
                1412,
                992,
                11,
                51110
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 13,
            "seek": 5236,
            "start": 67.28,
            "end": 71.24,
            "text": " but that data set is typically fixed in our world, right?",
            "tokens": [
                51110,
                457,
                300,
                1412,
                992,
                307,
                5850,
                6806,
                294,
                527,
                1002,
                11,
                558,
                30,
                51308
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 14,
            "seek": 5236,
            "start": 71.24,
            "end": 75.2,
            "text": " We collect, we go out and collect that data set, we deploy it on our machine learning",
            "tokens": [
                51308,
                492,
                2500,
                11,
                321,
                352,
                484,
                293,
                2500,
                300,
                1412,
                992,
                11,
                321,
                7274,
                309,
                322,
                527,
                3479,
                2539,
                51506
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 15,
            "seek": 5236,
            "start": 75.2,
            "end": 79.56,
            "text": " or deep learning algorithm, and then we can evaluate on a brand new data set.",
            "tokens": [
                51506,
                420,
                2452,
                2539,
                9284,
                11,
                293,
                550,
                321,
                393,
                13059,
                322,
                257,
                3360,
                777,
                1412,
                992,
                13,
                51724
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15766561031341553,
            "compression_ratio": 1.790513833992095,
            "no_speech_prob": 0.010627441108226776
        },
        {
            "id": 16,
            "seek": 7956,
            "start": 79.56,
            "end": 83.12,
            "text": " And that is very different than the way things work in the real world.",
            "tokens": [
                50364,
                400,
                300,
                307,
                588,
                819,
                813,
                264,
                636,
                721,
                589,
                294,
                264,
                957,
                1002,
                13,
                50542
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 17,
            "seek": 7956,
            "start": 83.12,
            "end": 87.56,
            "text": " In the real world, you have your deep learning model actually deployed together with the",
            "tokens": [
                50542,
                682,
                264,
                957,
                1002,
                11,
                291,
                362,
                428,
                2452,
                2539,
                2316,
                767,
                17826,
                1214,
                365,
                264,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 18,
            "seek": 7956,
            "start": 87.56,
            "end": 93.4,
            "text": " data, together out into reality, exploring, interacting with its environment, and trying",
            "tokens": [
                50764,
                1412,
                11,
                1214,
                484,
                666,
                4103,
                11,
                12736,
                11,
                18017,
                365,
                1080,
                2823,
                11,
                293,
                1382,
                51056
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 19,
            "seek": 7956,
            "start": 93.4,
            "end": 97.52000000000001,
            "text": " out a whole bunch of different actions and different things in that environment in order",
            "tokens": [
                51056,
                484,
                257,
                1379,
                3840,
                295,
                819,
                5909,
                293,
                819,
                721,
                294,
                300,
                2823,
                294,
                1668,
                51262
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 20,
            "seek": 7956,
            "start": 97.52000000000001,
            "end": 103.64,
            "text": " to be able to learn how to best perform any particular task that it may need to accomplish.",
            "tokens": [
                51262,
                281,
                312,
                1075,
                281,
                1466,
                577,
                281,
                1151,
                2042,
                604,
                1729,
                5633,
                300,
                309,
                815,
                643,
                281,
                9021,
                13,
                51568
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 21,
            "seek": 7956,
            "start": 103.64,
            "end": 108.36,
            "text": " And typically, we want to be able to do this without explicit human supervision, right?",
            "tokens": [
                51568,
                400,
                5850,
                11,
                321,
                528,
                281,
                312,
                1075,
                281,
                360,
                341,
                1553,
                13691,
                1952,
                32675,
                11,
                558,
                30,
                51804
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13218703312156474,
            "compression_ratio": 1.8013937282229966,
            "no_speech_prob": 0.0022457728628069162
        },
        {
            "id": 22,
            "seek": 10836,
            "start": 108.36,
            "end": 111.4,
            "text": " This is the key motivation of reinforcement learning.",
            "tokens": [
                50364,
                639,
                307,
                264,
                2141,
                12335,
                295,
                29280,
                2539,
                13,
                50516
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 23,
            "seek": 10836,
            "start": 111.4,
            "end": 115.72,
            "text": " You're going to try and learn through reinforcement, making mistakes in your world, and then",
            "tokens": [
                50516,
                509,
                434,
                516,
                281,
                853,
                293,
                1466,
                807,
                29280,
                11,
                1455,
                8038,
                294,
                428,
                1002,
                11,
                293,
                550,
                50732
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 24,
            "seek": 10836,
            "start": 115.72,
            "end": 119.8,
            "text": " collecting data on those mistakes to learn how to improve.",
            "tokens": [
                50732,
                12510,
                1412,
                322,
                729,
                8038,
                281,
                1466,
                577,
                281,
                3470,
                13,
                50936
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 25,
            "seek": 10836,
            "start": 119.8,
            "end": 126.8,
            "text": " Now this is obviously a huge field or a huge topic in the field of robotics and autonomy.",
            "tokens": [
                50936,
                823,
                341,
                307,
                2745,
                257,
                2603,
                2519,
                420,
                257,
                2603,
                4829,
                294,
                264,
                2519,
                295,
                34145,
                293,
                27278,
                13,
                51286
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 26,
            "seek": 10836,
            "start": 126.8,
            "end": 131.68,
            "text": " You can think of self-driving cars and robot manipulation, but also very recently we've",
            "tokens": [
                51286,
                509,
                393,
                519,
                295,
                2698,
                12,
                47094,
                5163,
                293,
                7881,
                26475,
                11,
                457,
                611,
                588,
                3938,
                321,
                600,
                51530
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 27,
            "seek": 10836,
            "start": 131.68,
            "end": 136.72,
            "text": " started seeing incredible advances of deeper reinforcement learning specifically also on",
            "tokens": [
                51530,
                1409,
                2577,
                4651,
                25297,
                295,
                7731,
                29280,
                2539,
                4682,
                611,
                322,
                51782
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16037574768066407,
            "compression_ratio": 1.7416974169741697,
            "no_speech_prob": 0.011841998435556889
        },
        {
            "id": 28,
            "seek": 13672,
            "start": 136.72,
            "end": 140.64,
            "text": " the side of gameplay and strategy-making as well.",
            "tokens": [
                50364,
                264,
                1252,
                295,
                11421,
                293,
                5206,
                12,
                12402,
                382,
                731,
                13,
                50560
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        },
        {
            "id": 29,
            "seek": 13672,
            "start": 140.64,
            "end": 149.12,
            "text": " So one really cool thing is that now you can even imagine this combination of robotics",
            "tokens": [
                50560,
                407,
                472,
                534,
                1627,
                551,
                307,
                300,
                586,
                291,
                393,
                754,
                3811,
                341,
                6562,
                295,
                34145,
                50984
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        }
    ],
    [
        {
            "id": 30,
            "seek": 13672,
            "start": 149.12,
            "end": 151.04,
            "text": " together with gameplay, right?",
            "tokens": [
                50984,
                1214,
                365,
                11421,
                11,
                558,
                30,
                51080
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        },
        {
            "id": 31,
            "seek": 13672,
            "start": 151.04,
            "end": 154.92,
            "text": " Now training robots to play against us in the real world, and I'll just play this very",
            "tokens": [
                51080,
                823,
                3097,
                14733,
                281,
                862,
                1970,
                505,
                294,
                264,
                957,
                1002,
                11,
                293,
                286,
                603,
                445,
                862,
                341,
                588,
                51274
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        },
        {
            "id": 32,
            "seek": 13672,
            "start": 154.92,
            "end": 159.28,
            "text": " short video on Starcraft and DeepBind.",
            "tokens": [
                51274,
                2099,
                960,
                322,
                5705,
                5611,
                293,
                14895,
                33,
                471,
                13,
                51492
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        },
        {
            "id": 33,
            "seek": 13672,
            "start": 159.28,
            "end": 165.36,
            "text": " Perfect information and to explain in real time.",
            "tokens": [
                51492,
                10246,
                1589,
                293,
                281,
                2903,
                294,
                957,
                565,
                13,
                51796
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2512722464168773,
            "compression_ratio": 1.5132743362831858,
            "no_speech_prob": 0.03335148096084595
        },
        {
            "id": 34,
            "seek": 16536,
            "start": 165.36,
            "end": 169.60000000000002,
            "text": " It also requires long-term planning and the ability to choose what action to take from",
            "tokens": [
                50364,
                467,
                611,
                7029,
                938,
                12,
                7039,
                5038,
                293,
                264,
                3485,
                281,
                2826,
                437,
                3069,
                281,
                747,
                490,
                50576
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 35,
            "seek": 16536,
            "start": 169.60000000000002,
            "end": 172.56,
            "text": " millions and millions of possibilities.",
            "tokens": [
                50576,
                6803,
                293,
                6803,
                295,
                12178,
                13,
                50724
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 36,
            "seek": 16536,
            "start": 172.56,
            "end": 176.4,
            "text": " I'm hoping for a 5-0 not to lose any games, but I think the realistic goal would be",
            "tokens": [
                50724,
                286,
                478,
                7159,
                337,
                257,
                1025,
                12,
                15,
                406,
                281,
                3624,
                604,
                2813,
                11,
                457,
                286,
                519,
                264,
                12465,
                3387,
                576,
                312,
                50916
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 37,
            "seek": 16536,
            "start": 176.4,
            "end": 180.04000000000002,
            "text": " 4-1 in my favour.",
            "tokens": [
                50916,
                1017,
                12,
                16,
                294,
                452,
                8182,
                13,
                51098
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 38,
            "seek": 16536,
            "start": 180.04000000000002,
            "end": 188.16000000000003,
            "text": " I think he looks more confident and TLO is quite nervous before.",
            "tokens": [
                51098,
                286,
                519,
                415,
                1542,
                544,
                6679,
                293,
                314,
                20184,
                307,
                1596,
                6296,
                949,
                13,
                51504
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 39,
            "seek": 16536,
            "start": 188.16000000000003,
            "end": 191.64000000000001,
            "text": " The room was much more tense this time.",
            "tokens": [
                51504,
                440,
                1808,
                390,
                709,
                544,
                18760,
                341,
                565,
                13,
                51678
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3159323274419549,
            "compression_ratio": 1.506787330316742,
            "no_speech_prob": 0.3578035235404968
        },
        {
            "id": 40,
            "seek": 19164,
            "start": 191.64,
            "end": 193.64,
            "text": " He didn't know what to expect.",
            "tokens": [
                50364,
                634,
                994,
                380,
                458,
                437,
                281,
                2066,
                13,
                50464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 41,
            "seek": 19164,
            "start": 193.64,
            "end": 201.27999999999997,
            "text": " He's been playing Starcraft pretty much since he's 5.",
            "tokens": [
                50464,
                634,
                311,
                668,
                2433,
                5705,
                5611,
                1238,
                709,
                1670,
                415,
                311,
                1025,
                13,
                50846
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 42,
            "seek": 19164,
            "start": 201.27999999999997,
            "end": 206.23999999999998,
            "text": " I wasn't expecting that good.",
            "tokens": [
                50846,
                286,
                2067,
                380,
                9650,
                300,
                665,
                13,
                51094
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 43,
            "seek": 19164,
            "start": 206.23999999999998,
            "end": 207.48,
            "text": " Everything that he did was proper.",
            "tokens": [
                51094,
                5471,
                300,
                415,
                630,
                390,
                2296,
                13,
                51156
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 44,
            "seek": 19164,
            "start": 207.48,
            "end": 210.44,
            "text": " It was calculated and it was done well.",
            "tokens": [
                51156,
                467,
                390,
                15598,
                293,
                309,
                390,
                1096,
                731,
                13,
                51304
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 45,
            "seek": 19164,
            "start": 210.44,
            "end": 214.95999999999998,
            "text": " I thought I'm learning something.",
            "tokens": [
                51304,
                286,
                1194,
                286,
                478,
                2539,
                746,
                13,
                51530
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 46,
            "seek": 19164,
            "start": 214.95999999999998,
            "end": 216.92,
            "text": " It's much better than expected.",
            "tokens": [
                51530,
                467,
                311,
                709,
                1101,
                813,
                5176,
                13,
                51628
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 47,
            "seek": 19164,
            "start": 216.92,
            "end": 219.44,
            "text": " That would consider myself a good player, right?",
            "tokens": [
                51628,
                663,
                576,
                1949,
                2059,
                257,
                665,
                4256,
                11,
                558,
                30,
                51754
            ],
            "temperature": 0.0,
            "avg_logprob": -0.38926270950672237,
            "compression_ratio": 1.52,
            "no_speech_prob": 0.49253836274147034
        },
        {
            "id": 48,
            "seek": 21944,
            "start": 219.44,
            "end": 226.44,
            "text": " I lost every single one of 5 games.",
            "tokens": [
                50364,
                286,
                2731,
                633,
                2167,
                472,
                295,
                1025,
                2813,
                13,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 49,
            "seek": 21944,
            "start": 226.44,
            "end": 228.88,
            "text": " Way ahead of all.",
            "tokens": [
                50714,
                9558,
                2286,
                295,
                439,
                13,
                50836
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 50,
            "seek": 21944,
            "start": 228.88,
            "end": 235.6,
            "text": " Let's take a step back first of all and think about how reinforcement learning fits into",
            "tokens": [
                50836,
                961,
                311,
                747,
                257,
                1823,
                646,
                700,
                295,
                439,
                293,
                519,
                466,
                577,
                29280,
                2539,
                9001,
                666,
                51172
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 51,
            "seek": 21944,
            "start": 235.6,
            "end": 239.76,
            "text": " this paradigm of all the different topics that you've been exposed to in this class so",
            "tokens": [
                51172,
                341,
                24709,
                295,
                439,
                264,
                819,
                8378,
                300,
                291,
                600,
                668,
                9495,
                281,
                294,
                341,
                1508,
                370,
                51380
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 52,
            "seek": 21944,
            "start": 239.76,
            "end": 241.28,
            "text": " far.",
            "tokens": [
                51380,
                1400,
                13,
                51456
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 53,
            "seek": 21944,
            "start": 241.28,
            "end": 245.07999999999998,
            "text": " As a whole, I think that we've really covered two different types of learning in this",
            "tokens": [
                51456,
                1018,
                257,
                1379,
                11,
                286,
                519,
                300,
                321,
                600,
                534,
                5343,
                732,
                819,
                3467,
                295,
                2539,
                294,
                341,
                51646
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 54,
            "seek": 21944,
            "start": 245.07999999999998,
            "end": 246.68,
            "text": " course to date.",
            "tokens": [
                51646,
                1164,
                281,
                4002,
                13,
                51726
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30795114690607245,
            "compression_ratio": 1.5774647887323943,
            "no_speech_prob": 0.26111191511154175
        },
        {
            "id": 55,
            "seek": 24668,
            "start": 246.68,
            "end": 251.08,
            "text": " Up until now, we've really started focusing in the beginning part of the lectures, firstly,",
            "tokens": [
                50364,
                5858,
                1826,
                586,
                11,
                321,
                600,
                534,
                1409,
                8416,
                294,
                264,
                2863,
                644,
                295,
                264,
                16564,
                11,
                27376,
                11,
                50584
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 56,
            "seek": 24668,
            "start": 251.08,
            "end": 254.20000000000002,
            "text": " on what we call supervised learning.",
            "tokens": [
                50584,
                322,
                437,
                321,
                818,
                46533,
                2539,
                13,
                50740
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 57,
            "seek": 24668,
            "start": 254.20000000000002,
            "end": 260.48,
            "text": " Supervised learning is in this domain where we're given data in the form of x's, our inputs,",
            "tokens": [
                50740,
                4548,
                24420,
                2539,
                307,
                294,
                341,
                9274,
                689,
                321,
                434,
                2212,
                1412,
                294,
                264,
                1254,
                295,
                2031,
                311,
                11,
                527,
                15743,
                11,
                51054
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 58,
            "seek": 24668,
            "start": 260.48,
            "end": 262.36,
            "text": " and our labels y.",
            "tokens": [
                51054,
                293,
                527,
                16949,
                288,
                13,
                51148
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 59,
            "seek": 24668,
            "start": 262.36,
            "end": 266.64,
            "text": " Our goal here is to learn a function or a neural network that can learn to predict why",
            "tokens": [
                51148,
                2621,
                3387,
                510,
                307,
                281,
                1466,
                257,
                2445,
                420,
                257,
                18161,
                3209,
                300,
                393,
                1466,
                281,
                6069,
                983,
                51362
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        }
    ],
    [
        {
            "id": 60,
            "seek": 24668,
            "start": 266.64,
            "end": 268.64,
            "text": " given our inputs x.",
            "tokens": [
                51362,
                2212,
                527,
                15743,
                2031,
                13,
                51462
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 61,
            "seek": 24668,
            "start": 268.64,
            "end": 273.72,
            "text": " For example, if you consider this example of an apple, observing a bunch of images of",
            "tokens": [
                51462,
                1171,
                1365,
                11,
                498,
                291,
                1949,
                341,
                1365,
                295,
                364,
                10606,
                11,
                22107,
                257,
                3840,
                295,
                5267,
                295,
                51716
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20893436778675425,
            "compression_ratio": 1.6744186046511629,
            "no_speech_prob": 0.28261053562164307
        },
        {
            "id": 62,
            "seek": 27372,
            "start": 273.72,
            "end": 278.40000000000003,
            "text": " apples, we want to detect in the future if we see a new image of an apple to detect that",
            "tokens": [
                50364,
                16814,
                11,
                321,
                528,
                281,
                5531,
                294,
                264,
                2027,
                498,
                321,
                536,
                257,
                777,
                3256,
                295,
                364,
                10606,
                281,
                5531,
                300,
                50598
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 63,
            "seek": 27372,
            "start": 278.40000000000003,
            "end": 281.08000000000004,
            "text": " this is indeed an apple.",
            "tokens": [
                50598,
                341,
                307,
                6451,
                364,
                10606,
                13,
                50732
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 64,
            "seek": 27372,
            "start": 281.08000000000004,
            "end": 286.20000000000005,
            "text": " The second class of learning approaches that we've discovered yesterday in yesterday's",
            "tokens": [
                50732,
                440,
                1150,
                1508,
                295,
                2539,
                11587,
                300,
                321,
                600,
                6941,
                5186,
                294,
                5186,
                311,
                50988
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 65,
            "seek": 27372,
            "start": 286.20000000000005,
            "end": 289.0,
            "text": " lecture was that of unsupervised learning.",
            "tokens": [
                50988,
                7991,
                390,
                300,
                295,
                2693,
                12879,
                24420,
                2539,
                13,
                51128
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 66,
            "seek": 27372,
            "start": 289.0,
            "end": 292.68,
            "text": " These algorithms, you have only access to the data.",
            "tokens": [
                51128,
                1981,
                14642,
                11,
                291,
                362,
                787,
                2105,
                281,
                264,
                1412,
                13,
                51312
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 67,
            "seek": 27372,
            "start": 292.68,
            "end": 294.48,
            "text": " There's no notion of labels.",
            "tokens": [
                51312,
                821,
                311,
                572,
                10710,
                295,
                16949,
                13,
                51402
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 68,
            "seek": 27372,
            "start": 294.48,
            "end": 297.36,
            "text": " This is what we learned about yesterday.",
            "tokens": [
                51402,
                639,
                307,
                437,
                321,
                3264,
                466,
                5186,
                13,
                51546
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 69,
            "seek": 27372,
            "start": 297.36,
            "end": 301.20000000000005,
            "text": " In these types of algorithms, you're not trying to predict a label, but you're trying to",
            "tokens": [
                51546,
                682,
                613,
                3467,
                295,
                14642,
                11,
                291,
                434,
                406,
                1382,
                281,
                6069,
                257,
                7645,
                11,
                457,
                291,
                434,
                1382,
                281,
                51738
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2037341971146433,
            "compression_ratio": 1.816,
            "no_speech_prob": 0.0012248290004208684
        },
        {
            "id": 70,
            "seek": 30120,
            "start": 301.2,
            "end": 303.71999999999997,
            "text": " uncover some of the underlying structure.",
            "tokens": [
                50364,
                21694,
                512,
                295,
                264,
                14217,
                3877,
                13,
                50490
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 71,
            "seek": 30120,
            "start": 303.71999999999997,
            "end": 307.56,
            "text": " What we were calling basically these latent variables, these hidden features in your",
            "tokens": [
                50490,
                708,
                321,
                645,
                5141,
                1936,
                613,
                48994,
                9102,
                11,
                613,
                7633,
                4122,
                294,
                428,
                50682
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 72,
            "seek": 30120,
            "start": 307.56,
            "end": 308.56,
            "text": " data.",
            "tokens": [
                50682,
                1412,
                13,
                50732
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 73,
            "seek": 30120,
            "start": 308.56,
            "end": 314.44,
            "text": " For example, in this apple example, using unsupervised learning, the analogous example would basically",
            "tokens": [
                50732,
                1171,
                1365,
                11,
                294,
                341,
                10606,
                1365,
                11,
                1228,
                2693,
                12879,
                24420,
                2539,
                11,
                264,
                16660,
                563,
                1365,
                576,
                1936,
                51026
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 74,
            "seek": 30120,
            "start": 314.44,
            "end": 321.91999999999996,
            "text": " be to build a model that could understand and cluster certain parts of these images together.",
            "tokens": [
                51026,
                312,
                281,
                1322,
                257,
                2316,
                300,
                727,
                1223,
                293,
                13630,
                1629,
                3166,
                295,
                613,
                5267,
                1214,
                13,
                51400
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 75,
            "seek": 30120,
            "start": 321.91999999999996,
            "end": 326.0,
            "text": " Maybe it doesn't have to understand that necessarily this is an image of an apple, but it",
            "tokens": [
                51400,
                2704,
                309,
                1177,
                380,
                362,
                281,
                1223,
                300,
                4725,
                341,
                307,
                364,
                3256,
                295,
                364,
                10606,
                11,
                457,
                309,
                51604
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 76,
            "seek": 30120,
            "start": 326.0,
            "end": 329.76,
            "text": " needs to understand that this image of the red apple is similar.",
            "tokens": [
                51604,
                2203,
                281,
                1223,
                300,
                341,
                3256,
                295,
                264,
                2182,
                10606,
                307,
                2531,
                13,
                51792
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17021634843614367,
            "compression_ratio": 1.7859778597785978,
            "no_speech_prob": 0.002885931171476841
        },
        {
            "id": 77,
            "seek": 32976,
            "start": 329.76,
            "end": 335.32,
            "text": " It has the same latent features and semantic meaning as this black and white outline sketch",
            "tokens": [
                50364,
                467,
                575,
                264,
                912,
                48994,
                4122,
                293,
                47982,
                3620,
                382,
                341,
                2211,
                293,
                2418,
                16387,
                12325,
                50642
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 78,
            "seek": 32976,
            "start": 335.32,
            "end": 338.24,
            "text": " of the apple.",
            "tokens": [
                50642,
                295,
                264,
                10606,
                13,
                50788
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 79,
            "seek": 32976,
            "start": 338.24,
            "end": 343.48,
            "text": " In today's lecture, we're going to talk about yet another type of learning algorithms.",
            "tokens": [
                50788,
                682,
                965,
                311,
                7991,
                11,
                321,
                434,
                516,
                281,
                751,
                466,
                1939,
                1071,
                2010,
                295,
                2539,
                14642,
                13,
                51050
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 80,
            "seek": 32976,
            "start": 343.48,
            "end": 347.96,
            "text": " In reinforcement learning, we're going to be only given data in the form of what are",
            "tokens": [
                51050,
                682,
                29280,
                2539,
                11,
                321,
                434,
                516,
                281,
                312,
                787,
                2212,
                1412,
                294,
                264,
                1254,
                295,
                437,
                366,
                51274
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 81,
            "seek": 32976,
            "start": 347.96,
            "end": 351.12,
            "text": " called state action pairs.",
            "tokens": [
                51274,
                1219,
                1785,
                3069,
                15494,
                13,
                51432
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 82,
            "seek": 32976,
            "start": 351.12,
            "end": 353.56,
            "text": " States are observations.",
            "tokens": [
                51432,
                3040,
                366,
                18163,
                13,
                51554
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 83,
            "seek": 32976,
            "start": 353.56,
            "end": 357.8,
            "text": " This is what the agent, the neural network is going to observe.",
            "tokens": [
                51554,
                639,
                307,
                437,
                264,
                9461,
                11,
                264,
                18161,
                3209,
                307,
                516,
                281,
                11441,
                13,
                51766
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 84,
            "seek": 32976,
            "start": 357.8,
            "end": 359.4,
            "text": " It's what it sees.",
            "tokens": [
                51766,
                467,
                311,
                437,
                309,
                8194,
                13,
                51846
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20270382779315838,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.0003403557348065078
        },
        {
            "id": 85,
            "seek": 35940,
            "start": 359.4,
            "end": 365.76,
            "text": " The actions are the behaviors that this agent takes in those particular states.",
            "tokens": [
                50364,
                440,
                5909,
                366,
                264,
                15501,
                300,
                341,
                9461,
                2516,
                294,
                729,
                1729,
                4368,
                13,
                50682
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        },
        {
            "id": 86,
            "seek": 35940,
            "start": 365.76,
            "end": 370.21999999999997,
            "text": " The goal of reinforcement learning is to build an agent that can learn how to maximize",
            "tokens": [
                50682,
                440,
                3387,
                295,
                29280,
                2539,
                307,
                281,
                1322,
                364,
                9461,
                300,
                393,
                1466,
                577,
                281,
                19874,
                50905
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        },
        {
            "id": 87,
            "seek": 35940,
            "start": 370.21999999999997,
            "end": 372.03999999999996,
            "text": " what are called rewards.",
            "tokens": [
                50905,
                437,
                366,
                1219,
                17203,
                13,
                50996
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        },
        {
            "id": 88,
            "seek": 35940,
            "start": 372.03999999999996,
            "end": 375.88,
            "text": " This is the third component that is specific to reinforcement learning.",
            "tokens": [
                50996,
                639,
                307,
                264,
                2636,
                6542,
                300,
                307,
                2685,
                281,
                29280,
                2539,
                13,
                51188
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        },
        {
            "id": 89,
            "seek": 35940,
            "start": 375.88,
            "end": 381.44,
            "text": " You want to maximize all of those rewards over many, many time steps in the future.",
            "tokens": [
                51188,
                509,
                528,
                281,
                19874,
                439,
                295,
                729,
                17203,
                670,
                867,
                11,
                867,
                565,
                4439,
                294,
                264,
                2027,
                13,
                51466
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        }
    ],
    [
        {
            "id": 90,
            "seek": 35940,
            "start": 381.44,
            "end": 386.08,
            "text": " Again, in this apple example, we might now see that the agent doesn't necessarily learn",
            "tokens": [
                51466,
                3764,
                11,
                294,
                341,
                10606,
                1365,
                11,
                321,
                1062,
                586,
                536,
                300,
                264,
                9461,
                1177,
                380,
                4725,
                1466,
                51698
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1493976730661294,
            "compression_ratio": 1.74,
            "no_speech_prob": 6.705435953335837e-05
        },
        {
            "id": 91,
            "seek": 38608,
            "start": 386.08,
            "end": 389.03999999999996,
            "text": " that this is an apple or it looks like these other apples.",
            "tokens": [
                50364,
                300,
                341,
                307,
                364,
                10606,
                420,
                309,
                1542,
                411,
                613,
                661,
                16814,
                13,
                50512
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 92,
            "seek": 38608,
            "start": 389.03999999999996,
            "end": 393.32,
            "text": " Now it has to learn to, let's say, eat the apple, take an action, eat that apple because",
            "tokens": [
                50512,
                823,
                309,
                575,
                281,
                1466,
                281,
                11,
                718,
                311,
                584,
                11,
                1862,
                264,
                10606,
                11,
                747,
                364,
                3069,
                11,
                1862,
                300,
                10606,
                570,
                50726
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 93,
            "seek": 38608,
            "start": 393.32,
            "end": 397.59999999999997,
            "text": " it has learned that eating that apple makes it live longer or survive because it doesn't",
            "tokens": [
                50726,
                309,
                575,
                3264,
                300,
                3936,
                300,
                10606,
                1669,
                309,
                1621,
                2854,
                420,
                7867,
                570,
                309,
                1177,
                380,
                50940
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 94,
            "seek": 38608,
            "start": 397.59999999999997,
            "end": 400.12,
            "text": " starve.",
            "tokens": [
                50940,
                46755,
                13,
                51066
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 95,
            "seek": 38608,
            "start": 400.12,
            "end": 405.08,
            "text": " In today, like I said, we're going to be focusing exclusively on this third type of learning",
            "tokens": [
                51066,
                682,
                965,
                11,
                411,
                286,
                848,
                11,
                321,
                434,
                516,
                281,
                312,
                8416,
                20638,
                322,
                341,
                2636,
                2010,
                295,
                2539,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 96,
            "seek": 38608,
            "start": 405.08,
            "end": 408.32,
            "text": " paradigm, which is reinforcement learning.",
            "tokens": [
                51314,
                24709,
                11,
                597,
                307,
                29280,
                2539,
                13,
                51476
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 97,
            "seek": 38608,
            "start": 408.32,
            "end": 413.08,
            "text": " Before we go any further, I just want to start by building up some very key terminology",
            "tokens": [
                51476,
                4546,
                321,
                352,
                604,
                3052,
                11,
                286,
                445,
                528,
                281,
                722,
                538,
                2390,
                493,
                512,
                588,
                2141,
                27575,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17032304303399448,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.007001016288995743
        },
        {
            "id": 98,
            "seek": 41308,
            "start": 413.08,
            "end": 418.4,
            "text": " and basically background for all of you so that we're all on the same page when we",
            "tokens": [
                50364,
                293,
                1936,
                3678,
                337,
                439,
                295,
                291,
                370,
                300,
                321,
                434,
                439,
                322,
                264,
                912,
                3028,
                562,
                321,
                50630
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18953208681903308,
            "compression_ratio": 1.6243654822335025,
            "no_speech_prob": 0.0012053466634824872
        },
        {
            "id": 99,
            "seek": 41308,
            "start": 418.4,
            "end": 423.56,
            "text": " start discussing some of the more complex components of today's lecture.",
            "tokens": [
                50630,
                722,
                10850,
                512,
                295,
                264,
                544,
                3997,
                6677,
                295,
                965,
                311,
                7991,
                13,
                50888
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18953208681903308,
            "compression_ratio": 1.6243654822335025,
            "no_speech_prob": 0.0012053466634824872
        },
        {
            "id": 100,
            "seek": 41308,
            "start": 423.56,
            "end": 427.03999999999996,
            "text": " Let's start by building up some of this terminology.",
            "tokens": [
                50888,
                961,
                311,
                722,
                538,
                2390,
                493,
                512,
                295,
                341,
                27575,
                13,
                51062
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18953208681903308,
            "compression_ratio": 1.6243654822335025,
            "no_speech_prob": 0.0012053466634824872
        },
        {
            "id": 101,
            "seek": 41308,
            "start": 427.03999999999996,
            "end": 430.88,
            "text": " The first main piece of terminology is that of an agent.",
            "tokens": [
                51062,
                440,
                700,
                2135,
                2522,
                295,
                27575,
                307,
                300,
                295,
                364,
                9461,
                13,
                51254
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18953208681903308,
            "compression_ratio": 1.6243654822335025,
            "no_speech_prob": 0.0012053466634824872
        },
        {
            "id": 102,
            "seek": 41308,
            "start": 430.88,
            "end": 436.47999999999996,
            "text": " An agent is a being, basically, that can take actions.",
            "tokens": [
                51254,
                1107,
                9461,
                307,
                257,
                885,
                11,
                1936,
                11,
                300,
                393,
                747,
                5909,
                13,
                51534
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18953208681903308,
            "compression_ratio": 1.6243654822335025,
            "no_speech_prob": 0.0012053466634824872
        },
        {
            "id": 103,
            "seek": 43648,
            "start": 436.48,
            "end": 442.84000000000003,
            "text": " For example, you can think of an agent as a machine that is, let's say, an autonomous",
            "tokens": [
                50364,
                1171,
                1365,
                11,
                291,
                393,
                519,
                295,
                364,
                9461,
                382,
                257,
                3479,
                300,
                307,
                11,
                718,
                311,
                584,
                11,
                364,
                23797,
                50682
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 104,
            "seek": 43648,
            "start": 442.84000000000003,
            "end": 448.52000000000004,
            "text": " drone that is making a delivery or, for example, in a game, it could be Super Mario that's",
            "tokens": [
                50682,
                13852,
                300,
                307,
                1455,
                257,
                8982,
                420,
                11,
                337,
                1365,
                11,
                294,
                257,
                1216,
                11,
                309,
                727,
                312,
                4548,
                9343,
                300,
                311,
                50966
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 105,
            "seek": 43648,
            "start": 448.52000000000004,
            "end": 451.56,
            "text": " navigating inside of your video game.",
            "tokens": [
                50966,
                32054,
                1854,
                295,
                428,
                960,
                1216,
                13,
                51118
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 106,
            "seek": 43648,
            "start": 451.56,
            "end": 456.32,
            "text": " The algorithm itself, it's important to remember that the algorithm is the agent.",
            "tokens": [
                51118,
                440,
                9284,
                2564,
                11,
                309,
                311,
                1021,
                281,
                1604,
                300,
                264,
                9284,
                307,
                264,
                9461,
                13,
                51356
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 107,
            "seek": 43648,
            "start": 456.32,
            "end": 460.68,
            "text": " We're trying to build an agent that can do these tasks and the algorithm is that agent.",
            "tokens": [
                51356,
                492,
                434,
                1382,
                281,
                1322,
                364,
                9461,
                300,
                393,
                360,
                613,
                9608,
                293,
                264,
                9284,
                307,
                300,
                9461,
                13,
                51574
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 108,
            "seek": 43648,
            "start": 460.68,
            "end": 465.56,
            "text": " In life, for example, all of you are agents in life.",
            "tokens": [
                51574,
                682,
                993,
                11,
                337,
                1365,
                11,
                439,
                295,
                291,
                366,
                12554,
                294,
                993,
                13,
                51818
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15949085539421148,
            "compression_ratio": 1.7764227642276422,
            "no_speech_prob": 0.006376356352120638
        },
        {
            "id": 109,
            "seek": 46556,
            "start": 465.64,
            "end": 470.8,
            "text": " The environment is the other kind of contrary approach or the contrary perspective to the",
            "tokens": [
                50368,
                440,
                2823,
                307,
                264,
                661,
                733,
                295,
                19506,
                3109,
                420,
                264,
                19506,
                4585,
                281,
                264,
                50626
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 110,
            "seek": 46556,
            "start": 470.8,
            "end": 471.8,
            "text": " agent.",
            "tokens": [
                50626,
                9461,
                13,
                50676
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 111,
            "seek": 46556,
            "start": 471.8,
            "end": 476.84,
            "text": " The environment is simply the world where that agent lives and where it operates.",
            "tokens": [
                50676,
                440,
                2823,
                307,
                2935,
                264,
                1002,
                689,
                300,
                9461,
                2909,
                293,
                689,
                309,
                22577,
                13,
                50928
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 112,
            "seek": 46556,
            "start": 476.84,
            "end": 480.12,
            "text": " Where it exists and it moves around in.",
            "tokens": [
                50928,
                2305,
                309,
                8198,
                293,
                309,
                6067,
                926,
                294,
                13,
                51092
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 113,
            "seek": 46556,
            "start": 480.12,
            "end": 484.84000000000003,
            "text": " The agent can send commands to that environment in the form of what are called actions.",
            "tokens": [
                51092,
                440,
                9461,
                393,
                2845,
                16901,
                281,
                300,
                2823,
                294,
                264,
                1254,
                295,
                437,
                366,
                1219,
                5909,
                13,
                51328
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 114,
            "seek": 46556,
            "start": 484.84000000000003,
            "end": 490.08,
            "text": " It can take actions in that environment and let's call for notation purposes.",
            "tokens": [
                51328,
                467,
                393,
                747,
                5909,
                294,
                300,
                2823,
                293,
                718,
                311,
                818,
                337,
                24657,
                9932,
                13,
                51590
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1981115231568786,
            "compression_ratio": 1.8823529411764706,
            "no_speech_prob": 0.00046488502994179726
        },
        {
            "id": 115,
            "seek": 49008,
            "start": 490.08,
            "end": 495.56,
            "text": " Let's say the possible set of all actions that it could take is, let's say, a set of",
            "tokens": [
                50364,
                961,
                311,
                584,
                264,
                1944,
                992,
                295,
                439,
                5909,
                300,
                309,
                727,
                747,
                307,
                11,
                718,
                311,
                584,
                11,
                257,
                992,
                295,
                50638
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 116,
            "seek": 49008,
            "start": 495.56,
            "end": 503.59999999999997,
            "text": " capital A. It should be noted that agents at any point in time could choose amongst this,",
            "tokens": [
                50638,
                4238,
                316,
                13,
                467,
                820,
                312,
                12964,
                300,
                12554,
                412,
                604,
                935,
                294,
                565,
                727,
                2826,
                12918,
                341,
                11,
                51040
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 117,
            "seek": 49008,
            "start": 503.59999999999997,
            "end": 505.64,
            "text": " let's say, list of possible actions.",
            "tokens": [
                51040,
                718,
                311,
                584,
                11,
                1329,
                295,
                1944,
                5909,
                13,
                51142
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 118,
            "seek": 49008,
            "start": 505.64,
            "end": 510.32,
            "text": " Of course, in some situations, your action space does not necessarily need to be a finite",
            "tokens": [
                51142,
                2720,
                1164,
                11,
                294,
                512,
                6851,
                11,
                428,
                3069,
                1901,
                775,
                406,
                4725,
                643,
                281,
                312,
                257,
                19362,
                51376
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 119,
            "seek": 49008,
            "start": 510.32,
            "end": 511.32,
            "text": " space.",
            "tokens": [
                51376,
                1901,
                13,
                51426
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        }
    ],
    [
        {
            "id": 120,
            "seek": 49008,
            "start": 511.32,
            "end": 513.16,
            "text": " Maybe you could take actions in a continuous space.",
            "tokens": [
                51426,
                2704,
                291,
                727,
                747,
                5909,
                294,
                257,
                10957,
                1901,
                13,
                51518
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 121,
            "seek": 49008,
            "start": 513.16,
            "end": 518.16,
            "text": " For example, when you're driving a car, you're taking actions on a continuous angle space",
            "tokens": [
                51518,
                1171,
                1365,
                11,
                562,
                291,
                434,
                4840,
                257,
                1032,
                11,
                291,
                434,
                1940,
                5909,
                322,
                257,
                10957,
                5802,
                1901,
                51768
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1780207924220873,
            "compression_ratio": 1.859504132231405,
            "no_speech_prob": 0.007565222214907408
        },
        {
            "id": 122,
            "seek": 51816,
            "start": 518.16,
            "end": 520.1999999999999,
            "text": " of what angle you want to steer that car.",
            "tokens": [
                50364,
                295,
                437,
                5802,
                291,
                528,
                281,
                30814,
                300,
                1032,
                13,
                50466
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 123,
            "seek": 51816,
            "start": 520.1999999999999,
            "end": 523.0,
            "text": " It's not necessarily just going right or left or straight.",
            "tokens": [
                50466,
                467,
                311,
                406,
                4725,
                445,
                516,
                558,
                420,
                1411,
                420,
                2997,
                13,
                50606
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 124,
            "seek": 51816,
            "start": 523.0,
            "end": 527.68,
            "text": " You may steer at any continuous degree.",
            "tokens": [
                50606,
                509,
                815,
                30814,
                412,
                604,
                10957,
                4314,
                13,
                50840
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 125,
            "seek": 51816,
            "start": 527.68,
            "end": 531.8399999999999,
            "text": " Observations is essentially how the environment responds back to the agent.",
            "tokens": [
                50840,
                42547,
                763,
                307,
                4476,
                577,
                264,
                2823,
                27331,
                646,
                281,
                264,
                9461,
                13,
                51048
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 126,
            "seek": 51816,
            "start": 531.8399999999999,
            "end": 537.24,
            "text": " The environment can tell the agent what it should be seeing based on those actions that",
            "tokens": [
                51048,
                440,
                2823,
                393,
                980,
                264,
                9461,
                437,
                309,
                820,
                312,
                2577,
                2361,
                322,
                729,
                5909,
                300,
                51318
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 127,
            "seek": 51816,
            "start": 537.24,
            "end": 538.7199999999999,
            "text": " it just took.",
            "tokens": [
                51318,
                309,
                445,
                1890,
                13,
                51392
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 128,
            "seek": 51816,
            "start": 538.7199999999999,
            "end": 542.4399999999999,
            "text": " It responds in the form of what is called a state.",
            "tokens": [
                51392,
                467,
                27331,
                294,
                264,
                1254,
                295,
                437,
                307,
                1219,
                257,
                1785,
                13,
                51578
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 129,
            "seek": 51816,
            "start": 542.4399999999999,
            "end": 547.8,
            "text": " A state is simply a concrete and immediate situation that the agent finds itself in.",
            "tokens": [
                51578,
                316,
                1785,
                307,
                2935,
                257,
                9859,
                293,
                11629,
                2590,
                300,
                264,
                9461,
                10704,
                2564,
                294,
                13,
                51846
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16418073811662307,
            "compression_ratio": 1.7461538461538462,
            "no_speech_prob": 0.0014537040842697024
        },
        {
            "id": 130,
            "seek": 54780,
            "start": 547.8,
            "end": 551.52,
            "text": " At that particular moment.",
            "tokens": [
                50364,
                1711,
                300,
                1729,
                1623,
                13,
                50550
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 131,
            "seek": 54780,
            "start": 551.52,
            "end": 556.3199999999999,
            "text": " It's important to remember that unlike other types of learning that we've covered in this",
            "tokens": [
                50550,
                467,
                311,
                1021,
                281,
                1604,
                300,
                8343,
                661,
                3467,
                295,
                2539,
                300,
                321,
                600,
                5343,
                294,
                341,
                50790
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 132,
            "seek": 54780,
            "start": 556.3199999999999,
            "end": 561.8399999999999,
            "text": " course, reinforcement learning is a bit unique because it has one more component here in addition",
            "tokens": [
                50790,
                1164,
                11,
                29280,
                2539,
                307,
                257,
                857,
                3845,
                570,
                309,
                575,
                472,
                544,
                6542,
                510,
                294,
                4500,
                51066
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 133,
            "seek": 54780,
            "start": 561.8399999999999,
            "end": 565.4799999999999,
            "text": " to these other components, which is called the reward.",
            "tokens": [
                51066,
                281,
                613,
                661,
                6677,
                11,
                597,
                307,
                1219,
                264,
                7782,
                13,
                51248
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 134,
            "seek": 54780,
            "start": 565.4799999999999,
            "end": 572.4,
            "text": " Now the reward is a feedback by which we measure or we can try to measure the success of",
            "tokens": [
                51248,
                823,
                264,
                7782,
                307,
                257,
                5824,
                538,
                597,
                321,
                3481,
                420,
                321,
                393,
                853,
                281,
                3481,
                264,
                2245,
                295,
                51594
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 135,
            "seek": 54780,
            "start": 572.4,
            "end": 574.92,
            "text": " a particular agent in its environment.",
            "tokens": [
                51594,
                257,
                1729,
                9461,
                294,
                1080,
                2823,
                13,
                51720
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19270979563395182,
            "compression_ratio": 1.7112068965517242,
            "no_speech_prob": 0.000967491592746228
        },
        {
            "id": 136,
            "seek": 57492,
            "start": 574.92,
            "end": 580.76,
            "text": " For example, in a video game, when Mario grabs a coin, for example, he wins points.",
            "tokens": [
                50364,
                1171,
                1365,
                11,
                294,
                257,
                960,
                1216,
                11,
                562,
                9343,
                30028,
                257,
                11464,
                11,
                337,
                1365,
                11,
                415,
                10641,
                2793,
                13,
                50656
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15735018730163575,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.01821753941476345
        },
        {
            "id": 137,
            "seek": 57492,
            "start": 580.76,
            "end": 587.5999999999999,
            "text": " From a given state, an agent can send out any form of actions to take some decisions.",
            "tokens": [
                50656,
                3358,
                257,
                2212,
                1785,
                11,
                364,
                9461,
                393,
                2845,
                484,
                604,
                1254,
                295,
                5909,
                281,
                747,
                512,
                5327,
                13,
                50998
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15735018730163575,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.01821753941476345
        },
        {
            "id": 138,
            "seek": 57492,
            "start": 587.5999999999999,
            "end": 594.3199999999999,
            "text": " Those actions may or may not result in rewards being collected and accumulated over time.",
            "tokens": [
                50998,
                3950,
                5909,
                815,
                420,
                815,
                406,
                1874,
                294,
                17203,
                885,
                11087,
                293,
                31346,
                670,
                565,
                13,
                51334
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15735018730163575,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.01821753941476345
        },
        {
            "id": 139,
            "seek": 57492,
            "start": 594.3199999999999,
            "end": 598.64,
            "text": " It's also very important to remember that not all actions result in immediate rewards.",
            "tokens": [
                51334,
                467,
                311,
                611,
                588,
                1021,
                281,
                1604,
                300,
                406,
                439,
                5909,
                1874,
                294,
                11629,
                17203,
                13,
                51550
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15735018730163575,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.01821753941476345
        },
        {
            "id": 140,
            "seek": 57492,
            "start": 598.64,
            "end": 603.28,
            "text": " You may take some actions that will result in a reward in a delayed fashion.",
            "tokens": [
                51550,
                509,
                815,
                747,
                512,
                5909,
                300,
                486,
                1874,
                294,
                257,
                7782,
                294,
                257,
                20268,
                6700,
                13,
                51782
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15735018730163575,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.01821753941476345
        },
        {
            "id": 141,
            "seek": 60328,
            "start": 603.28,
            "end": 606.9599999999999,
            "text": " Maybe in a few time steps down the future or maybe in life, maybe years.",
            "tokens": [
                50364,
                2704,
                294,
                257,
                1326,
                565,
                4439,
                760,
                264,
                2027,
                420,
                1310,
                294,
                993,
                11,
                1310,
                924,
                13,
                50548
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17953980906625813,
            "compression_ratio": 1.6475770925110131,
            "no_speech_prob": 0.0016203231643885374
        },
        {
            "id": 142,
            "seek": 60328,
            "start": 606.9599999999999,
            "end": 613.0,
            "text": " You may take an action today that results in a reward many some time from now.",
            "tokens": [
                50548,
                509,
                815,
                747,
                364,
                3069,
                965,
                300,
                3542,
                294,
                257,
                7782,
                867,
                512,
                565,
                490,
                586,
                13,
                50850
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17953980906625813,
            "compression_ratio": 1.6475770925110131,
            "no_speech_prob": 0.0016203231643885374
        },
        {
            "id": 143,
            "seek": 60328,
            "start": 613.0,
            "end": 620.0,
            "text": " Essentially, all of these try to effectively evaluate some way of measuring the success",
            "tokens": [
                50850,
                23596,
                11,
                439,
                295,
                613,
                853,
                281,
                8659,
                13059,
                512,
                636,
                295,
                13389,
                264,
                2245,
                51200
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17953980906625813,
            "compression_ratio": 1.6475770925110131,
            "no_speech_prob": 0.0016203231643885374
        },
        {
            "id": 144,
            "seek": 60328,
            "start": 620.0,
            "end": 623.52,
            "text": " of a particular action that an agent takes.",
            "tokens": [
                51200,
                295,
                257,
                1729,
                3069,
                300,
                364,
                9461,
                2516,
                13,
                51376
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17953980906625813,
            "compression_ratio": 1.6475770925110131,
            "no_speech_prob": 0.0016203231643885374
        },
        {
            "id": 145,
            "seek": 60328,
            "start": 623.52,
            "end": 628.0799999999999,
            "text": " For example, when we look at the total reward that an agent accumulates over the course of",
            "tokens": [
                51376,
                1171,
                1365,
                11,
                562,
                321,
                574,
                412,
                264,
                3217,
                7782,
                300,
                364,
                9461,
                12989,
                26192,
                670,
                264,
                1164,
                295,
                51604
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17953980906625813,
            "compression_ratio": 1.6475770925110131,
            "no_speech_prob": 0.0016203231643885374
        },
        {
            "id": 146,
            "seek": 62808,
            "start": 628.08,
            "end": 634.32,
            "text": " its lifetime, we can simply sum up all of the rewards that an agent gets after a certain",
            "tokens": [
                50364,
                1080,
                11364,
                11,
                321,
                393,
                2935,
                2408,
                493,
                439,
                295,
                264,
                17203,
                300,
                364,
                9461,
                2170,
                934,
                257,
                1629,
                50676
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 147,
            "seek": 62808,
            "start": 634.32,
            "end": 635.32,
            "text": " time t.",
            "tokens": [
                50676,
                565,
                256,
                13,
                50726
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 148,
            "seek": 62808,
            "start": 635.32,
            "end": 641.62,
            "text": " So this capital R of t is the sum of all rewards from that point on into the future, into",
            "tokens": [
                50726,
                407,
                341,
                4238,
                497,
                295,
                256,
                307,
                264,
                2408,
                295,
                439,
                17203,
                490,
                300,
                935,
                322,
                666,
                264,
                2027,
                11,
                666,
                51041
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 149,
            "seek": 62808,
            "start": 641.62,
            "end": 643.82,
            "text": " infinity.",
            "tokens": [
                51041,
                13202,
                13,
                51151
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        }
    ],
    [
        {
            "id": 150,
            "seek": 62808,
            "start": 643.82,
            "end": 646.72,
            "text": " And that can be expanded to look exactly like this.",
            "tokens": [
                51151,
                400,
                300,
                393,
                312,
                14342,
                281,
                574,
                2293,
                411,
                341,
                13,
                51296
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 151,
            "seek": 62808,
            "start": 646.72,
            "end": 651.24,
            "text": " It's rewarded time t plus the reward time t plus one plus t plus two and so on and so",
            "tokens": [
                51296,
                467,
                311,
                29105,
                565,
                256,
                1804,
                264,
                7782,
                565,
                256,
                1804,
                472,
                1804,
                256,
                1804,
                732,
                293,
                370,
                322,
                293,
                370,
                51522
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 152,
            "seek": 62808,
            "start": 651.24,
            "end": 652.88,
            "text": " forth.",
            "tokens": [
                51522,
                5220,
                13,
                51604
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 153,
            "seek": 62808,
            "start": 652.88,
            "end": 657.72,
            "text": " Often it's actually very useful for all of us to consider not only the sum of all of",
            "tokens": [
                51604,
                20043,
                309,
                311,
                767,
                588,
                4420,
                337,
                439,
                295,
                505,
                281,
                1949,
                406,
                787,
                264,
                2408,
                295,
                439,
                295,
                51846
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21443103921824488,
            "compression_ratio": 1.7676348547717842,
            "no_speech_prob": 0.0033748133573681116
        },
        {
            "id": 154,
            "seek": 65772,
            "start": 657.72,
            "end": 660.8000000000001,
            "text": " these rewards, but instead what's called the discounted sum.",
            "tokens": [
                50364,
                613,
                17203,
                11,
                457,
                2602,
                437,
                311,
                1219,
                264,
                11635,
                292,
                2408,
                13,
                50518
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 155,
            "seek": 65772,
            "start": 660.8000000000001,
            "end": 666.8000000000001,
            "text": " So you can see here, I've added this gamma factor in front of all of the rewards and that",
            "tokens": [
                50518,
                407,
                291,
                393,
                536,
                510,
                11,
                286,
                600,
                3869,
                341,
                15546,
                5952,
                294,
                1868,
                295,
                439,
                295,
                264,
                17203,
                293,
                300,
                50818
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 156,
            "seek": 65772,
            "start": 666.8000000000001,
            "end": 673.28,
            "text": " discounting factor is essentially multiplied by every future reward that the agent sees",
            "tokens": [
                50818,
                11635,
                278,
                5952,
                307,
                4476,
                17207,
                538,
                633,
                2027,
                7782,
                300,
                264,
                9461,
                8194,
                51142
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 157,
            "seek": 65772,
            "start": 673.28,
            "end": 674.76,
            "text": " and is discovered by the agent.",
            "tokens": [
                51142,
                293,
                307,
                6941,
                538,
                264,
                9461,
                13,
                51216
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 158,
            "seek": 65772,
            "start": 674.76,
            "end": 680.36,
            "text": " And the reason that we want to do this is actually this dampening factor is designed to make",
            "tokens": [
                51216,
                400,
                264,
                1778,
                300,
                321,
                528,
                281,
                360,
                341,
                307,
                767,
                341,
                19498,
                4559,
                5952,
                307,
                4761,
                281,
                652,
                51496
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 159,
            "seek": 65772,
            "start": 680.36,
            "end": 686.36,
            "text": " future rewards essentially worth less than rewards that we might see at this instant,",
            "tokens": [
                51496,
                2027,
                17203,
                4476,
                3163,
                1570,
                813,
                17203,
                300,
                321,
                1062,
                536,
                412,
                341,
                9836,
                11,
                51796
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1578216182375417,
            "compression_ratio": 1.8630705394190872,
            "no_speech_prob": 0.0018936828710138798
        },
        {
            "id": 160,
            "seek": 68636,
            "start": 686.36,
            "end": 688.24,
            "text": " right at this moment right now.",
            "tokens": [
                50364,
                558,
                412,
                341,
                1623,
                558,
                586,
                13,
                50458
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 161,
            "seek": 68636,
            "start": 688.24,
            "end": 694.12,
            "text": " You can think of this as basically enforcing some kind of short term, uh, uh,",
            "tokens": [
                50458,
                509,
                393,
                519,
                295,
                341,
                382,
                1936,
                25495,
                2175,
                512,
                733,
                295,
                2099,
                1433,
                11,
                2232,
                11,
                2232,
                11,
                50752
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 162,
            "seek": 68636,
            "start": 694.12,
            "end": 696.16,
            "text": " agreediness in the algorithm, right?",
            "tokens": [
                50752,
                9166,
                1324,
                294,
                264,
                9284,
                11,
                558,
                30,
                50854
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 163,
            "seek": 68636,
            "start": 696.16,
            "end": 702.16,
            "text": " So for example, if I offered you a reward of $5 today or a reward of $5 in 10 years",
            "tokens": [
                50854,
                407,
                337,
                1365,
                11,
                498,
                286,
                8059,
                291,
                257,
                7782,
                295,
                1848,
                20,
                965,
                420,
                257,
                7782,
                295,
                1848,
                20,
                294,
                1266,
                924,
                51154
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 164,
            "seek": 68636,
            "start": 702.16,
            "end": 707.76,
            "text": " from now, I think all of you would prefer that $5 today simply because we have that same",
            "tokens": [
                51154,
                490,
                586,
                11,
                286,
                519,
                439,
                295,
                291,
                576,
                4382,
                300,
                1848,
                20,
                965,
                2935,
                570,
                321,
                362,
                300,
                912,
                51434
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 165,
            "seek": 68636,
            "start": 707.76,
            "end": 711.36,
            "text": " discounting factor applied to this processing, right?",
            "tokens": [
                51434,
                11635,
                278,
                5952,
                6456,
                281,
                341,
                9007,
                11,
                558,
                30,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 166,
            "seek": 68636,
            "start": 711.36,
            "end": 716.26,
            "text": " We have that factor that that $5 is not worth as much to us if it's given to us 10 years",
            "tokens": [
                51614,
                492,
                362,
                300,
                5952,
                300,
                300,
                1848,
                20,
                307,
                406,
                3163,
                382,
                709,
                281,
                505,
                498,
                309,
                311,
                2212,
                281,
                505,
                1266,
                924,
                51859
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22023004198831225,
            "compression_ratio": 1.7047970479704797,
            "no_speech_prob": 0.003705262904986739
        },
        {
            "id": 167,
            "seek": 71626,
            "start": 716.48,
            "end": 717.16,
            "text": " in the future.",
            "tokens": [
                50375,
                294,
                264,
                2027,
                13,
                50409
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 168,
            "seek": 71626,
            "start": 717.16,
            "end": 720.78,
            "text": " And that's exactly how this is captured here as well mathematically.",
            "tokens": [
                50409,
                400,
                300,
                311,
                2293,
                577,
                341,
                307,
                11828,
                510,
                382,
                731,
                44003,
                13,
                50590
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 169,
            "seek": 71626,
            "start": 720.78,
            "end": 725.8,
            "text": " This discounting factor is like multiple, like I said, multiplied it every single future",
            "tokens": [
                50590,
                639,
                11635,
                278,
                5952,
                307,
                411,
                3866,
                11,
                411,
                286,
                848,
                11,
                17207,
                309,
                633,
                2167,
                2027,
                50841
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 170,
            "seek": 71626,
            "start": 725.8,
            "end": 728.78,
            "text": " reward exponentially.",
            "tokens": [
                50841,
                7782,
                37330,
                13,
                50990
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 171,
            "seek": 71626,
            "start": 728.78,
            "end": 733.7,
            "text": " And it's important to understand that also typically this discounting factor is, you know,",
            "tokens": [
                50990,
                400,
                309,
                311,
                1021,
                281,
                1223,
                300,
                611,
                5850,
                341,
                11635,
                278,
                5952,
                307,
                11,
                291,
                458,
                11,
                51236
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 172,
            "seek": 71626,
            "start": 733.7,
            "end": 734.86,
            "text": " between zero and one.",
            "tokens": [
                51236,
                1296,
                4018,
                293,
                472,
                13,
                51294
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 173,
            "seek": 71626,
            "start": 734.86,
            "end": 738.22,
            "text": " There are some exceptional cases where maybe you want some strange behaviors and they",
            "tokens": [
                51294,
                821,
                366,
                512,
                19279,
                3331,
                689,
                1310,
                291,
                528,
                512,
                5861,
                15501,
                293,
                436,
                51462
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 174,
            "seek": 71626,
            "start": 738.22,
            "end": 742.14,
            "text": " have a discounting factor greater than one, but in general, that's not something we're",
            "tokens": [
                51462,
                362,
                257,
                11635,
                278,
                5952,
                5044,
                813,
                472,
                11,
                457,
                294,
                2674,
                11,
                300,
                311,
                406,
                746,
                321,
                434,
                51658
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 175,
            "seek": 71626,
            "start": 742.14,
            "end": 744.54,
            "text": " going to be talking about today.",
            "tokens": [
                51658,
                516,
                281,
                312,
                1417,
                466,
                965,
                13,
                51778
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22489434878031414,
            "compression_ratio": 1.7750865051903115,
            "no_speech_prob": 0.004751618951559067
        },
        {
            "id": 176,
            "seek": 74454,
            "start": 744.54,
            "end": 750.74,
            "text": " Now finally, it's very important in reinforcement learning, this special function called the",
            "tokens": [
                50364,
                823,
                2721,
                11,
                309,
                311,
                588,
                1021,
                294,
                29280,
                2539,
                11,
                341,
                2121,
                2445,
                1219,
                264,
                50674
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 177,
            "seek": 74454,
            "start": 750.74,
            "end": 754.8399999999999,
            "text": " Q function, which ties in a lot of these different components that I've just shared with",
            "tokens": [
                50674,
                1249,
                2445,
                11,
                597,
                14039,
                294,
                257,
                688,
                295,
                613,
                819,
                6677,
                300,
                286,
                600,
                445,
                5507,
                365,
                50879
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 178,
            "seek": 74454,
            "start": 754.8399999999999,
            "end": 756.78,
            "text": " you all together.",
            "tokens": [
                50879,
                291,
                439,
                1214,
                13,
                50976
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 179,
            "seek": 74454,
            "start": 756.78,
            "end": 759.5799999999999,
            "text": " Now let's look at what this Q function is, right?",
            "tokens": [
                50976,
                823,
                718,
                311,
                574,
                412,
                437,
                341,
                1249,
                2445,
                307,
                11,
                558,
                30,
                51116
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        }
    ],
    [
        {
            "id": 180,
            "seek": 74454,
            "start": 759.5799999999999,
            "end": 762.8199999999999,
            "text": " So we already covered this R of T function, right?",
            "tokens": [
                51116,
                407,
                321,
                1217,
                5343,
                341,
                497,
                295,
                314,
                2445,
                11,
                558,
                30,
                51278
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 181,
            "seek": 74454,
            "start": 762.8199999999999,
            "end": 769.5,
            "text": " R of T is the discounted sum of rewards from time T all the way into the future, time",
            "tokens": [
                51278,
                497,
                295,
                314,
                307,
                264,
                11635,
                292,
                2408,
                295,
                17203,
                490,
                565,
                314,
                439,
                264,
                636,
                666,
                264,
                2027,
                11,
                565,
                51612
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 182,
            "seek": 74454,
            "start": 769.5,
            "end": 770.5,
            "text": " infinity.",
            "tokens": [
                51612,
                13202,
                13,
                51662
            ],
            "temperature": 0.0,
            "avg_logprob": -0.21632476881438611,
            "compression_ratio": 1.6229508196721312,
            "no_speech_prob": 0.0012244790559634566
        },
        {
            "id": 183,
            "seek": 77050,
            "start": 770.66,
            "end": 777.54,
            "text": " But remember that this R of T, right, it's discounted number one and number two, we're going",
            "tokens": [
                50372,
                583,
                1604,
                300,
                341,
                497,
                295,
                314,
                11,
                558,
                11,
                309,
                311,
                11635,
                292,
                1230,
                472,
                293,
                1230,
                732,
                11,
                321,
                434,
                516,
                50716
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 184,
            "seek": 77050,
            "start": 777.54,
            "end": 786.22,
            "text": " to try and build a Q function that captures the maximum or the best action that we could",
            "tokens": [
                50716,
                281,
                853,
                293,
                1322,
                257,
                1249,
                2445,
                300,
                27986,
                264,
                6674,
                420,
                264,
                1151,
                3069,
                300,
                321,
                727,
                51150
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 185,
            "seek": 77050,
            "start": 786.22,
            "end": 789.1,
            "text": " take that will maximize this reward.",
            "tokens": [
                51150,
                747,
                300,
                486,
                19874,
                341,
                7782,
                13,
                51294
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 186,
            "seek": 77050,
            "start": 789.1,
            "end": 791.74,
            "text": " So let me say that one more time in a different way.",
            "tokens": [
                51294,
                407,
                718,
                385,
                584,
                300,
                472,
                544,
                565,
                294,
                257,
                819,
                636,
                13,
                51426
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 187,
            "seek": 77050,
            "start": 791.74,
            "end": 795.06,
            "text": " The Q function takes as input two different things.",
            "tokens": [
                51426,
                440,
                1249,
                2445,
                2516,
                382,
                4846,
                732,
                819,
                721,
                13,
                51592
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 188,
            "seek": 77050,
            "start": 795.06,
            "end": 797.18,
            "text": " The first is the state that you're currently in.",
            "tokens": [
                51592,
                440,
                700,
                307,
                264,
                1785,
                300,
                291,
                434,
                4362,
                294,
                13,
                51698
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16621854901313782,
            "compression_ratio": 1.6756756756756757,
            "no_speech_prob": 0.0021803448908030987
        },
        {
            "id": 189,
            "seek": 79718,
            "start": 797.18,
            "end": 802.66,
            "text": " And the second is a possible action that you could execute in this particular state.",
            "tokens": [
                50364,
                400,
                264,
                1150,
                307,
                257,
                1944,
                3069,
                300,
                291,
                727,
                14483,
                294,
                341,
                1729,
                1785,
                13,
                50638
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1435468799465305,
            "compression_ratio": 1.816326530612245,
            "no_speech_prob": 0.00016856761067174375
        },
        {
            "id": 190,
            "seek": 79718,
            "start": 802.66,
            "end": 807.9799999999999,
            "text": " So here, S of T is that state at time T, A of T is that action that you may want to take",
            "tokens": [
                50638,
                407,
                510,
                11,
                318,
                295,
                314,
                307,
                300,
                1785,
                412,
                565,
                314,
                11,
                316,
                295,
                314,
                307,
                300,
                3069,
                300,
                291,
                815,
                528,
                281,
                747,
                50904
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1435468799465305,
            "compression_ratio": 1.816326530612245,
            "no_speech_prob": 0.00016856761067174375
        },
        {
            "id": 191,
            "seek": 79718,
            "start": 807.9799999999999,
            "end": 814.7399999999999,
            "text": " at time T, and the Q function of these two pieces is going to denote or capture what",
            "tokens": [
                50904,
                412,
                565,
                314,
                11,
                293,
                264,
                1249,
                2445,
                295,
                613,
                732,
                3755,
                307,
                516,
                281,
                45708,
                420,
                7983,
                437,
                51242
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1435468799465305,
            "compression_ratio": 1.816326530612245,
            "no_speech_prob": 0.00016856761067174375
        },
        {
            "id": 192,
            "seek": 79718,
            "start": 814.7399999999999,
            "end": 820.5,
            "text": " the expected total return would be of that agent if it took that action in that particular",
            "tokens": [
                51242,
                264,
                5176,
                3217,
                2736,
                576,
                312,
                295,
                300,
                9461,
                498,
                309,
                1890,
                300,
                3069,
                294,
                300,
                1729,
                51530
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1435468799465305,
            "compression_ratio": 1.816326530612245,
            "no_speech_prob": 0.00016856761067174375
        },
        {
            "id": 193,
            "seek": 79718,
            "start": 820.5,
            "end": 822.9799999999999,
            "text": " state.",
            "tokens": [
                51530,
                1785,
                13,
                51654
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1435468799465305,
            "compression_ratio": 1.816326530612245,
            "no_speech_prob": 0.00016856761067174375
        },
        {
            "id": 194,
            "seek": 82298,
            "start": 822.98,
            "end": 829.58,
            "text": " Now one thing that I think maybe we should all be asking ourselves now is this seems like",
            "tokens": [
                50364,
                823,
                472,
                551,
                300,
                286,
                519,
                1310,
                321,
                820,
                439,
                312,
                3365,
                4175,
                586,
                307,
                341,
                2544,
                411,
                50694
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 195,
            "seek": 82298,
            "start": 829.58,
            "end": 831.3000000000001,
            "text": " a really powerful function, right?",
            "tokens": [
                50694,
                257,
                534,
                4005,
                2445,
                11,
                558,
                30,
                50780
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 196,
            "seek": 82298,
            "start": 831.3000000000001,
            "end": 835.7,
            "text": " If you had access to this type of function, this Q function, I think you could actually",
            "tokens": [
                50780,
                759,
                291,
                632,
                2105,
                281,
                341,
                2010,
                295,
                2445,
                11,
                341,
                1249,
                2445,
                11,
                286,
                519,
                291,
                727,
                767,
                51000
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 197,
            "seek": 82298,
            "start": 835.7,
            "end": 837.98,
            "text": " perform a lot of tasks right off the bat, right?",
            "tokens": [
                51000,
                2042,
                257,
                688,
                295,
                9608,
                558,
                766,
                264,
                7362,
                11,
                558,
                30,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 198,
            "seek": 82298,
            "start": 837.98,
            "end": 844.22,
            "text": " So if you wanted to, for example, understand how to what actions to take in a particular",
            "tokens": [
                51114,
                407,
                498,
                291,
                1415,
                281,
                11,
                337,
                1365,
                11,
                1223,
                577,
                281,
                437,
                5909,
                281,
                747,
                294,
                257,
                1729,
                51426
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 199,
            "seek": 82298,
            "start": 844.22,
            "end": 845.22,
            "text": " state.",
            "tokens": [
                51426,
                1785,
                13,
                51476
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 200,
            "seek": 82298,
            "start": 845.22,
            "end": 847.98,
            "text": " And let's suppose I gave you this magical Q function.",
            "tokens": [
                51476,
                400,
                718,
                311,
                7297,
                286,
                2729,
                291,
                341,
                12066,
                1249,
                2445,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 201,
            "seek": 82298,
            "start": 847.98,
            "end": 852.94,
            "text": " Does anyone have any ideas of how you could transform that Q function to directly infer",
            "tokens": [
                51614,
                4402,
                2878,
                362,
                604,
                3487,
                295,
                577,
                291,
                727,
                4088,
                300,
                1249,
                2445,
                281,
                3838,
                13596,
                51862
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15302062616115664,
            "compression_ratio": 1.7326388888888888,
            "no_speech_prob": 0.011497687548398972
        },
        {
            "id": 202,
            "seek": 85294,
            "start": 853.1,
            "end": 855.6600000000001,
            "text": " what action should be taken?",
            "tokens": [
                50372,
                437,
                3069,
                820,
                312,
                2726,
                30,
                50500
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 203,
            "seek": 85294,
            "start": 855.6600000000001,
            "end": 856.6600000000001,
            "text": " Yep.",
            "tokens": [
                50500,
                7010,
                13,
                50550
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 204,
            "seek": 85294,
            "start": 856.6600000000001,
            "end": 861.58,
            "text": " Given a state, you can look at your possible action space and pick the one that gives you",
            "tokens": [
                50550,
                18600,
                257,
                1785,
                11,
                291,
                393,
                574,
                412,
                428,
                1944,
                3069,
                1901,
                293,
                1888,
                264,
                472,
                300,
                2709,
                291,
                50796
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 205,
            "seek": 85294,
            "start": 861.58,
            "end": 863.1,
            "text": " the highest Q values.",
            "tokens": [
                50796,
                264,
                6343,
                1249,
                4190,
                13,
                50872
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 206,
            "seek": 85294,
            "start": 863.1,
            "end": 864.1,
            "text": " Exactly.",
            "tokens": [
                50872,
                7587,
                13,
                50922
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 207,
            "seek": 85294,
            "start": 864.1,
            "end": 865.1,
            "text": " So that's exactly right.",
            "tokens": [
                50922,
                407,
                300,
                311,
                2293,
                558,
                13,
                50972
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 208,
            "seek": 85294,
            "start": 865.1,
            "end": 870.3000000000001,
            "text": " So just to repeat that one more time, the Q function tells us for any possible action,",
            "tokens": [
                50972,
                407,
                445,
                281,
                7149,
                300,
                472,
                544,
                565,
                11,
                264,
                1249,
                2445,
                5112,
                505,
                337,
                604,
                1944,
                3069,
                11,
                51232
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 209,
            "seek": 85294,
            "start": 870.3000000000001,
            "end": 871.3000000000001,
            "text": " right?",
            "tokens": [
                51232,
                558,
                30,
                51282
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        }
    ],
    [
        {
            "id": 210,
            "seek": 85294,
            "start": 871.3000000000001,
            "end": 874.7800000000001,
            "text": " What is the expected reward for that action to be taken?",
            "tokens": [
                51282,
                708,
                307,
                264,
                5176,
                7782,
                337,
                300,
                3069,
                281,
                312,
                2726,
                30,
                51456
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 211,
            "seek": 85294,
            "start": 874.7800000000001,
            "end": 881.1,
            "text": " So if we wanted to take a specific action given a specific state, ultimately we need to",
            "tokens": [
                51456,
                407,
                498,
                321,
                1415,
                281,
                747,
                257,
                2685,
                3069,
                2212,
                257,
                2685,
                1785,
                11,
                6284,
                321,
                643,
                281,
                51772
            ],
            "temperature": 0.0,
            "avg_logprob": -0.27505585999615423,
            "compression_ratio": 1.7272727272727273,
            "no_speech_prob": 0.001700085704214871
        },
        {
            "id": 212,
            "seek": 88110,
            "start": 881.1,
            "end": 883.98,
            "text": " figure out which action is the best action.",
            "tokens": [
                50364,
                2573,
                484,
                597,
                3069,
                307,
                264,
                1151,
                3069,
                13,
                50508
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 213,
            "seek": 88110,
            "start": 883.98,
            "end": 890.02,
            "text": " The way we do that from a Q function is simply to pick the action that will maximize our",
            "tokens": [
                50508,
                440,
                636,
                321,
                360,
                300,
                490,
                257,
                1249,
                2445,
                307,
                2935,
                281,
                1888,
                264,
                3069,
                300,
                486,
                19874,
                527,
                50810
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 214,
            "seek": 88110,
            "start": 890.02,
            "end": 891.02,
            "text": " future reward.",
            "tokens": [
                50810,
                2027,
                7782,
                13,
                50860
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 215,
            "seek": 88110,
            "start": 891.02,
            "end": 894.46,
            "text": " And we can simply pry out number one.",
            "tokens": [
                50860,
                400,
                321,
                393,
                2935,
                41902,
                484,
                1230,
                472,
                13,
                51032
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 216,
            "seek": 88110,
            "start": 894.46,
            "end": 898.86,
            "text": " If we have a discrete action space, we can simply try out all possible actions, compute",
            "tokens": [
                51032,
                759,
                321,
                362,
                257,
                27706,
                3069,
                1901,
                11,
                321,
                393,
                2935,
                853,
                484,
                439,
                1944,
                5909,
                11,
                14722,
                51252
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 217,
            "seek": 88110,
            "start": 898.86,
            "end": 903.1,
            "text": " their Q value for every single possible action based on the state that we currently find",
            "tokens": [
                51252,
                641,
                1249,
                2158,
                337,
                633,
                2167,
                1944,
                3069,
                2361,
                322,
                264,
                1785,
                300,
                321,
                4362,
                915,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 218,
            "seek": 88110,
            "start": 903.1,
            "end": 904.1,
            "text": " ourselves in.",
            "tokens": [
                51464,
                4175,
                294,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 219,
            "seek": 88110,
            "start": 904.1,
            "end": 909.94,
            "text": " And then we pick the action that is going to result in the highest Q value.",
            "tokens": [
                51514,
                400,
                550,
                321,
                1888,
                264,
                3069,
                300,
                307,
                516,
                281,
                1874,
                294,
                264,
                6343,
                1249,
                2158,
                13,
                51806
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13775035313197545,
            "compression_ratio": 1.808,
            "no_speech_prob": 0.004132146947085857
        },
        {
            "id": 220,
            "seek": 90994,
            "start": 909.94,
            "end": 913.94,
            "text": " If we have a continuous action space, maybe we do something a bit more intelligent, maybe",
            "tokens": [
                50364,
                759,
                321,
                362,
                257,
                10957,
                3069,
                1901,
                11,
                1310,
                321,
                360,
                746,
                257,
                857,
                544,
                13232,
                11,
                1310,
                50564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 221,
            "seek": 90994,
            "start": 913.94,
            "end": 919.0200000000001,
            "text": " following the gradients along this Q value curve and maximizing it as part of an optimization",
            "tokens": [
                50564,
                3480,
                264,
                2771,
                2448,
                2051,
                341,
                1249,
                2158,
                7605,
                293,
                5138,
                3319,
                309,
                382,
                644,
                295,
                364,
                19618,
                50818
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 222,
            "seek": 90994,
            "start": 919.0200000000001,
            "end": 920.86,
            "text": " procedure.",
            "tokens": [
                50818,
                10747,
                13,
                50910
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 223,
            "seek": 90994,
            "start": 920.86,
            "end": 926.62,
            "text": " But generally, in this lecture, what I want to focus on is actually how we can obtain this",
            "tokens": [
                50910,
                583,
                5101,
                11,
                294,
                341,
                7991,
                11,
                437,
                286,
                528,
                281,
                1879,
                322,
                307,
                767,
                577,
                321,
                393,
                12701,
                341,
                51198
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 224,
            "seek": 90994,
            "start": 926.62,
            "end": 928.74,
            "text": " Q function to start with, right?",
            "tokens": [
                51198,
                1249,
                2445,
                281,
                722,
                365,
                11,
                558,
                30,
                51304
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 225,
            "seek": 90994,
            "start": 928.74,
            "end": 932.2600000000001,
            "text": " I kind of skipped a lot of steps in that last slide where I just said, let's suppose I",
            "tokens": [
                51304,
                286,
                733,
                295,
                30193,
                257,
                688,
                295,
                4439,
                294,
                300,
                1036,
                4137,
                689,
                286,
                445,
                848,
                11,
                718,
                311,
                7297,
                286,
                51480
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 226,
            "seek": 90994,
            "start": 932.2600000000001,
            "end": 934.1,
            "text": " give you this magical Q function.",
            "tokens": [
                51480,
                976,
                291,
                341,
                12066,
                1249,
                2445,
                13,
                51572
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 227,
            "seek": 90994,
            "start": 934.1,
            "end": 936.2600000000001,
            "text": " How can you determine what action to take?",
            "tokens": [
                51572,
                1012,
                393,
                291,
                6997,
                437,
                3069,
                281,
                747,
                30,
                51680
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 228,
            "seek": 90994,
            "start": 936.2600000000001,
            "end": 938.1800000000001,
            "text": " But in reality, we're not given that Q function.",
            "tokens": [
                51680,
                583,
                294,
                4103,
                11,
                321,
                434,
                406,
                2212,
                300,
                1249,
                2445,
                13,
                51776
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15034572460033274,
            "compression_ratio": 1.7019230769230769,
            "no_speech_prob": 0.00178143463563174
        },
        {
            "id": 229,
            "seek": 93818,
            "start": 938.18,
            "end": 940.9799999999999,
            "text": " We have to learn that Q function using deep learning.",
            "tokens": [
                50364,
                492,
                362,
                281,
                1466,
                300,
                1249,
                2445,
                1228,
                2452,
                2539,
                13,
                50504
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 230,
            "seek": 93818,
            "start": 940.9799999999999,
            "end": 943.9,
            "text": " And that's what today's lecture is going to be talking about primarily.",
            "tokens": [
                50504,
                400,
                300,
                311,
                437,
                965,
                311,
                7991,
                307,
                516,
                281,
                312,
                1417,
                466,
                10029,
                13,
                50650
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 231,
            "seek": 93818,
            "start": 943.9,
            "end": 948.4599999999999,
            "text": " First of all, how can we construct and learn that Q function from data?",
            "tokens": [
                50650,
                2386,
                295,
                439,
                11,
                577,
                393,
                321,
                7690,
                293,
                1466,
                300,
                1249,
                2445,
                490,
                1412,
                30,
                50878
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 232,
            "seek": 93818,
            "start": 948.4599999999999,
            "end": 953.14,
            "text": " And then, of course, the final step is use that Q function to take some actions in the",
            "tokens": [
                50878,
                400,
                550,
                11,
                295,
                1164,
                11,
                264,
                2572,
                1823,
                307,
                764,
                300,
                1249,
                2445,
                281,
                747,
                512,
                5909,
                294,
                264,
                51112
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 233,
            "seek": 93818,
            "start": 953.14,
            "end": 954.14,
            "text": " real world.",
            "tokens": [
                51112,
                957,
                1002,
                13,
                51162
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 234,
            "seek": 93818,
            "start": 954.14,
            "end": 957.9399999999999,
            "text": " And broadly speaking, there are two classes of reinforcement learning algorithms that",
            "tokens": [
                51162,
                400,
                19511,
                4124,
                11,
                456,
                366,
                732,
                5359,
                295,
                29280,
                2539,
                14642,
                300,
                51352
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 235,
            "seek": 93818,
            "start": 957.9399999999999,
            "end": 960.66,
            "text": " we're going to briefly touch on as part of today's lecture.",
            "tokens": [
                51352,
                321,
                434,
                516,
                281,
                10515,
                2557,
                322,
                382,
                644,
                295,
                965,
                311,
                7991,
                13,
                51488
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 236,
            "seek": 93818,
            "start": 960.66,
            "end": 963.18,
            "text": " The first class is what's going to be called value learning.",
            "tokens": [
                51488,
                440,
                700,
                1508,
                307,
                437,
                311,
                516,
                281,
                312,
                1219,
                2158,
                2539,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 237,
            "seek": 93818,
            "start": 963.18,
            "end": 965.9,
            "text": " And that's exactly this process that we've just talked about.",
            "tokens": [
                51614,
                400,
                300,
                311,
                2293,
                341,
                1399,
                300,
                321,
                600,
                445,
                2825,
                466,
                13,
                51750
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13918385989424112,
            "compression_ratio": 1.8708609271523178,
            "no_speech_prob": 0.0015002033906057477
        },
        {
            "id": 238,
            "seek": 96590,
            "start": 965.9,
            "end": 970.9,
            "text": " The second class of algorithms, which we'll touch on right at the end of today's lecture,",
            "tokens": [
                50364,
                440,
                1150,
                1508,
                295,
                14642,
                11,
                597,
                321,
                603,
                2557,
                322,
                558,
                412,
                264,
                917,
                295,
                965,
                311,
                7991,
                11,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.6546101127703166,
            "compression_ratio": 1.995049504950495,
            "no_speech_prob": 0.0023223210591822863
        },
        {
            "id": 239,
            "seek": 96590,
            "start": 970.9,
            "end": 973.9,
            "text": " is kind of a different framing of the same approach.",
            "tokens": [
                50614,
                307,
                733,
                295,
                257,
                819,
                28971,
                295,
                264,
                912,
                3109,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.6546101127703166,
            "compression_ratio": 1.995049504950495,
            "no_speech_prob": 0.0023223210591822863
        }
    ],
    [
        {
            "id": 240,
            "seek": 96590,
            "start": 973.9,
            "end": 978.9,
            "text": " But instead of first optimizing the Q function and finding the Q value and then using that",
            "tokens": [
                50764,
                583,
                2602,
                295,
                700,
                40425,
                264,
                1249,
                2445,
                293,
                5006,
                264,
                1249,
                2158,
                293,
                550,
                1228,
                300,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.6546101127703166,
            "compression_ratio": 1.995049504950495,
            "no_speech_prob": 0.0023223210591822863
        },
        {
            "id": 241,
            "seek": 96590,
            "start": 978.9,
            "end": 983.9,
            "text": " Q function to optimize our value, we're going to find the first class of algorithms.",
            "tokens": [
                51014,
                1249,
                2445,
                281,
                19719,
                527,
                2158,
                11,
                321,
                434,
                516,
                281,
                915,
                264,
                700,
                1508,
                295,
                14642,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.6546101127703166,
            "compression_ratio": 1.995049504950495,
            "no_speech_prob": 0.0023223210591822863
        },
        {
            "id": 242,
            "seek": 96590,
            "start": 983.9,
            "end": 988.9,
            "text": " And then, we're going to find the first class of algorithms that we're going to find",
            "tokens": [
                51264,
                400,
                550,
                11,
                321,
                434,
                516,
                281,
                915,
                264,
                700,
                1508,
                295,
                14642,
                300,
                321,
                434,
                516,
                281,
                915,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.6546101127703166,
            "compression_ratio": 1.995049504950495,
            "no_speech_prob": 0.0023223210591822863
        },
        {
            "id": 243,
            "seek": 98890,
            "start": 988.9,
            "end": 993.9,
            "text": " to take, but instead of first optimizing the Q function and finding the Q value and then",
            "tokens": [
                50364,
                281,
                747,
                11,
                457,
                2602,
                295,
                700,
                40425,
                264,
                1249,
                2445,
                293,
                5006,
                264,
                1249,
                2158,
                293,
                550,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 244,
            "seek": 98890,
            "start": 993.9,
            "end": 999.9,
            "text": " using that Q function to optimize our actions, what if we just try to directly optimize our",
            "tokens": [
                50614,
                1228,
                300,
                1249,
                2445,
                281,
                19719,
                527,
                5909,
                11,
                437,
                498,
                321,
                445,
                853,
                281,
                3838,
                19719,
                527,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 245,
            "seek": 98890,
            "start": 999.9,
            "end": 1004.9,
            "text": " policy, which is what action to take based on a particular state that we find ourselves",
            "tokens": [
                50914,
                3897,
                11,
                597,
                307,
                437,
                3069,
                281,
                747,
                2361,
                322,
                257,
                1729,
                1785,
                300,
                321,
                915,
                4175,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 246,
            "seek": 98890,
            "start": 1004.9,
            "end": 1005.9,
            "text": " in?",
            "tokens": [
                51164,
                294,
                30,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 247,
            "seek": 98890,
            "start": 1005.9,
            "end": 1010.9,
            "text": " If we do that, if we can obtain this function, right, then we can directly sample from that",
            "tokens": [
                51214,
                759,
                321,
                360,
                300,
                11,
                498,
                321,
                393,
                12701,
                341,
                2445,
                11,
                558,
                11,
                550,
                321,
                393,
                3838,
                6889,
                490,
                300,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 248,
            "seek": 98890,
            "start": 1010.9,
            "end": 1013.9,
            "text": " policy distribution to obtain the optimal action.",
            "tokens": [
                51464,
                3897,
                7316,
                281,
                12701,
                264,
                16252,
                3069,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 249,
            "seek": 98890,
            "start": 1013.9,
            "end": 1016.9,
            "text": " We'll talk more details about that later in the lecture.",
            "tokens": [
                51614,
                492,
                603,
                751,
                544,
                4365,
                466,
                300,
                1780,
                294,
                264,
                7991,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14611637592315674,
            "compression_ratio": 1.8543307086614174,
            "no_speech_prob": 0.028851764276623726
        },
        {
            "id": 250,
            "seek": 101690,
            "start": 1016.9,
            "end": 1021.9,
            "text": " First, let's cover this first class of approaches, which is Q learning approaches, and we'll build up",
            "tokens": [
                50364,
                2386,
                11,
                718,
                311,
                2060,
                341,
                700,
                1508,
                295,
                11587,
                11,
                597,
                307,
                1249,
                2539,
                11587,
                11,
                293,
                321,
                603,
                1322,
                493,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 251,
            "seek": 101690,
            "start": 1021.9,
            "end": 1026.9,
            "text": " that intuition and that knowledge onto the second part of policy learning.",
            "tokens": [
                50614,
                300,
                24002,
                293,
                300,
                3601,
                3911,
                264,
                1150,
                644,
                295,
                3897,
                2539,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 252,
            "seek": 101690,
            "start": 1026.9,
            "end": 1031.9,
            "text": " So maybe let's start by just digging a bit deeper into the Q function specifically,",
            "tokens": [
                50864,
                407,
                1310,
                718,
                311,
                722,
                538,
                445,
                17343,
                257,
                857,
                7731,
                666,
                264,
                1249,
                2445,
                4682,
                11,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 253,
            "seek": 101690,
            "start": 1031.9,
            "end": 1035.9,
            "text": " just to start to understand how we could estimate this in the beginning.",
            "tokens": [
                51114,
                445,
                281,
                722,
                281,
                1223,
                577,
                321,
                727,
                12539,
                341,
                294,
                264,
                2863,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 254,
            "seek": 101690,
            "start": 1035.9,
            "end": 1037.9,
            "text": " So first, let me introduce this game.",
            "tokens": [
                51314,
                407,
                700,
                11,
                718,
                385,
                5366,
                341,
                1216,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 255,
            "seek": 101690,
            "start": 1037.9,
            "end": 1039.9,
            "text": " Maybe some of you recognize this.",
            "tokens": [
                51414,
                2704,
                512,
                295,
                291,
                5521,
                341,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 256,
            "seek": 101690,
            "start": 1039.9,
            "end": 1042.9,
            "text": " This is the game of called Atari Breakout.",
            "tokens": [
                51514,
                639,
                307,
                264,
                1216,
                295,
                1219,
                41381,
                16925,
                346,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12596182469968442,
            "compression_ratio": 1.6779026217228465,
            "no_speech_prob": 0.002018062165006995
        },
        {
            "id": 257,
            "seek": 104290,
            "start": 1042.9,
            "end": 1048.9,
            "text": " The game here is essentially one where the agent is able to move left or right, this paddle on the",
            "tokens": [
                50364,
                440,
                1216,
                510,
                307,
                4476,
                472,
                689,
                264,
                9461,
                307,
                1075,
                281,
                1286,
                1411,
                420,
                558,
                11,
                341,
                31834,
                322,
                264,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 258,
            "seek": 104290,
            "start": 1048.9,
            "end": 1054.9,
            "text": " bottom, left or right, and the objective is to move it in a way that this ball that's coming down",
            "tokens": [
                50664,
                2767,
                11,
                1411,
                420,
                558,
                11,
                293,
                264,
                10024,
                307,
                281,
                1286,
                309,
                294,
                257,
                636,
                300,
                341,
                2594,
                300,
                311,
                1348,
                760,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 259,
            "seek": 104290,
            "start": 1054.9,
            "end": 1060.9,
            "text": " towards the bottom of the screen can be bounced off of your paddle, reflected back up, and essentially",
            "tokens": [
                50964,
                3030,
                264,
                2767,
                295,
                264,
                2568,
                393,
                312,
                46482,
                766,
                295,
                428,
                31834,
                11,
                15502,
                646,
                493,
                11,
                293,
                4476,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 260,
            "seek": 104290,
            "start": 1060.9,
            "end": 1065.9,
            "text": " you want to break out, right, reflect that ball back up to the top of the screen towards the rainbow",
            "tokens": [
                51264,
                291,
                528,
                281,
                1821,
                484,
                11,
                558,
                11,
                5031,
                300,
                2594,
                646,
                493,
                281,
                264,
                1192,
                295,
                264,
                2568,
                3030,
                264,
                18526,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 261,
            "seek": 104290,
            "start": 1065.9,
            "end": 1067.9,
            "text": " portion, and keep breaking off.",
            "tokens": [
                51514,
                8044,
                11,
                293,
                1066,
                7697,
                766,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 262,
            "seek": 104290,
            "start": 1067.9,
            "end": 1070.9,
            "text": " Every time you hit a pixel on the top of the screen, you break off that pixel.",
            "tokens": [
                51614,
                2048,
                565,
                291,
                2045,
                257,
                19261,
                322,
                264,
                1192,
                295,
                264,
                2568,
                11,
                291,
                1821,
                766,
                300,
                19261,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.098036561693464,
            "compression_ratio": 1.9578544061302683,
            "no_speech_prob": 0.15521737933158875
        },
        {
            "id": 263,
            "seek": 107090,
            "start": 1070.9,
            "end": 1075.9,
            "text": " The objective of the game is to basically eliminate all of those rainbow pixels, right?",
            "tokens": [
                50364,
                440,
                10024,
                295,
                264,
                1216,
                307,
                281,
                1936,
                13819,
                439,
                295,
                729,
                18526,
                18668,
                11,
                558,
                30,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08610241813997252,
            "compression_ratio": 1.712686567164179,
            "no_speech_prob": 0.007450993172824383
        },
        {
            "id": 264,
            "seek": 107090,
            "start": 1075.9,
            "end": 1080.9,
            "text": " So you want to keep hitting that ball against the top of the screen until you remove all the pixels.",
            "tokens": [
                50614,
                407,
                291,
                528,
                281,
                1066,
                8850,
                300,
                2594,
                1970,
                264,
                1192,
                295,
                264,
                2568,
                1826,
                291,
                4159,
                439,
                264,
                18668,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08610241813997252,
            "compression_ratio": 1.712686567164179,
            "no_speech_prob": 0.007450993172824383
        },
        {
            "id": 265,
            "seek": 107090,
            "start": 1080.9,
            "end": 1087.9,
            "text": " Now, the Q function tells us, you know, the expected total return, or the total reward,",
            "tokens": [
                50864,
                823,
                11,
                264,
                1249,
                2445,
                5112,
                505,
                11,
                291,
                458,
                11,
                264,
                5176,
                3217,
                2736,
                11,
                420,
                264,
                3217,
                7782,
                11,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08610241813997252,
            "compression_ratio": 1.712686567164179,
            "no_speech_prob": 0.007450993172824383
        },
        {
            "id": 266,
            "seek": 107090,
            "start": 1087.9,
            "end": 1093.9,
            "text": " that we can expect based on a given state and action pair that we may find ourselves in this game.",
            "tokens": [
                51214,
                300,
                321,
                393,
                2066,
                2361,
                322,
                257,
                2212,
                1785,
                293,
                3069,
                6119,
                300,
                321,
                815,
                915,
                4175,
                294,
                341,
                1216,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08610241813997252,
            "compression_ratio": 1.712686567164179,
            "no_speech_prob": 0.007450993172824383
        },
        {
            "id": 267,
            "seek": 107090,
            "start": 1093.9,
            "end": 1099.9,
            "text": " Now, the first point I want to make here is that sometimes, even for us, as humans,",
            "tokens": [
                51514,
                823,
                11,
                264,
                700,
                935,
                286,
                528,
                281,
                652,
                510,
                307,
                300,
                2171,
                11,
                754,
                337,
                505,
                11,
                382,
                6255,
                11,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08610241813997252,
            "compression_ratio": 1.712686567164179,
            "no_speech_prob": 0.007450993172824383
        },
        {
            "id": 268,
            "seek": 109990,
            "start": 1099.9,
            "end": 1104.9,
            "text": " to understand what the Q value should be is sometimes quite unintuitive, right?",
            "tokens": [
                50364,
                281,
                1223,
                437,
                264,
                1249,
                2158,
                820,
                312,
                307,
                2171,
                1596,
                29466,
                48314,
                11,
                558,
                30,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06581861145642338,
            "compression_ratio": 1.544,
            "no_speech_prob": 0.0022850611712783575
        },
        {
            "id": 269,
            "seek": 109990,
            "start": 1104.9,
            "end": 1109.9,
            "text": " So here's one example. Let's say we find these two state action pairs, right?",
            "tokens": [
                50614,
                407,
                510,
                311,
                472,
                1365,
                13,
                961,
                311,
                584,
                321,
                915,
                613,
                732,
                1785,
                3069,
                15494,
                11,
                558,
                30,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06581861145642338,
            "compression_ratio": 1.544,
            "no_speech_prob": 0.0022850611712783575
        }
    ],
    [
        {
            "id": 270,
            "seek": 109990,
            "start": 1109.9,
            "end": 1113.9,
            "text": " Here is A and B, two different options that we can be presented with in this game.",
            "tokens": [
                50864,
                1692,
                307,
                316,
                293,
                363,
                11,
                732,
                819,
                3956,
                300,
                321,
                393,
                312,
                8212,
                365,
                294,
                341,
                1216,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06581861145642338,
            "compression_ratio": 1.544,
            "no_speech_prob": 0.0022850611712783575
        },
        {
            "id": 271,
            "seek": 109990,
            "start": 1113.9,
            "end": 1117.9,
            "text": " A, the ball is coming straight down towards us. That's our state.",
            "tokens": [
                51064,
                316,
                11,
                264,
                2594,
                307,
                1348,
                2997,
                760,
                3030,
                505,
                13,
                663,
                311,
                527,
                1785,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06581861145642338,
            "compression_ratio": 1.544,
            "no_speech_prob": 0.0022850611712783575
        },
        {
            "id": 272,
            "seek": 109990,
            "start": 1117.9,
            "end": 1122.9,
            "text": " Our action is to do nothing and simply reflect that ball back up vertically up.",
            "tokens": [
                51264,
                2621,
                3069,
                307,
                281,
                360,
                1825,
                293,
                2935,
                5031,
                300,
                2594,
                646,
                493,
                28450,
                493,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06581861145642338,
            "compression_ratio": 1.544,
            "no_speech_prob": 0.0022850611712783575
        },
        {
            "id": 273,
            "seek": 112290,
            "start": 1122.9,
            "end": 1128.9,
            "text": " The second situation, the state is basically that the ball is coming slightly at an angle,",
            "tokens": [
                50364,
                440,
                1150,
                2590,
                11,
                264,
                1785,
                307,
                1936,
                300,
                264,
                2594,
                307,
                1348,
                4748,
                412,
                364,
                5802,
                11,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07770944942127575,
            "compression_ratio": 1.6513409961685823,
            "no_speech_prob": 0.0384051688015461
        },
        {
            "id": 274,
            "seek": 112290,
            "start": 1128.9,
            "end": 1136.9,
            "text": " we're not quite underneath it yet, and we need to move towards it and actually hit that ball in a way that, you know,",
            "tokens": [
                50664,
                321,
                434,
                406,
                1596,
                7223,
                309,
                1939,
                11,
                293,
                321,
                643,
                281,
                1286,
                3030,
                309,
                293,
                767,
                2045,
                300,
                2594,
                294,
                257,
                636,
                300,
                11,
                291,
                458,
                11,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07770944942127575,
            "compression_ratio": 1.6513409961685823,
            "no_speech_prob": 0.0384051688015461
        },
        {
            "id": 275,
            "seek": 112290,
            "start": 1136.9,
            "end": 1139.9,
            "text": " we'll make it and not miss it, hopefully, right?",
            "tokens": [
                51064,
                321,
                603,
                652,
                309,
                293,
                406,
                1713,
                309,
                11,
                4696,
                11,
                558,
                30,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07770944942127575,
            "compression_ratio": 1.6513409961685823,
            "no_speech_prob": 0.0384051688015461
        },
        {
            "id": 276,
            "seek": 112290,
            "start": 1139.9,
            "end": 1142.9,
            "text": " So hopefully that ball doesn't pass below us, then the game would be over.",
            "tokens": [
                51214,
                407,
                4696,
                300,
                2594,
                1177,
                380,
                1320,
                2507,
                505,
                11,
                550,
                264,
                1216,
                576,
                312,
                670,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07770944942127575,
            "compression_ratio": 1.6513409961685823,
            "no_speech_prob": 0.0384051688015461
        },
        {
            "id": 277,
            "seek": 112290,
            "start": 1142.9,
            "end": 1149.9,
            "text": " Can you imagine, you know, which of these two options might have a higher Q value for the network?",
            "tokens": [
                51364,
                1664,
                291,
                3811,
                11,
                291,
                458,
                11,
                597,
                295,
                613,
                732,
                3956,
                1062,
                362,
                257,
                2946,
                1249,
                2158,
                337,
                264,
                3209,
                30,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07770944942127575,
            "compression_ratio": 1.6513409961685823,
            "no_speech_prob": 0.0384051688015461
        },
        {
            "id": 278,
            "seek": 114990,
            "start": 1149.9,
            "end": 1156.9,
            "text": " Which one would result in a greater reward for the neural network or for the agent?",
            "tokens": [
                50364,
                3013,
                472,
                576,
                1874,
                294,
                257,
                5044,
                7782,
                337,
                264,
                18161,
                3209,
                420,
                337,
                264,
                9461,
                30,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12359604154314313,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.0800757110118866
        },
        {
            "id": 279,
            "seek": 114990,
            "start": 1156.9,
            "end": 1162.9,
            "text": " So how many people believe A would result in a higher return?",
            "tokens": [
                50714,
                407,
                577,
                867,
                561,
                1697,
                316,
                576,
                1874,
                294,
                257,
                2946,
                2736,
                30,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12359604154314313,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.0800757110118866
        },
        {
            "id": 280,
            "seek": 114990,
            "start": 1162.9,
            "end": 1165.9,
            "text": " How about B?",
            "tokens": [
                51014,
                1012,
                466,
                363,
                30,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12359604154314313,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.0800757110118866
        },
        {
            "id": 281,
            "seek": 114990,
            "start": 1165.9,
            "end": 1171.9,
            "text": " How about someone who picked B? Can you tell me why B?",
            "tokens": [
                51164,
                1012,
                466,
                1580,
                567,
                6183,
                363,
                30,
                1664,
                291,
                980,
                385,
                983,
                363,
                30,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12359604154314313,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.0800757110118866
        },
        {
            "id": 282,
            "seek": 114990,
            "start": 1171.9,
            "end": 1175.9,
            "text": " Why an agency? You're actually doing something?",
            "tokens": [
                51464,
                1545,
                364,
                7934,
                30,
                509,
                434,
                767,
                884,
                746,
                30,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12359604154314313,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.0800757110118866
        },
        {
            "id": 283,
            "seek": 117590,
            "start": 1175.9,
            "end": 1178.9,
            "text": " Okay. Yeah. Have a more?",
            "tokens": [
                50364,
                1033,
                13,
                865,
                13,
                3560,
                257,
                544,
                30,
                50514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 284,
            "seek": 117590,
            "start": 1178.9,
            "end": 1182.9,
            "text": " For A, you only have like the maximum you can take off is like one,",
            "tokens": [
                50514,
                1171,
                316,
                11,
                291,
                787,
                362,
                411,
                264,
                6674,
                291,
                393,
                747,
                766,
                307,
                411,
                472,
                11,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 285,
            "seek": 117590,
            "start": 1182.9,
            "end": 1185.9,
            "text": " because after you reflect your automatic comes back down,",
            "tokens": [
                50714,
                570,
                934,
                291,
                5031,
                428,
                12509,
                1487,
                646,
                760,
                11,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 286,
            "seek": 117590,
            "start": 1185.9,
            "end": 1189.9,
            "text": " but then B can bounce around, and there's more than that, what happens?",
            "tokens": [
                50864,
                457,
                550,
                363,
                393,
                15894,
                926,
                11,
                293,
                456,
                311,
                544,
                813,
                300,
                11,
                437,
                2314,
                30,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 287,
            "seek": 117590,
            "start": 1189.9,
            "end": 1193.9,
            "text": " Exactly. And actually, there's a very interesting thing.",
            "tokens": [
                51064,
                7587,
                13,
                400,
                767,
                11,
                456,
                311,
                257,
                588,
                1880,
                551,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 288,
            "seek": 117590,
            "start": 1193.9,
            "end": 1198.9,
            "text": " So when I first saw this, actually, it was very unintuitive for me.",
            "tokens": [
                51264,
                407,
                562,
                286,
                700,
                1866,
                341,
                11,
                767,
                11,
                309,
                390,
                588,
                29466,
                48314,
                337,
                385,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 289,
            "seek": 117590,
            "start": 1198.9,
            "end": 1201.9,
            "text": " Why A is actually working much worse than B, but in general,",
            "tokens": [
                51514,
                1545,
                316,
                307,
                767,
                1364,
                709,
                5324,
                813,
                363,
                11,
                457,
                294,
                2674,
                11,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2781260550559104,
            "compression_ratio": 1.5632183908045978,
            "no_speech_prob": 0.025113634765148163
        },
        {
            "id": 290,
            "seek": 120190,
            "start": 1201.9,
            "end": 1206.9,
            "text": " this very conservative action of B, you're kind of exactly like you said,",
            "tokens": [
                50364,
                341,
                588,
                13780,
                3069,
                295,
                363,
                11,
                291,
                434,
                733,
                295,
                2293,
                411,
                291,
                848,
                11,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 291,
            "seek": 120190,
            "start": 1206.9,
            "end": 1210.9,
            "text": " the two answers we're implying, is that A is a very conservative action.",
            "tokens": [
                50614,
                264,
                732,
                6338,
                321,
                434,
                704,
                7310,
                11,
                307,
                300,
                316,
                307,
                257,
                588,
                13780,
                3069,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 292,
            "seek": 120190,
            "start": 1210.9,
            "end": 1212.9,
            "text": " You're kind of only going up and down.",
            "tokens": [
                50814,
                509,
                434,
                733,
                295,
                787,
                516,
                493,
                293,
                760,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 293,
            "seek": 120190,
            "start": 1212.9,
            "end": 1215.9,
            "text": " It will achieve a good reward. It will solve the game, right?",
            "tokens": [
                50914,
                467,
                486,
                4584,
                257,
                665,
                7782,
                13,
                467,
                486,
                5039,
                264,
                1216,
                11,
                558,
                30,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 294,
            "seek": 120190,
            "start": 1215.9,
            "end": 1218.9,
            "text": " In fact, it solves the game exactly like this right here.",
            "tokens": [
                51064,
                682,
                1186,
                11,
                309,
                39890,
                264,
                1216,
                2293,
                411,
                341,
                558,
                510,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 295,
            "seek": 120190,
            "start": 1218.9,
            "end": 1221.9,
            "text": " You can see, in general, this action is going to be quite conservative.",
            "tokens": [
                51214,
                509,
                393,
                536,
                11,
                294,
                2674,
                11,
                341,
                3069,
                307,
                516,
                281,
                312,
                1596,
                13780,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 296,
            "seek": 120190,
            "start": 1221.9,
            "end": 1224.9,
            "text": " It's just bouncing up, hitting one point at a time from the top,",
            "tokens": [
                51364,
                467,
                311,
                445,
                27380,
                493,
                11,
                8850,
                472,
                935,
                412,
                257,
                565,
                490,
                264,
                1192,
                11,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 297,
            "seek": 120190,
            "start": 1224.9,
            "end": 1228.9,
            "text": " and breaking off very slowly the board that you can see here.",
            "tokens": [
                51514,
                293,
                7697,
                766,
                588,
                5692,
                264,
                3150,
                300,
                291,
                393,
                536,
                510,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09675622342237786,
            "compression_ratio": 1.8597785977859778,
            "no_speech_prob": 0.01968342624604702
        },
        {
            "id": 298,
            "seek": 122890,
            "start": 1228.9,
            "end": 1232.9,
            "text": " But in general, you see the part of the board that's being broken off",
            "tokens": [
                50364,
                583,
                294,
                2674,
                11,
                291,
                536,
                264,
                644,
                295,
                264,
                3150,
                300,
                311,
                885,
                5463,
                766,
                50564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 299,
            "seek": 122890,
            "start": 1232.9,
            "end": 1234.9,
            "text": " is towards the center of the board, right?",
            "tokens": [
                50564,
                307,
                3030,
                264,
                3056,
                295,
                264,
                3150,
                11,
                558,
                30,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        }
    ],
    [
        {
            "id": 300,
            "seek": 122890,
            "start": 1234.9,
            "end": 1236.9,
            "text": " Not much on the edges of the board.",
            "tokens": [
                50664,
                1726,
                709,
                322,
                264,
                8819,
                295,
                264,
                3150,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 301,
            "seek": 122890,
            "start": 1236.9,
            "end": 1240.9,
            "text": " If you look at B now, with B, you're kind of having agency,",
            "tokens": [
                50764,
                759,
                291,
                574,
                412,
                363,
                586,
                11,
                365,
                363,
                11,
                291,
                434,
                733,
                295,
                1419,
                7934,
                11,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 302,
            "seek": 122890,
            "start": 1240.9,
            "end": 1242.9,
            "text": " like one of the answers said.",
            "tokens": [
                50964,
                411,
                472,
                295,
                264,
                6338,
                848,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 303,
            "seek": 122890,
            "start": 1242.9,
            "end": 1246.9,
            "text": " You're coming towards the ball, and what that implies is that you're sometimes",
            "tokens": [
                51064,
                509,
                434,
                1348,
                3030,
                264,
                2594,
                11,
                293,
                437,
                300,
                18779,
                307,
                300,
                291,
                434,
                2171,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 304,
            "seek": 122890,
            "start": 1246.9,
            "end": 1250.9,
            "text": " going to actually hit the corner of your paddle and have a very extreme angle",
            "tokens": [
                51264,
                516,
                281,
                767,
                2045,
                264,
                4538,
                295,
                428,
                31834,
                293,
                362,
                257,
                588,
                8084,
                5802,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 305,
            "seek": 122890,
            "start": 1250.9,
            "end": 1253.9,
            "text": " on your paddle and hit the sides of the board as well.",
            "tokens": [
                51464,
                322,
                428,
                31834,
                293,
                2045,
                264,
                4881,
                295,
                264,
                3150,
                382,
                731,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 306,
            "seek": 122890,
            "start": 1253.9,
            "end": 1257.9,
            "text": " And it turns out that the algorithm, the agent, can actually learn that",
            "tokens": [
                51614,
                400,
                309,
                4523,
                484,
                300,
                264,
                9284,
                11,
                264,
                9461,
                11,
                393,
                767,
                1466,
                300,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09001995169598123,
            "compression_ratio": 1.851063829787234,
            "no_speech_prob": 0.020607110112905502
        },
        {
            "id": 307,
            "seek": 125790,
            "start": 1257.9,
            "end": 1261.9,
            "text": " hitting the side of the board can have some kind of unexpected consequences",
            "tokens": [
                50364,
                8850,
                264,
                1252,
                295,
                264,
                3150,
                393,
                362,
                512,
                733,
                295,
                13106,
                10098,
                50564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 308,
            "seek": 125790,
            "start": 1261.9,
            "end": 1263.9,
            "text": " that look like this.",
            "tokens": [
                50564,
                300,
                574,
                411,
                341,
                13,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 309,
            "seek": 125790,
            "start": 1263.9,
            "end": 1265.9,
            "text": " So here you see it trying to enact that policy.",
            "tokens": [
                50664,
                407,
                510,
                291,
                536,
                309,
                1382,
                281,
                25909,
                300,
                3897,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 310,
            "seek": 125790,
            "start": 1265.9,
            "end": 1267.9,
            "text": " It's targeting the sides of the board.",
            "tokens": [
                50764,
                467,
                311,
                17918,
                264,
                4881,
                295,
                264,
                3150,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 311,
            "seek": 125790,
            "start": 1267.9,
            "end": 1270.9,
            "text": " But once it reaches a breakout on the side of the board,",
            "tokens": [
                50864,
                583,
                1564,
                309,
                14235,
                257,
                30067,
                322,
                264,
                1252,
                295,
                264,
                3150,
                11,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 312,
            "seek": 125790,
            "start": 1270.9,
            "end": 1272.9,
            "text": " it found this hack in the solution.",
            "tokens": [
                51014,
                309,
                1352,
                341,
                10339,
                294,
                264,
                3827,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 313,
            "seek": 125790,
            "start": 1272.9,
            "end": 1274.9,
            "text": " We're now breaking off a ton of points.",
            "tokens": [
                51114,
                492,
                434,
                586,
                7697,
                766,
                257,
                2952,
                295,
                2793,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 314,
            "seek": 125790,
            "start": 1274.9,
            "end": 1277.9,
            "text": " So that was a kind of a trick that this neural network learned,",
            "tokens": [
                51214,
                407,
                300,
                390,
                257,
                733,
                295,
                257,
                4282,
                300,
                341,
                18161,
                3209,
                3264,
                11,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 315,
            "seek": 125790,
            "start": 1277.9,
            "end": 1281.9,
            "text": " which was a way that it even moves away from the ball as it's coming down",
            "tokens": [
                51364,
                597,
                390,
                257,
                636,
                300,
                309,
                754,
                6067,
                1314,
                490,
                264,
                2594,
                382,
                309,
                311,
                1348,
                760,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 316,
            "seek": 125790,
            "start": 1281.9,
            "end": 1284.9,
            "text": " just so it could move back towards it, just to hit it on the corner",
            "tokens": [
                51564,
                445,
                370,
                309,
                727,
                1286,
                646,
                3030,
                309,
                11,
                445,
                281,
                2045,
                309,
                322,
                264,
                4538,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07567514198413794,
            "compression_ratio": 1.806228373702422,
            "no_speech_prob": 0.0014535163063555956
        },
        {
            "id": 317,
            "seek": 128490,
            "start": 1284.9,
            "end": 1289.9,
            "text": " and execute on those corner parts of the board and break out a lot of pieces",
            "tokens": [
                50364,
                293,
                14483,
                322,
                729,
                4538,
                3166,
                295,
                264,
                3150,
                293,
                1821,
                484,
                257,
                688,
                295,
                3755,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 318,
            "seek": 128490,
            "start": 1289.9,
            "end": 1292.9,
            "text": " for free, almost.",
            "tokens": [
                50614,
                337,
                1737,
                11,
                1920,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 319,
            "seek": 128490,
            "start": 1292.9,
            "end": 1297.9,
            "text": " So now that we can see that sometimes obtaining the Q function can be a little bit",
            "tokens": [
                50764,
                407,
                586,
                300,
                321,
                393,
                536,
                300,
                2171,
                36749,
                264,
                1249,
                2445,
                393,
                312,
                257,
                707,
                857,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 320,
            "seek": 128490,
            "start": 1297.9,
            "end": 1301.9,
            "text": " unintuitive, but the key point here is that if we have the Q function,",
            "tokens": [
                51014,
                29466,
                48314,
                11,
                457,
                264,
                2141,
                935,
                510,
                307,
                300,
                498,
                321,
                362,
                264,
                1249,
                2445,
                11,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 321,
            "seek": 128490,
            "start": 1301.9,
            "end": 1306.9,
            "text": " we can directly use it to determine what is the best action that we can take",
            "tokens": [
                51214,
                321,
                393,
                3838,
                764,
                309,
                281,
                6997,
                437,
                307,
                264,
                1151,
                3069,
                300,
                321,
                393,
                747,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 322,
            "seek": 128490,
            "start": 1306.9,
            "end": 1308.9,
            "text": " in any given state that we find ourselves in.",
            "tokens": [
                51464,
                294,
                604,
                2212,
                1785,
                300,
                321,
                915,
                4175,
                294,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 323,
            "seek": 128490,
            "start": 1308.9,
            "end": 1313.9,
            "text": " So now the question naturally is, how can we train a neural network that can, indeed,",
            "tokens": [
                51564,
                407,
                586,
                264,
                1168,
                8195,
                307,
                11,
                577,
                393,
                321,
                3847,
                257,
                18161,
                3209,
                300,
                393,
                11,
                6451,
                11,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12085825821449017,
            "compression_ratio": 1.7576923076923077,
            "no_speech_prob": 0.0014765537343919277
        },
        {
            "id": 324,
            "seek": 131390,
            "start": 1313.9,
            "end": 1316.9,
            "text": " learn this Q function?",
            "tokens": [
                50364,
                1466,
                341,
                1249,
                2445,
                30,
                50514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 325,
            "seek": 131390,
            "start": 1316.9,
            "end": 1321.9,
            "text": " So the type of the neural network here naturally, because we have a function",
            "tokens": [
                50514,
                407,
                264,
                2010,
                295,
                264,
                18161,
                3209,
                510,
                8195,
                11,
                570,
                321,
                362,
                257,
                2445,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 326,
            "seek": 131390,
            "start": 1321.9,
            "end": 1325.9,
            "text": " that takes us input two things, let's imagine our neural network will also take as input",
            "tokens": [
                50764,
                300,
                2516,
                505,
                4846,
                732,
                721,
                11,
                718,
                311,
                3811,
                527,
                18161,
                3209,
                486,
                611,
                747,
                382,
                4846,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 327,
            "seek": 131390,
            "start": 1325.9,
            "end": 1327.9,
            "text": " these two objects as well.",
            "tokens": [
                50964,
                613,
                732,
                6565,
                382,
                731,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 328,
            "seek": 131390,
            "start": 1327.9,
            "end": 1329.9,
            "text": " One object is going to be the state of the board.",
            "tokens": [
                51064,
                1485,
                2657,
                307,
                516,
                281,
                312,
                264,
                1785,
                295,
                264,
                3150,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 329,
            "seek": 131390,
            "start": 1329.9,
            "end": 1333.9,
            "text": " You can think of this as simply the pixels that are on the screen describing that board.",
            "tokens": [
                51164,
                509,
                393,
                519,
                295,
                341,
                382,
                2935,
                264,
                18668,
                300,
                366,
                322,
                264,
                2568,
                16141,
                300,
                3150,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        }
    ],
    [
        {
            "id": 330,
            "seek": 131390,
            "start": 1333.9,
            "end": 1335.9,
            "text": " So it's an image of the board at a particular time.",
            "tokens": [
                51364,
                407,
                309,
                311,
                364,
                3256,
                295,
                264,
                3150,
                412,
                257,
                1729,
                565,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 331,
            "seek": 131390,
            "start": 1335.9,
            "end": 1340.9,
            "text": " Maybe you want to even provide two or three images to give it some sense of temporal information",
            "tokens": [
                51464,
                2704,
                291,
                528,
                281,
                754,
                2893,
                732,
                420,
                1045,
                5267,
                281,
                976,
                309,
                512,
                2020,
                295,
                30881,
                1589,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07511739033024485,
            "compression_ratio": 1.7587412587412588,
            "no_speech_prob": 5.474237332236953e-05
        },
        {
            "id": 332,
            "seek": 134090,
            "start": 1340.9,
            "end": 1345.9,
            "text": " and some past history as well, but all of that information can be combined together",
            "tokens": [
                50364,
                293,
                512,
                1791,
                2503,
                382,
                731,
                11,
                457,
                439,
                295,
                300,
                1589,
                393,
                312,
                9354,
                1214,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 333,
            "seek": 134090,
            "start": 1345.9,
            "end": 1348.9,
            "text": " and provided to the network in the form of a state.",
            "tokens": [
                50614,
                293,
                5649,
                281,
                264,
                3209,
                294,
                264,
                1254,
                295,
                257,
                1785,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 334,
            "seek": 134090,
            "start": 1348.9,
            "end": 1352.9,
            "text": " And in addition to that, you may also want to provide it some actions as well.",
            "tokens": [
                50764,
                400,
                294,
                4500,
                281,
                300,
                11,
                291,
                815,
                611,
                528,
                281,
                2893,
                309,
                512,
                5909,
                382,
                731,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 335,
            "seek": 134090,
            "start": 1352.9,
            "end": 1357.9,
            "text": " So in this case, the actions that a neural network or an agent could take in this game",
            "tokens": [
                50964,
                407,
                294,
                341,
                1389,
                11,
                264,
                5909,
                300,
                257,
                18161,
                3209,
                420,
                364,
                9461,
                727,
                747,
                294,
                341,
                1216,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 336,
            "seek": 134090,
            "start": 1357.9,
            "end": 1361.9,
            "text": " is to move to the right to the left to stay still.",
            "tokens": [
                51214,
                307,
                281,
                1286,
                281,
                264,
                558,
                281,
                264,
                1411,
                281,
                1754,
                920,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 337,
            "seek": 134090,
            "start": 1361.9,
            "end": 1364.9,
            "text": " And those could be three different actions that could be provided and parameterized",
            "tokens": [
                51414,
                400,
                729,
                727,
                312,
                1045,
                819,
                5909,
                300,
                727,
                312,
                5649,
                293,
                13075,
                1602,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 338,
            "seek": 134090,
            "start": 1364.9,
            "end": 1366.9,
            "text": " to the input of a neural network.",
            "tokens": [
                51564,
                281,
                264,
                4846,
                295,
                257,
                18161,
                3209,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07018802905904836,
            "compression_ratio": 1.88,
            "no_speech_prob": 0.029690632596611977
        },
        {
            "id": 339,
            "seek": 136690,
            "start": 1366.9,
            "end": 1373.9,
            "text": " The goal here is to estimate the single number output that measures what is the expected value",
            "tokens": [
                50364,
                440,
                3387,
                510,
                307,
                281,
                12539,
                264,
                2167,
                1230,
                5598,
                300,
                8000,
                437,
                307,
                264,
                5176,
                2158,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 340,
            "seek": 136690,
            "start": 1373.9,
            "end": 1379.9,
            "text": " or the expected q value of this neural network at this particular state action pair.",
            "tokens": [
                50714,
                420,
                264,
                5176,
                9505,
                2158,
                295,
                341,
                18161,
                3209,
                412,
                341,
                1729,
                1785,
                3069,
                6119,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 341,
            "seek": 136690,
            "start": 1379.9,
            "end": 1383.9,
            "text": " Now, oftentimes what you'll see is that if you wanted to evaluate, let's suppose,",
            "tokens": [
                51014,
                823,
                11,
                18349,
                437,
                291,
                603,
                536,
                307,
                300,
                498,
                291,
                1415,
                281,
                13059,
                11,
                718,
                311,
                7297,
                11,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 342,
            "seek": 136690,
            "start": 1383.9,
            "end": 1385.9,
            "text": " a very large action space.",
            "tokens": [
                51214,
                257,
                588,
                2416,
                3069,
                1901,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 343,
            "seek": 136690,
            "start": 1385.9,
            "end": 1390.9,
            "text": " It's going to be very inefficient to try the approach on the left with a very large action space.",
            "tokens": [
                51314,
                467,
                311,
                516,
                281,
                312,
                588,
                43495,
                281,
                853,
                264,
                3109,
                322,
                264,
                1411,
                365,
                257,
                588,
                2416,
                3069,
                1901,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 344,
            "seek": 136690,
            "start": 1390.9,
            "end": 1395.9,
            "text": " Because what it would mean is that you'd have to run your neural network forward many different times.",
            "tokens": [
                51564,
                1436,
                437,
                309,
                576,
                914,
                307,
                300,
                291,
                1116,
                362,
                281,
                1190,
                428,
                18161,
                3209,
                2128,
                867,
                819,
                1413,
                13,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10863890690086163,
            "compression_ratio": 1.8314606741573034,
            "no_speech_prob": 0.022957799956202507
        },
        {
            "id": 345,
            "seek": 139590,
            "start": 1395.9,
            "end": 1398.9,
            "text": " One time for every single element of your action space.",
            "tokens": [
                50364,
                1485,
                565,
                337,
                633,
                2167,
                4478,
                295,
                428,
                3069,
                1901,
                13,
                50514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08787794396428779,
            "compression_ratio": 1.7543103448275863,
            "no_speech_prob": 0.0006262136739678681
        },
        {
            "id": 346,
            "seek": 139590,
            "start": 1398.9,
            "end": 1402.9,
            "text": " So what if instead you only provided an input of your state.",
            "tokens": [
                50514,
                407,
                437,
                498,
                2602,
                291,
                787,
                5649,
                364,
                4846,
                295,
                428,
                1785,
                13,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08787794396428779,
            "compression_ratio": 1.7543103448275863,
            "no_speech_prob": 0.0006262136739678681
        },
        {
            "id": 347,
            "seek": 139590,
            "start": 1402.9,
            "end": 1409.9,
            "text": " And as output, you gave it, let's say, all n different q values, one q value for every single possible action.",
            "tokens": [
                50714,
                400,
                382,
                5598,
                11,
                291,
                2729,
                309,
                11,
                718,
                311,
                584,
                11,
                439,
                297,
                819,
                9505,
                4190,
                11,
                472,
                9505,
                2158,
                337,
                633,
                2167,
                1944,
                3069,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08787794396428779,
            "compression_ratio": 1.7543103448275863,
            "no_speech_prob": 0.0006262136739678681
        },
        {
            "id": 348,
            "seek": 139590,
            "start": 1409.9,
            "end": 1414.9,
            "text": " That way you only need to run your neural network once for the given state that you're in.",
            "tokens": [
                51064,
                663,
                636,
                291,
                787,
                643,
                281,
                1190,
                428,
                18161,
                3209,
                1564,
                337,
                264,
                2212,
                1785,
                300,
                291,
                434,
                294,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08787794396428779,
            "compression_ratio": 1.7543103448275863,
            "no_speech_prob": 0.0006262136739678681
        },
        {
            "id": 349,
            "seek": 139590,
            "start": 1414.9,
            "end": 1419.9,
            "text": " And then that neural network will tell you for all possible actions, what's the maximum?",
            "tokens": [
                51314,
                400,
                550,
                300,
                18161,
                3209,
                486,
                980,
                291,
                337,
                439,
                1944,
                5909,
                11,
                437,
                311,
                264,
                6674,
                30,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08787794396428779,
            "compression_ratio": 1.7543103448275863,
            "no_speech_prob": 0.0006262136739678681
        },
        {
            "id": 350,
            "seek": 141990,
            "start": 1419.9,
            "end": 1426.9,
            "text": " You'd simply then look at that output and pick the action that has the kai sq value.",
            "tokens": [
                50364,
                509,
                1116,
                2935,
                550,
                574,
                412,
                300,
                5598,
                293,
                1888,
                264,
                3069,
                300,
                575,
                264,
                350,
                1301,
                262,
                80,
                2158,
                13,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14369205006381922,
            "compression_ratio": 1.7710843373493976,
            "no_speech_prob": 0.03670034930109978
        },
        {
            "id": 351,
            "seek": 141990,
            "start": 1426.9,
            "end": 1432.9,
            "text": " Now, what would happen? Right. So actually, the question I want to pose here is really, you know,",
            "tokens": [
                50714,
                823,
                11,
                437,
                576,
                1051,
                30,
                1779,
                13,
                407,
                767,
                11,
                264,
                1168,
                286,
                528,
                281,
                10774,
                510,
                307,
                534,
                11,
                291,
                458,
                11,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14369205006381922,
            "compression_ratio": 1.7710843373493976,
            "no_speech_prob": 0.03670034930109978
        },
        {
            "id": 352,
            "seek": 141990,
            "start": 1432.9,
            "end": 1436.9,
            "text": " we want to train one of these two networks. Let's stick with the network on the right for simplicity,",
            "tokens": [
                51014,
                321,
                528,
                281,
                3847,
                472,
                295,
                613,
                732,
                9590,
                13,
                961,
                311,
                2897,
                365,
                264,
                3209,
                322,
                264,
                558,
                337,
                25632,
                11,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14369205006381922,
            "compression_ratio": 1.7710843373493976,
            "no_speech_prob": 0.03670034930109978
        },
        {
            "id": 353,
            "seek": 141990,
            "start": 1436.9,
            "end": 1440.9,
            "text": " just since it's a much more efficient version of the network on the left.",
            "tokens": [
                51214,
                445,
                1670,
                309,
                311,
                257,
                709,
                544,
                7148,
                3037,
                295,
                264,
                3209,
                322,
                264,
                1411,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14369205006381922,
            "compression_ratio": 1.7710843373493976,
            "no_speech_prob": 0.03670034930109978
        },
        {
            "id": 354,
            "seek": 141990,
            "start": 1440.9,
            "end": 1445.9,
            "text": " And the question is, you know, how do we actually train that network on the right?",
            "tokens": [
                51414,
                400,
                264,
                1168,
                307,
                11,
                291,
                458,
                11,
                577,
                360,
                321,
                767,
                3847,
                300,
                3209,
                322,
                264,
                558,
                30,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14369205006381922,
            "compression_ratio": 1.7710843373493976,
            "no_speech_prob": 0.03670034930109978
        },
        {
            "id": 355,
            "seek": 144590,
            "start": 1445.9,
            "end": 1450.9,
            "text": " And specifically, I want all of you to think about really the best case scenario just to start with.",
            "tokens": [
                50364,
                400,
                4682,
                11,
                286,
                528,
                439,
                295,
                291,
                281,
                519,
                466,
                534,
                264,
                1151,
                1389,
                9005,
                445,
                281,
                722,
                365,
                13,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12228047975929834,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.006376936100423336
        },
        {
            "id": 356,
            "seek": 144590,
            "start": 1450.9,
            "end": 1460.9,
            "text": " How an agent would perform ideally in a particular situation or what would happen, right, if an agent took all of the ideal actions at any given state.",
            "tokens": [
                50614,
                1012,
                364,
                9461,
                576,
                2042,
                22915,
                294,
                257,
                1729,
                2590,
                420,
                437,
                576,
                1051,
                11,
                558,
                11,
                498,
                364,
                9461,
                1890,
                439,
                295,
                264,
                7157,
                5909,
                412,
                604,
                2212,
                1785,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12228047975929834,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.006376936100423336
        },
        {
            "id": 357,
            "seek": 144590,
            "start": 1460.9,
            "end": 1471.9,
            "text": " This would mean that essentially the target return, right, the predicted or the value that we're trying to predict, the target is going to always be maximized.",
            "tokens": [
                51114,
                639,
                576,
                914,
                300,
                4476,
                264,
                3779,
                2736,
                11,
                558,
                11,
                264,
                19147,
                420,
                264,
                2158,
                300,
                321,
                434,
                1382,
                281,
                6069,
                11,
                264,
                3779,
                307,
                516,
                281,
                1009,
                312,
                5138,
                1602,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12228047975929834,
            "compression_ratio": 1.6885245901639345,
            "no_speech_prob": 0.006376936100423336
        },
        {
            "id": 358,
            "seek": 147190,
            "start": 1471.9,
            "end": 1475.9,
            "text": " And this can serve as essentially the ground truth to the agent.",
            "tokens": [
                50364,
                400,
                341,
                393,
                4596,
                382,
                4476,
                264,
                2727,
                3494,
                281,
                264,
                9461,
                13,
                50564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09057494096977767,
            "compression_ratio": 1.7077625570776256,
            "no_speech_prob": 0.054107408970594406
        },
        {
            "id": 359,
            "seek": 147190,
            "start": 1475.9,
            "end": 1487.9,
            "text": " Now, for example, to do this, we want to formulate a loss function that's going to essentially represent our expected return if we're able to take all of the best actions.",
            "tokens": [
                50564,
                823,
                11,
                337,
                1365,
                11,
                281,
                360,
                341,
                11,
                321,
                528,
                281,
                47881,
                257,
                4470,
                2445,
                300,
                311,
                516,
                281,
                4476,
                2906,
                527,
                5176,
                2736,
                498,
                321,
                434,
                1075,
                281,
                747,
                439,
                295,
                264,
                1151,
                5909,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09057494096977767,
            "compression_ratio": 1.7077625570776256,
            "no_speech_prob": 0.054107408970594406
        }
    ],
    [
        {
            "id": 360,
            "seek": 147190,
            "start": 1487.9,
            "end": 1495.9,
            "text": " Right. So, for example, if we select an initial reward plus selecting some action in our action space that maximizes our expected return,",
            "tokens": [
                51164,
                1779,
                13,
                407,
                11,
                337,
                1365,
                11,
                498,
                321,
                3048,
                364,
                5883,
                7782,
                1804,
                18182,
                512,
                3069,
                294,
                527,
                3069,
                1901,
                300,
                5138,
                5660,
                527,
                5176,
                2736,
                11,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09057494096977767,
            "compression_ratio": 1.7077625570776256,
            "no_speech_prob": 0.054107408970594406
        },
        {
            "id": 361,
            "seek": 149590,
            "start": 1495.9,
            "end": 1503.9,
            "text": " then for the next future state, we need to apply that discounting factor and recursively apply the same equation.",
            "tokens": [
                50364,
                550,
                337,
                264,
                958,
                2027,
                1785,
                11,
                321,
                643,
                281,
                3079,
                300,
                11635,
                278,
                5952,
                293,
                20560,
                3413,
                3079,
                264,
                912,
                5367,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1317141701193417,
            "compression_ratio": 1.625,
            "no_speech_prob": 0.013005056418478489
        },
        {
            "id": 362,
            "seek": 149590,
            "start": 1503.9,
            "end": 1511.9,
            "text": " And that simply turns into our target, right. Now we can ask basically what does our neural network predict, right.",
            "tokens": [
                50764,
                400,
                300,
                2935,
                4523,
                666,
                527,
                3779,
                11,
                558,
                13,
                823,
                321,
                393,
                1029,
                1936,
                437,
                775,
                527,
                18161,
                3209,
                6069,
                11,
                558,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1317141701193417,
            "compression_ratio": 1.625,
            "no_speech_prob": 0.013005056418478489
        },
        {
            "id": 363,
            "seek": 149590,
            "start": 1511.9,
            "end": 1519.9,
            "text": " So that's our target and recall from previous lectures, if we have a target value, in this case, our q value is a continuous variable,",
            "tokens": [
                51164,
                407,
                300,
                311,
                527,
                3779,
                293,
                9901,
                490,
                3894,
                16564,
                11,
                498,
                321,
                362,
                257,
                3779,
                2158,
                11,
                294,
                341,
                1389,
                11,
                527,
                9505,
                2158,
                307,
                257,
                10957,
                7006,
                11,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1317141701193417,
            "compression_ratio": 1.625,
            "no_speech_prob": 0.013005056418478489
        },
        {
            "id": 364,
            "seek": 151990,
            "start": 1519.9,
            "end": 1528.9,
            "text": " we have also a predicted variable that is going to come as part of the output of every single one of these potential actions that could be taken.",
            "tokens": [
                50364,
                321,
                362,
                611,
                257,
                19147,
                7006,
                300,
                307,
                516,
                281,
                808,
                382,
                644,
                295,
                264,
                5598,
                295,
                633,
                2167,
                472,
                295,
                613,
                3995,
                5909,
                300,
                727,
                312,
                2726,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10820704090351961,
            "compression_ratio": 1.7112676056338028,
            "no_speech_prob": 0.003648367477580905
        },
        {
            "id": 365,
            "seek": 151990,
            "start": 1528.9,
            "end": 1535.9,
            "text": " We can define what's called a q loss, which is essentially just a very simple mean squared error loss between these two continuous variables.",
            "tokens": [
                50814,
                492,
                393,
                6964,
                437,
                311,
                1219,
                257,
                9505,
                4470,
                11,
                597,
                307,
                4476,
                445,
                257,
                588,
                2199,
                914,
                8889,
                6713,
                4470,
                1296,
                613,
                732,
                10957,
                9102,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10820704090351961,
            "compression_ratio": 1.7112676056338028,
            "no_speech_prob": 0.003648367477580905
        },
        {
            "id": 366,
            "seek": 151990,
            "start": 1535.9,
            "end": 1547.9,
            "text": " We minimize their distance over two over many, many different iterations of flying our neural network in this environment, observing actions and observing not only the actions, but most importantly,",
            "tokens": [
                51164,
                492,
                17522,
                641,
                4560,
                670,
                732,
                670,
                867,
                11,
                867,
                819,
                36540,
                295,
                7137,
                527,
                18161,
                3209,
                294,
                341,
                2823,
                11,
                22107,
                5909,
                293,
                22107,
                406,
                787,
                264,
                5909,
                11,
                457,
                881,
                8906,
                11,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10820704090351961,
            "compression_ratio": 1.7112676056338028,
            "no_speech_prob": 0.003648367477580905
        },
        {
            "id": 367,
            "seek": 154790,
            "start": 1547.9,
            "end": 1557.9,
            "text": " after the action is committed or executed, we can see exactly the ground truth expected return, right.",
            "tokens": [
                50364,
                934,
                264,
                3069,
                307,
                7784,
                420,
                17577,
                11,
                321,
                393,
                536,
                2293,
                264,
                2727,
                3494,
                5176,
                2736,
                11,
                558,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06025756256920951,
            "compression_ratio": 1.6024844720496894,
            "no_speech_prob": 0.0025891538243740797
        },
        {
            "id": 368,
            "seek": 154790,
            "start": 1557.9,
            "end": 1567.9,
            "text": " So we have the ground truth labels to train and supervise this model directly from the actions that were executed as part of random selection, for example.",
            "tokens": [
                50864,
                407,
                321,
                362,
                264,
                2727,
                3494,
                16949,
                281,
                3847,
                293,
                37971,
                908,
                341,
                2316,
                3838,
                490,
                264,
                5909,
                300,
                645,
                17577,
                382,
                644,
                295,
                4974,
                9450,
                11,
                337,
                1365,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06025756256920951,
            "compression_ratio": 1.6024844720496894,
            "no_speech_prob": 0.0025891538243740797
        },
        {
            "id": 369,
            "seek": 156790,
            "start": 1567.9,
            "end": 1578.9,
            "text": " Now, let me just stop right there and maybe summarize the whole process one more time and maybe a bit different terminology just to give everyone kind of a different perspective on this same problem.",
            "tokens": [
                50364,
                823,
                11,
                718,
                385,
                445,
                1590,
                558,
                456,
                293,
                1310,
                20858,
                264,
                1379,
                1399,
                472,
                544,
                565,
                293,
                1310,
                257,
                857,
                819,
                27575,
                445,
                281,
                976,
                1518,
                733,
                295,
                257,
                819,
                4585,
                322,
                341,
                912,
                1154,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0959130839297646,
            "compression_ratio": 1.7662835249042146,
            "no_speech_prob": 0.036707572638988495
        },
        {
            "id": 370,
            "seek": 156790,
            "start": 1578.9,
            "end": 1594.9,
            "text": " So our deep neural network that we're trying to train looks like this, right. It takes us input a state is trying to output and different numbers, those end different numbers correspond to the q value associated to end different actions, one q value per action.",
            "tokens": [
                50914,
                407,
                527,
                2452,
                18161,
                3209,
                300,
                321,
                434,
                1382,
                281,
                3847,
                1542,
                411,
                341,
                11,
                558,
                13,
                467,
                2516,
                505,
                4846,
                257,
                1785,
                307,
                1382,
                281,
                5598,
                293,
                819,
                3547,
                11,
                729,
                917,
                819,
                3547,
                6805,
                281,
                264,
                9505,
                2158,
                6615,
                281,
                917,
                819,
                5909,
                11,
                472,
                9505,
                2158,
                680,
                3069,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0959130839297646,
            "compression_ratio": 1.7662835249042146,
            "no_speech_prob": 0.036707572638988495
        },
        {
            "id": 371,
            "seek": 159490,
            "start": 1595.9,
            "end": 1607.9,
            "text": " Here, the actions in the tary breakout, for example, should be three actions, we can either go left, we can go right, or we can do nothing, we can stay where we are.",
            "tokens": [
                50414,
                1692,
                11,
                264,
                5909,
                294,
                264,
                256,
                822,
                30067,
                11,
                337,
                1365,
                11,
                820,
                312,
                1045,
                5909,
                11,
                321,
                393,
                2139,
                352,
                1411,
                11,
                321,
                393,
                352,
                558,
                11,
                420,
                321,
                393,
                360,
                1825,
                11,
                321,
                393,
                1754,
                689,
                321,
                366,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1484345000924416,
            "compression_ratio": 1.737556561085973,
            "no_speech_prob": 0.010805942118167877
        },
        {
            "id": 372,
            "seek": 159490,
            "start": 1607.9,
            "end": 1623.9,
            "text": " Right. So the next step from this, we saw if we have this q value output, what we can do with it is we can make an action, or we can even, let me be more formal about it, we can develop what's called a policy function.",
            "tokens": [
                51014,
                1779,
                13,
                407,
                264,
                958,
                1823,
                490,
                341,
                11,
                321,
                1866,
                498,
                321,
                362,
                341,
                9505,
                2158,
                5598,
                11,
                437,
                321,
                393,
                360,
                365,
                309,
                307,
                321,
                393,
                652,
                364,
                3069,
                11,
                420,
                321,
                393,
                754,
                11,
                718,
                385,
                312,
                544,
                9860,
                466,
                309,
                11,
                321,
                393,
                1499,
                437,
                311,
                1219,
                257,
                3897,
                2445,
                13,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1484345000924416,
            "compression_ratio": 1.737556561085973,
            "no_speech_prob": 0.010805942118167877
        },
        {
            "id": 373,
            "seek": 162390,
            "start": 1623.9,
            "end": 1637.9,
            "text": " Policy function is a function that given a state, it determines what is the best action. So that's different than the q function, right. The q function tells us given a state, what is the best, or what is the value, the return of every action that we could take.",
            "tokens": [
                50364,
                21708,
                2445,
                307,
                257,
                2445,
                300,
                2212,
                257,
                1785,
                11,
                309,
                24799,
                437,
                307,
                264,
                1151,
                3069,
                13,
                407,
                300,
                311,
                819,
                813,
                264,
                9505,
                2445,
                11,
                558,
                13,
                440,
                9505,
                2445,
                5112,
                505,
                2212,
                257,
                1785,
                11,
                437,
                307,
                264,
                1151,
                11,
                420,
                437,
                307,
                264,
                2158,
                11,
                264,
                2736,
                295,
                633,
                3069,
                300,
                321,
                727,
                747,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1295984359014602,
            "compression_ratio": 1.7583892617449663,
            "no_speech_prob": 0.010958819650113583
        },
        {
            "id": 374,
            "seek": 163790,
            "start": 1637.9,
            "end": 1653.9,
            "text": " The policy function tells us one step more than that given given a state, what is the best action, right. So it's a very end to end way of thinking about, you know, the agents decision making process based on what I see right now, what is the action that I should take.",
            "tokens": [
                50364,
                440,
                3897,
                2445,
                5112,
                505,
                472,
                1823,
                544,
                813,
                300,
                2212,
                2212,
                257,
                1785,
                11,
                437,
                307,
                264,
                1151,
                3069,
                11,
                558,
                13,
                407,
                309,
                311,
                257,
                588,
                917,
                281,
                917,
                636,
                295,
                1953,
                466,
                11,
                291,
                458,
                11,
                264,
                12554,
                3537,
                1455,
                1399,
                2361,
                322,
                437,
                286,
                536,
                558,
                586,
                11,
                437,
                307,
                264,
                3069,
                300,
                286,
                820,
                747,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13300044719989484,
            "compression_ratio": 1.563953488372093,
            "no_speech_prob": 0.49845945835113525
        },
        {
            "id": 375,
            "seek": 165390,
            "start": 1653.9,
            "end": 1665.9,
            "text": " And we can determine that policy function directly from the q function itself simply by maximizing and optimizing all of the different q values for all of the different actions that we see here.",
            "tokens": [
                50364,
                400,
                321,
                393,
                6997,
                300,
                3897,
                2445,
                3838,
                490,
                264,
                9505,
                2445,
                2564,
                2935,
                538,
                5138,
                3319,
                293,
                40425,
                439,
                295,
                264,
                819,
                9505,
                4190,
                337,
                439,
                295,
                264,
                819,
                5909,
                300,
                321,
                536,
                510,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1225476766887464,
            "compression_ratio": 1.9291338582677164,
            "no_speech_prob": 0.5754892230033875
        },
        {
            "id": 376,
            "seek": 165390,
            "start": 1665.9,
            "end": 1682.9,
            "text": " So for example, here we can see that given this state, the q function has the results of these three different values as a q value of 20, if it goes to the left, as a q value of three, if it stays in the same place, and it has a q value of zero, it's going to basically die after this iteration.",
            "tokens": [
                50964,
                407,
                337,
                1365,
                11,
                510,
                321,
                393,
                536,
                300,
                2212,
                341,
                1785,
                11,
                264,
                9505,
                2445,
                575,
                264,
                3542,
                295,
                613,
                1045,
                819,
                4190,
                382,
                257,
                9505,
                2158,
                295,
                945,
                11,
                498,
                309,
                1709,
                281,
                264,
                1411,
                11,
                382,
                257,
                9505,
                2158,
                295,
                1045,
                11,
                498,
                309,
                10834,
                294,
                264,
                912,
                1081,
                11,
                293,
                309,
                575,
                257,
                9505,
                2158,
                295,
                4018,
                11,
                309,
                311,
                516,
                281,
                1936,
                978,
                934,
                341,
                24784,
                13,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1225476766887464,
            "compression_ratio": 1.9291338582677164,
            "no_speech_prob": 0.5754892230033875
        },
        {
            "id": 377,
            "seek": 168290,
            "start": 1682.9,
            "end": 1694.9,
            "text": " If it moves to the right, because you can see that the ball is coming to the left of it, the most right, the game is over, right. So it needs to move to the left in order to do that in order to continue the game and the q value reflects that.",
            "tokens": [
                50364,
                759,
                309,
                6067,
                281,
                264,
                558,
                11,
                570,
                291,
                393,
                536,
                300,
                264,
                2594,
                307,
                1348,
                281,
                264,
                1411,
                295,
                309,
                11,
                264,
                881,
                558,
                11,
                264,
                1216,
                307,
                670,
                11,
                558,
                13,
                407,
                309,
                2203,
                281,
                1286,
                281,
                264,
                1411,
                294,
                1668,
                281,
                360,
                300,
                294,
                1668,
                281,
                2354,
                264,
                1216,
                293,
                264,
                9505,
                2158,
                18926,
                300,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10749679699278715,
            "compression_ratio": 1.8866396761133604,
            "no_speech_prob": 0.10326743125915527
        },
        {
            "id": 378,
            "seek": 168290,
            "start": 1694.9,
            "end": 1708.9,
            "text": " The optimal action here is simply going to be the maximum of these three q values. In this case, it's going to be 20 and then the action is going to be the corresponding action that comes from that 20, which is moving left.",
            "tokens": [
                50964,
                440,
                16252,
                3069,
                510,
                307,
                2935,
                516,
                281,
                312,
                264,
                6674,
                295,
                613,
                1045,
                9505,
                4190,
                13,
                682,
                341,
                1389,
                11,
                309,
                311,
                516,
                281,
                312,
                945,
                293,
                550,
                264,
                3069,
                307,
                516,
                281,
                312,
                264,
                11760,
                3069,
                300,
                1487,
                490,
                300,
                945,
                11,
                597,
                307,
                2684,
                1411,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10749679699278715,
            "compression_ratio": 1.8866396761133604,
            "no_speech_prob": 0.10326743125915527
        },
        {
            "id": 379,
            "seek": 170890,
            "start": 1708.9,
            "end": 1728.9,
            "text": " Now, we can send this action back to the environment in the form of the game to execute the next step, right. And as the agent moves through this environment, it's going to be responded with not only by new pixels that come from the game, but more importantly, some reward signal.",
            "tokens": [
                50364,
                823,
                11,
                321,
                393,
                2845,
                341,
                3069,
                646,
                281,
                264,
                2823,
                294,
                264,
                1254,
                295,
                264,
                1216,
                281,
                14483,
                264,
                958,
                1823,
                11,
                558,
                13,
                400,
                382,
                264,
                9461,
                6067,
                807,
                341,
                2823,
                11,
                309,
                311,
                516,
                281,
                312,
                15806,
                365,
                406,
                787,
                538,
                777,
                18668,
                300,
                808,
                490,
                264,
                1216,
                11,
                457,
                544,
                8906,
                11,
                512,
                7782,
                6358,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07187473773956299,
            "compression_ratio": 1.530054644808743,
            "no_speech_prob": 0.07658671587705612
        },
        {
            "id": 380,
            "seek": 172890,
            "start": 1728.9,
            "end": 1741.9,
            "text": " Now, it's very important to remember that the reward signals in a Tari breakout are very sparse, right. You get a reward not necessarily based on the action that you take at this exact moment.",
            "tokens": [
                50364,
                823,
                11,
                309,
                311,
                588,
                1021,
                281,
                1604,
                300,
                264,
                7782,
                12354,
                294,
                257,
                314,
                3504,
                30067,
                366,
                588,
                637,
                11668,
                11,
                558,
                13,
                509,
                483,
                257,
                7782,
                406,
                4725,
                2361,
                322,
                264,
                3069,
                300,
                291,
                747,
                412,
                341,
                1900,
                1623,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11544175667337853,
            "compression_ratio": 1.6742424242424243,
            "no_speech_prob": 0.4136372208595276
        },
        {
            "id": 381,
            "seek": 172890,
            "start": 1741.9,
            "end": 1755.9,
            "text": " It usually takes a few time steps for that ball to travel back up to the top of the screen. So usually your rewards will be quite delayed, maybe at least by several time steps, sometimes even more if you're bouncing off of the corners of the screen.",
            "tokens": [
                51014,
                467,
                2673,
                2516,
                257,
                1326,
                565,
                4439,
                337,
                300,
                2594,
                281,
                3147,
                646,
                493,
                281,
                264,
                1192,
                295,
                264,
                2568,
                13,
                407,
                2673,
                428,
                17203,
                486,
                312,
                1596,
                20268,
                11,
                1310,
                412,
                1935,
                538,
                2940,
                565,
                4439,
                11,
                2171,
                754,
                544,
                498,
                291,
                434,
                27380,
                766,
                295,
                264,
                12413,
                295,
                264,
                2568,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11544175667337853,
            "compression_ratio": 1.6742424242424243,
            "no_speech_prob": 0.4136372208595276
        },
        {
            "id": 382,
            "seek": 175590,
            "start": 1755.9,
            "end": 1768.9,
            "text": " Now, one very popular or very famous approach that showed this was presented by DeepMind, Google DeepMind several years ago, where they showed that you could train a q value network.",
            "tokens": [
                50364,
                823,
                11,
                472,
                588,
                3743,
                420,
                588,
                4618,
                3109,
                300,
                4712,
                341,
                390,
                8212,
                538,
                14895,
                44,
                471,
                11,
                3329,
                14895,
                44,
                471,
                2940,
                924,
                2057,
                11,
                689,
                436,
                4712,
                300,
                291,
                727,
                3847,
                257,
                9505,
                2158,
                3209,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10043034442635469,
            "compression_ratio": 1.378787878787879,
            "no_speech_prob": 0.03246642276644707
        },
        {
            "id": 383,
            "seek": 176890,
            "start": 1768.9,
            "end": 1778.9,
            "text": " And you can see the input on the left hand side is simply the raw pixels coming from the screen all the way to the actions of a controller on the right hand side.",
            "tokens": [
                50364,
                400,
                291,
                393,
                536,
                264,
                4846,
                322,
                264,
                1411,
                1011,
                1252,
                307,
                2935,
                264,
                8936,
                18668,
                1348,
                490,
                264,
                2568,
                439,
                264,
                636,
                281,
                264,
                5909,
                295,
                257,
                10561,
                322,
                264,
                558,
                1011,
                1252,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05776374716507761,
            "compression_ratio": 1.75,
            "no_speech_prob": 0.859819769859314
        },
        {
            "id": 384,
            "seek": 176890,
            "start": 1778.9,
            "end": 1796.9,
            "text": " And you could train this one network for a variety of different tasks all across the Atari breakout ecosystem of games. And for each of these tasks, the really fascinating thing that they showed was for this very simple algorithm, which really relies on random choice of selection of actions.",
            "tokens": [
                50864,
                400,
                291,
                727,
                3847,
                341,
                472,
                3209,
                337,
                257,
                5673,
                295,
                819,
                9608,
                439,
                2108,
                264,
                41381,
                30067,
                11311,
                295,
                2813,
                13,
                400,
                337,
                1184,
                295,
                613,
                9608,
                11,
                264,
                534,
                10343,
                551,
                300,
                436,
                4712,
                390,
                337,
                341,
                588,
                2199,
                9284,
                11,
                597,
                534,
                30910,
                322,
                4974,
                3922,
                295,
                9450,
                295,
                5909,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05776374716507761,
            "compression_ratio": 1.75,
            "no_speech_prob": 0.859819769859314
        },
        {
            "id": 385,
            "seek": 179690,
            "start": 1796.9,
            "end": 1806.9,
            "text": " And then, you know, learning from, you know, actions that don't do very well that you discourage them and trying to do actions that did perform well more frequently, very simple algorithm.",
            "tokens": [
                50364,
                400,
                550,
                11,
                291,
                458,
                11,
                2539,
                490,
                11,
                291,
                458,
                11,
                5909,
                300,
                500,
                380,
                360,
                588,
                731,
                300,
                291,
                21497,
                609,
                552,
                293,
                1382,
                281,
                360,
                5909,
                300,
                630,
                2042,
                731,
                544,
                10374,
                11,
                588,
                2199,
                9284,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09197566783533687,
            "compression_ratio": 1.8763636363636365,
            "no_speech_prob": 0.2521088719367981
        },
        {
            "id": 386,
            "seek": 179690,
            "start": 1806.9,
            "end": 1813.9,
            "text": " But what they found was even with that type of algorithm, they were able to surpass human level performance on over half of the game.",
            "tokens": [
                50864,
                583,
                437,
                436,
                1352,
                390,
                754,
                365,
                300,
                2010,
                295,
                9284,
                11,
                436,
                645,
                1075,
                281,
                27650,
                1952,
                1496,
                3389,
                322,
                670,
                1922,
                295,
                264,
                1216,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09197566783533687,
            "compression_ratio": 1.8763636363636365,
            "no_speech_prob": 0.2521088719367981
        },
        {
            "id": 387,
            "seek": 179690,
            "start": 1813.9,
            "end": 1823.9,
            "text": " There were some games that you can see here were still below human level performance. But as we'll see, this was really like such an exciting advance because of the simplicity of the algorithm.",
            "tokens": [
                51214,
                821,
                645,
                512,
                2813,
                300,
                291,
                393,
                536,
                510,
                645,
                920,
                2507,
                1952,
                1496,
                3389,
                13,
                583,
                382,
                321,
                603,
                536,
                11,
                341,
                390,
                534,
                411,
                1270,
                364,
                4670,
                7295,
                570,
                295,
                264,
                25632,
                295,
                264,
                9284,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09197566783533687,
            "compression_ratio": 1.8763636363636365,
            "no_speech_prob": 0.2521088719367981
        },
        {
            "id": 388,
            "seek": 182390,
            "start": 1823.9,
            "end": 1834.9,
            "text": " And how you know, clean the formulation of the training was you only needed a very little amount of prior knowledge to impose on to this neural network where to be able to learn how to play these games.",
            "tokens": [
                50364,
                400,
                577,
                291,
                458,
                11,
                2541,
                264,
                37642,
                295,
                264,
                3097,
                390,
                291,
                787,
                2978,
                257,
                588,
                707,
                2372,
                295,
                4059,
                3601,
                281,
                26952,
                322,
                281,
                341,
                18161,
                3209,
                689,
                281,
                312,
                1075,
                281,
                1466,
                577,
                281,
                862,
                613,
                2813,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12977989153428512,
            "compression_ratio": 1.6837606837606838,
            "no_speech_prob": 0.34385180473327637
        },
        {
            "id": 389,
            "seek": 182390,
            "start": 1834.9,
            "end": 1846.9,
            "text": " You never had to teach you any of the rules of the game, right? You only had to let it explore its environment play the game many, many times against itself and learn directly from that data.",
            "tokens": [
                50914,
                509,
                1128,
                632,
                281,
                2924,
                291,
                604,
                295,
                264,
                4474,
                295,
                264,
                1216,
                11,
                558,
                30,
                509,
                787,
                632,
                281,
                718,
                309,
                6839,
                1080,
                2823,
                862,
                264,
                1216,
                867,
                11,
                867,
                1413,
                1970,
                2564,
                293,
                1466,
                3838,
                490,
                300,
                1412,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12977989153428512,
            "compression_ratio": 1.6837606837606838,
            "no_speech_prob": 0.34385180473327637
        }
    ],
    [
        {
            "id": 390,
            "seek": 184690,
            "start": 1846.9,
            "end": 1854.9,
            "text": " Now, there are several very important downsides of QLearning and hopefully these are going to motivate the second part of today's lecture, which we'll talk about.",
            "tokens": [
                50364,
                823,
                11,
                456,
                366,
                2940,
                588,
                1021,
                21554,
                1875,
                295,
                1249,
                11020,
                2341,
                293,
                4696,
                613,
                366,
                516,
                281,
                28497,
                264,
                1150,
                644,
                295,
                965,
                311,
                7991,
                11,
                597,
                321,
                603,
                751,
                466,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07101086566322728,
            "compression_ratio": 1.6098484848484849,
            "no_speech_prob": 0.09499391913414001
        },
        {
            "id": 391,
            "seek": 184690,
            "start": 1854.9,
            "end": 1864.9,
            "text": " But the first one that I want to really convey to everyone here is that QLearning is naturally applicable to discrete action spaces, right?",
            "tokens": [
                50764,
                583,
                264,
                700,
                472,
                300,
                286,
                528,
                281,
                534,
                16965,
                281,
                1518,
                510,
                307,
                300,
                1249,
                11020,
                2341,
                307,
                8195,
                21142,
                281,
                27706,
                3069,
                7673,
                11,
                558,
                30,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07101086566322728,
            "compression_ratio": 1.6098484848484849,
            "no_speech_prob": 0.09499391913414001
        },
        {
            "id": 392,
            "seek": 184690,
            "start": 1864.9,
            "end": 1871.9,
            "text": " Because you can think of this output space that we're providing is kind of like one number per action that could be taken.",
            "tokens": [
                51264,
                1436,
                291,
                393,
                519,
                295,
                341,
                5598,
                1901,
                300,
                321,
                434,
                6530,
                307,
                733,
                295,
                411,
                472,
                1230,
                680,
                3069,
                300,
                727,
                312,
                2726,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07101086566322728,
            "compression_ratio": 1.6098484848484849,
            "no_speech_prob": 0.09499391913414001
        },
        {
            "id": 393,
            "seek": 187190,
            "start": 1871.9,
            "end": 1882.9,
            "text": " Now, if we have a continuous action space, we have to think about clever ways to work around that. In fact, there are now more recently, there are some solutions to achieve QLearning and continuous action spaces.",
            "tokens": [
                50364,
                823,
                11,
                498,
                321,
                362,
                257,
                10957,
                3069,
                1901,
                11,
                321,
                362,
                281,
                519,
                466,
                13494,
                2098,
                281,
                589,
                926,
                300,
                13,
                682,
                1186,
                11,
                456,
                366,
                586,
                544,
                3938,
                11,
                456,
                366,
                512,
                6547,
                281,
                4584,
                1249,
                11020,
                2341,
                293,
                10957,
                3069,
                7673,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06155392669496082,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.35040387511253357
        },
        {
            "id": 394,
            "seek": 187190,
            "start": 1882.9,
            "end": 1891.9,
            "text": " But for the most part, QLearning is very well suited for discrete action spaces and we'll talk about ways of overcoming that with other approaches a bit later.",
            "tokens": [
                50914,
                583,
                337,
                264,
                881,
                644,
                11,
                1249,
                11020,
                2341,
                307,
                588,
                731,
                24736,
                337,
                27706,
                3069,
                7673,
                293,
                321,
                603,
                751,
                466,
                2098,
                295,
                38047,
                300,
                365,
                661,
                11587,
                257,
                857,
                1780,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06155392669496082,
            "compression_ratio": 1.7142857142857142,
            "no_speech_prob": 0.35040387511253357
        },
        {
            "id": 395,
            "seek": 189190,
            "start": 1892.9,
            "end": 1906.9,
            "text": " And the second component here is that the policy that we're learning, right, the Q function is giving rise to that policy, which is the thing that we're actually using to determine what action to take given any state.",
            "tokens": [
                50414,
                400,
                264,
                1150,
                6542,
                510,
                307,
                300,
                264,
                3897,
                300,
                321,
                434,
                2539,
                11,
                558,
                11,
                264,
                1249,
                2445,
                307,
                2902,
                6272,
                281,
                300,
                3897,
                11,
                597,
                307,
                264,
                551,
                300,
                321,
                434,
                767,
                1228,
                281,
                6997,
                437,
                3069,
                281,
                747,
                2212,
                604,
                1785,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07491351633655782,
            "compression_ratio": 1.528169014084507,
            "no_speech_prob": 0.6489594578742981
        },
        {
            "id": 396,
            "seek": 190690,
            "start": 1906.9,
            "end": 1924.9,
            "text": " That policy is determined by, you know, deterministically optimizing that Q function. We simply look at the results from the Q function and apply our, or we look at the results of the Q function and we pick the action that has the best or the highest Q value.",
            "tokens": [
                50364,
                663,
                3897,
                307,
                9540,
                538,
                11,
                291,
                458,
                11,
                15957,
                20458,
                40425,
                300,
                1249,
                2445,
                13,
                492,
                2935,
                574,
                412,
                264,
                3542,
                490,
                264,
                1249,
                2445,
                293,
                3079,
                527,
                11,
                420,
                321,
                574,
                412,
                264,
                3542,
                295,
                264,
                1249,
                2445,
                293,
                321,
                1888,
                264,
                3069,
                300,
                575,
                264,
                1151,
                420,
                264,
                6343,
                1249,
                2158,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08671952910342459,
            "compression_ratio": 1.6818181818181819,
            "no_speech_prob": 0.17969469726085663
        },
        {
            "id": 397,
            "seek": 192490,
            "start": 1924.9,
            "end": 1934.9,
            "text": " That is very dangerous in many cases because of the fact that it's always going to pick the best value for a given state. There's no stochasticity in that pipeline.",
            "tokens": [
                50364,
                663,
                307,
                588,
                5795,
                294,
                867,
                3331,
                570,
                295,
                264,
                1186,
                300,
                309,
                311,
                1009,
                516,
                281,
                1888,
                264,
                1151,
                2158,
                337,
                257,
                2212,
                1785,
                13,
                821,
                311,
                572,
                342,
                8997,
                2750,
                507,
                294,
                300,
                15517,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05056152531975194,
            "compression_ratio": 1.5890410958904109,
            "no_speech_prob": 0.19796931743621826
        },
        {
            "id": 398,
            "seek": 192490,
            "start": 1934.9,
            "end": 1944.9,
            "text": " So you can very frequently get caught in situations where you keep repeating the same actions and you don't learn to explore potentially different options that you may be thinking of.",
            "tokens": [
                50864,
                407,
                291,
                393,
                588,
                10374,
                483,
                5415,
                294,
                6851,
                689,
                291,
                1066,
                18617,
                264,
                912,
                5909,
                293,
                291,
                500,
                380,
                1466,
                281,
                6839,
                7263,
                819,
                3956,
                300,
                291,
                815,
                312,
                1953,
                295,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05056152531975194,
            "compression_ratio": 1.5890410958904109,
            "no_speech_prob": 0.19796931743621826
        },
        {
            "id": 399,
            "seek": 194490,
            "start": 1944.9,
            "end": 1960.9,
            "text": " So to address these very important challenges, that's hopefully going to motivate now the next part of today's lecture, which is going to be focused on policy learning, which is a different class of reinforcement learning algorithms that are different than QLearning algorithms.",
            "tokens": [
                50364,
                407,
                281,
                2985,
                613,
                588,
                1021,
                4759,
                11,
                300,
                311,
                4696,
                516,
                281,
                28497,
                586,
                264,
                958,
                644,
                295,
                965,
                311,
                7991,
                11,
                597,
                307,
                516,
                281,
                312,
                5178,
                322,
                3897,
                2539,
                11,
                597,
                307,
                257,
                819,
                1508,
                295,
                29280,
                2539,
                14642,
                300,
                366,
                819,
                813,
                1249,
                11020,
                2341,
                14642,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0705714225769043,
            "compression_ratio": 1.606936416184971,
            "no_speech_prob": 0.05650955066084862
        },
        {
            "id": 400,
            "seek": 196090,
            "start": 1960.9,
            "end": 1976.9,
            "text": " And like I said, those are called policy grading algorithms and policy grading algorithms. The main difference is that instead of trying to infer the policy from the Q function, we're just going to build a neural network that will directly learn that policy function from the data, right.",
            "tokens": [
                50364,
                400,
                411,
                286,
                848,
                11,
                729,
                366,
                1219,
                3897,
                35540,
                14642,
                293,
                3897,
                35540,
                14642,
                13,
                440,
                2135,
                2649,
                307,
                300,
                2602,
                295,
                1382,
                281,
                13596,
                264,
                3897,
                490,
                264,
                1249,
                2445,
                11,
                321,
                434,
                445,
                516,
                281,
                1322,
                257,
                18161,
                3209,
                300,
                486,
                3838,
                1466,
                300,
                3897,
                2445,
                490,
                264,
                1412,
                11,
                558,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0873270332813263,
            "compression_ratio": 1.6851851851851851,
            "no_speech_prob": 0.3167664706707001
        },
        {
            "id": 401,
            "seek": 196090,
            "start": 1976.9,
            "end": 1982.9,
            "text": " So it kind of skips one step and we'll see how we can train those networks.",
            "tokens": [
                51164,
                407,
                309,
                733,
                295,
                1110,
                2600,
                472,
                1823,
                293,
                321,
                603,
                536,
                577,
                321,
                393,
                3847,
                729,
                9590,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0873270332813263,
            "compression_ratio": 1.6851851851851851,
            "no_speech_prob": 0.3167664706707001
        },
        {
            "id": 402,
            "seek": 198290,
            "start": 1982.9,
            "end": 1988.9,
            "text": " So before we get there, let me just revisit one more time the Q function illustration that we're looking at, right.",
            "tokens": [
                50364,
                407,
                949,
                321,
                483,
                456,
                11,
                718,
                385,
                445,
                32676,
                472,
                544,
                565,
                264,
                1249,
                2445,
                22645,
                300,
                321,
                434,
                1237,
                412,
                11,
                558,
                13,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11862032413482666,
            "compression_ratio": 1.7061611374407584,
            "no_speech_prob": 0.01222721766680479
        },
        {
            "id": 403,
            "seek": 198290,
            "start": 1988.9,
            "end": 2004.9,
            "text": " Q function, we're trying to build a neural network outputs these Q values, one value per action, and we determine the policy by looking over this state of Q values, picking the value that has the highest and looking at its corresponding action.",
            "tokens": [
                50664,
                1249,
                2445,
                11,
                321,
                434,
                1382,
                281,
                1322,
                257,
                18161,
                3209,
                23930,
                613,
                1249,
                4190,
                11,
                472,
                2158,
                680,
                3069,
                11,
                293,
                321,
                6997,
                264,
                3897,
                538,
                1237,
                670,
                341,
                1785,
                295,
                1249,
                4190,
                11,
                8867,
                264,
                2158,
                300,
                575,
                264,
                6343,
                293,
                1237,
                412,
                1080,
                11760,
                3069,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11862032413482666,
            "compression_ratio": 1.7061611374407584,
            "no_speech_prob": 0.01222721766680479
        },
        {
            "id": 404,
            "seek": 200490,
            "start": 2004.9,
            "end": 2017.9,
            "text": " Now with policy networks, the idea that we want to keep here is that instead of predicting the Q values themselves, let's directly try to optimize this policy function here. We're calling the policy function pi of s, right.",
            "tokens": [
                50364,
                823,
                365,
                3897,
                9590,
                11,
                264,
                1558,
                300,
                321,
                528,
                281,
                1066,
                510,
                307,
                300,
                2602,
                295,
                32884,
                264,
                1249,
                4190,
                2969,
                11,
                718,
                311,
                3838,
                853,
                281,
                19719,
                341,
                3897,
                2445,
                510,
                13,
                492,
                434,
                5141,
                264,
                3897,
                2445,
                3895,
                295,
                262,
                11,
                558,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11889129593258813,
            "compression_ratio": 1.7177033492822966,
            "no_speech_prob": 0.05825536325573921
        },
        {
            "id": 405,
            "seek": 200490,
            "start": 2017.9,
            "end": 2026.9,
            "text": " So pi is the policy s is our state. So it's a function that takes as input only the state and it's going to directly output the action.",
            "tokens": [
                51014,
                407,
                3895,
                307,
                264,
                3897,
                262,
                307,
                527,
                1785,
                13,
                407,
                309,
                311,
                257,
                2445,
                300,
                2516,
                382,
                4846,
                787,
                264,
                1785,
                293,
                309,
                311,
                516,
                281,
                3838,
                5598,
                264,
                3069,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11889129593258813,
            "compression_ratio": 1.7177033492822966,
            "no_speech_prob": 0.05825536325573921
        },
        {
            "id": 406,
            "seek": 202690,
            "start": 2026.9,
            "end": 2033.9,
            "text": " So the outputs here give us the desired action that we should take in any given state that we find ourselves in.",
            "tokens": [
                50364,
                407,
                264,
                23930,
                510,
                976,
                505,
                264,
                14721,
                3069,
                300,
                321,
                820,
                747,
                294,
                604,
                2212,
                1785,
                300,
                321,
                915,
                4175,
                294,
                13,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06141093282988577,
            "compression_ratio": 1.6881720430107527,
            "no_speech_prob": 0.06638827919960022
        },
        {
            "id": 407,
            "seek": 202690,
            "start": 2033.9,
            "end": 2047.9,
            "text": " And that represents not only the best action that we should take, but let's denote this as basically the probability that selecting that action would result in a very desirable outcome for our network.",
            "tokens": [
                50714,
                400,
                300,
                8855,
                406,
                787,
                264,
                1151,
                3069,
                300,
                321,
                820,
                747,
                11,
                457,
                718,
                311,
                45708,
                341,
                382,
                1936,
                264,
                8482,
                300,
                18182,
                300,
                3069,
                576,
                1874,
                294,
                257,
                588,
                30533,
                9700,
                337,
                527,
                3209,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06141093282988577,
            "compression_ratio": 1.6881720430107527,
            "no_speech_prob": 0.06638827919960022
        },
        {
            "id": 408,
            "seek": 204790,
            "start": 2047.9,
            "end": 2057.9,
            "text": " So not necessarily the value of that that action, but rather the probability that selecting that action would be the highest value, right.",
            "tokens": [
                50364,
                407,
                406,
                4725,
                264,
                2158,
                295,
                300,
                300,
                3069,
                11,
                457,
                2831,
                264,
                8482,
                300,
                18182,
                300,
                3069,
                576,
                312,
                264,
                6343,
                2158,
                11,
                558,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06709101292994116,
            "compression_ratio": 1.9191919191919191,
            "no_speech_prob": 0.5755826830863953
        },
        {
            "id": 409,
            "seek": 204790,
            "start": 2057.9,
            "end": 2073.9,
            "text": " So you don't care exactly about what is the numerical value that selecting this action takes or gives rise to rather, but rather what is the likelihood that selecting this action will give you the best performing value that you could expect.",
            "tokens": [
                50864,
                407,
                291,
                500,
                380,
                1127,
                2293,
                466,
                437,
                307,
                264,
                29054,
                2158,
                300,
                18182,
                341,
                3069,
                2516,
                420,
                2709,
                6272,
                281,
                2831,
                11,
                457,
                2831,
                437,
                307,
                264,
                22119,
                300,
                18182,
                341,
                3069,
                486,
                976,
                291,
                264,
                1151,
                10205,
                2158,
                300,
                291,
                727,
                2066,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06709101292994116,
            "compression_ratio": 1.9191919191919191,
            "no_speech_prob": 0.5755826830863953
        },
        {
            "id": 410,
            "seek": 207390,
            "start": 2073.9,
            "end": 2082.9,
            "text": " Exact value itself doesn't matter. You only care about if selecting this action is going to give you with high likelihood the best one.",
            "tokens": [
                50364,
                7199,
                2158,
                2564,
                1177,
                380,
                1871,
                13,
                509,
                787,
                1127,
                466,
                498,
                18182,
                341,
                3069,
                307,
                516,
                281,
                976,
                291,
                365,
                1090,
                22119,
                264,
                1151,
                472,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1405855858162658,
            "compression_ratio": 1.5714285714285714,
            "no_speech_prob": 0.12893357872962952
        },
        {
            "id": 411,
            "seek": 207390,
            "start": 2082.9,
            "end": 2099.9,
            "text": " So we can see that if these predicted probabilities here, right, in this example of Atari, right, going left has the probability of being the highest value action with 90% staying in the center.",
            "tokens": [
                50814,
                407,
                321,
                393,
                536,
                300,
                498,
                613,
                19147,
                33783,
                510,
                11,
                558,
                11,
                294,
                341,
                1365,
                295,
                41381,
                11,
                558,
                11,
                516,
                1411,
                575,
                264,
                8482,
                295,
                885,
                264,
                6343,
                2158,
                3069,
                365,
                4289,
                4,
                7939,
                294,
                264,
                3056,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1405855858162658,
            "compression_ratio": 1.5714285714285714,
            "no_speech_prob": 0.12893357872962952
        },
        {
            "id": 412,
            "seek": 209990,
            "start": 2099.9,
            "end": 2116.9,
            "text": " That's a probability of 10% going right is 0%. So ideally, what our neural networks should do in this case is 90% of the time in this situation go to the left 10% of the time, it could still try staying where it is, but never it should go to the right.",
            "tokens": [
                50364,
                663,
                311,
                257,
                8482,
                295,
                1266,
                4,
                516,
                558,
                307,
                1958,
                6856,
                407,
                22915,
                11,
                437,
                527,
                18161,
                9590,
                820,
                360,
                294,
                341,
                1389,
                307,
                4289,
                4,
                295,
                264,
                565,
                294,
                341,
                2590,
                352,
                281,
                264,
                1411,
                1266,
                4,
                295,
                264,
                565,
                11,
                309,
                727,
                920,
                853,
                7939,
                689,
                309,
                307,
                11,
                457,
                1128,
                309,
                820,
                352,
                281,
                264,
                558,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1449962909405048,
            "compression_ratio": 1.5,
            "no_speech_prob": 0.06543080508708954
        },
        {
            "id": 413,
            "seek": 211690,
            "start": 2116.9,
            "end": 2128.9,
            "text": " Now note that this now is a probability distribution. This is very different than a q function. A q function has actually no structure, right. The q values themselves can take any real number, right.",
            "tokens": [
                50364,
                823,
                3637,
                300,
                341,
                586,
                307,
                257,
                8482,
                7316,
                13,
                639,
                307,
                588,
                819,
                813,
                257,
                9505,
                2445,
                13,
                316,
                9505,
                2445,
                575,
                767,
                572,
                3877,
                11,
                558,
                13,
                440,
                9505,
                4190,
                2969,
                393,
                747,
                604,
                957,
                1230,
                11,
                558,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.20865586598714192,
            "compression_ratio": 1.4214285714285715,
            "no_speech_prob": 0.3980013132095337
        },
        {
            "id": 414,
            "seek": 212890,
            "start": 2128.9,
            "end": 2141.9,
            "text": " But here the policy network has a very formulated output all of the numbers here in the output have to sum to one because this is a probability distribution, right.",
            "tokens": [
                50364,
                583,
                510,
                264,
                3897,
                3209,
                575,
                257,
                588,
                48936,
                5598,
                439,
                295,
                264,
                3547,
                510,
                294,
                264,
                5598,
                362,
                281,
                2408,
                281,
                472,
                570,
                341,
                307,
                257,
                8482,
                7316,
                11,
                558,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10500045320880946,
            "compression_ratio": 1.5904255319148937,
            "no_speech_prob": 0.4486595392227173
        },
        {
            "id": 415,
            "seek": 212890,
            "start": 2141.9,
            "end": 2151.9,
            "text": " And that gives it a very rigorous version of how we can train this model that makes it a bit easier to train than q functions as well.",
            "tokens": [
                51014,
                400,
                300,
                2709,
                309,
                257,
                588,
                29882,
                3037,
                295,
                577,
                321,
                393,
                3847,
                341,
                2316,
                300,
                1669,
                309,
                257,
                857,
                3571,
                281,
                3847,
                813,
                9505,
                6828,
                382,
                731,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10500045320880946,
            "compression_ratio": 1.5904255319148937,
            "no_speech_prob": 0.4486595392227173
        },
        {
            "id": 416,
            "seek": 215190,
            "start": 2151.9,
            "end": 2165.9,
            "text": " So one other very important advantage of having an output that is a probability distribution is actually going to tie back to this other issue of q functions and q neural networks that we saw before.",
            "tokens": [
                50364,
                407,
                472,
                661,
                588,
                1021,
                5002,
                295,
                1419,
                364,
                5598,
                300,
                307,
                257,
                8482,
                7316,
                307,
                767,
                516,
                281,
                7582,
                646,
                281,
                341,
                661,
                2734,
                295,
                9505,
                6828,
                293,
                9505,
                18161,
                9590,
                300,
                321,
                1866,
                949,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08643474334325546,
            "compression_ratio": 1.6755555555555555,
            "no_speech_prob": 0.012414390221238136
        },
        {
            "id": 417,
            "seek": 215190,
            "start": 2165.9,
            "end": 2176.9,
            "text": " And that is the fact that q functions are naturally suited towards discrete action spaces. Now when we're looking at this policy network, we're outputting a distribution, right.",
            "tokens": [
                51064,
                400,
                300,
                307,
                264,
                1186,
                300,
                9505,
                6828,
                366,
                8195,
                24736,
                3030,
                27706,
                3069,
                7673,
                13,
                823,
                562,
                321,
                434,
                1237,
                412,
                341,
                3897,
                3209,
                11,
                321,
                434,
                5598,
                783,
                257,
                7316,
                11,
                558,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08643474334325546,
            "compression_ratio": 1.6755555555555555,
            "no_speech_prob": 0.012414390221238136
        },
        {
            "id": 418,
            "seek": 217690,
            "start": 2176.9,
            "end": 2191.9,
            "text": " And remember those distributions can also take continuous forms. In fact, we've seen this in the last two lectures, right. In the generative lecture, we saw how VIEs could be used to predict Gaussian distributions over their latent space.",
            "tokens": [
                50364,
                400,
                1604,
                729,
                37870,
                393,
                611,
                747,
                10957,
                6422,
                13,
                682,
                1186,
                11,
                321,
                600,
                1612,
                341,
                294,
                264,
                1036,
                732,
                16564,
                11,
                558,
                13,
                682,
                264,
                1337,
                1166,
                7991,
                11,
                321,
                1866,
                577,
                691,
                6550,
                82,
                727,
                312,
                1143,
                281,
                6069,
                39148,
                37870,
                670,
                641,
                48994,
                1901,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15380997927683704,
            "compression_ratio": 1.4424242424242424,
            "no_speech_prob": 0.15150004625320435
        },
        {
            "id": 419,
            "seek": 219190,
            "start": 2191.9,
            "end": 2216.9,
            "text": " And the last lecture, we also saw how we could learn to predict uncertainties, which are continuous probability distributions using data. And just like that, we could also use this same formulation to move beyond discrete action spaces, like you can see here, which are one possible action, a probability associated to one possible action in a discrete set of possible actions.",
            "tokens": [
                50364,
                400,
                264,
                1036,
                7991,
                11,
                321,
                611,
                1866,
                577,
                321,
                727,
                1466,
                281,
                6069,
                11308,
                6097,
                11,
                597,
                366,
                10957,
                8482,
                37870,
                1228,
                1412,
                13,
                400,
                445,
                411,
                300,
                11,
                321,
                727,
                611,
                764,
                341,
                912,
                37642,
                281,
                1286,
                4399,
                27706,
                3069,
                7673,
                11,
                411,
                291,
                393,
                536,
                510,
                11,
                597,
                366,
                472,
                1944,
                3069,
                11,
                257,
                8482,
                6615,
                281,
                472,
                1944,
                3069,
                294,
                257,
                27706,
                992,
                295,
                1944,
                5909,
                13,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08449532190958658,
            "compression_ratio": 1.7952380952380953,
            "no_speech_prob": 0.6675164103507996
        }
    ],
    [
        {
            "id": 420,
            "seek": 221690,
            "start": 2216.9,
            "end": 2234.9,
            "text": " Now we may have a space, which is not what action should I take go left, right, or send center, but rather how quickly should I move and what direction should I move, right. That is a continuous variable as opposed to a discrete variable. And you could say that now the answer should look like this, right.",
            "tokens": [
                50364,
                823,
                321,
                815,
                362,
                257,
                1901,
                11,
                597,
                307,
                406,
                437,
                3069,
                820,
                286,
                747,
                352,
                1411,
                11,
                558,
                11,
                420,
                2845,
                3056,
                11,
                457,
                2831,
                577,
                2661,
                820,
                286,
                1286,
                293,
                437,
                3513,
                820,
                286,
                1286,
                11,
                558,
                13,
                663,
                307,
                257,
                10957,
                7006,
                382,
                8851,
                281,
                257,
                27706,
                7006,
                13,
                400,
                291,
                727,
                584,
                300,
                586,
                264,
                1867,
                820,
                574,
                411,
                341,
                11,
                558,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13171822808005593,
            "compression_ratio": 1.842911877394636,
            "no_speech_prob": 0.1515277773141861
        },
        {
            "id": 421,
            "seek": 221690,
            "start": 2234.9,
            "end": 2244.9,
            "text": " Moving very fast to the right versus very slow to the or excuse me, very fast to the left versus very slow to the left has this continuous spectrum that we may want to model.",
            "tokens": [
                51264,
                14242,
                588,
                2370,
                281,
                264,
                558,
                5717,
                588,
                2964,
                281,
                264,
                420,
                8960,
                385,
                11,
                588,
                2370,
                281,
                264,
                1411,
                5717,
                588,
                2964,
                281,
                264,
                1411,
                575,
                341,
                10957,
                11143,
                300,
                321,
                815,
                528,
                281,
                2316,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13171822808005593,
            "compression_ratio": 1.842911877394636,
            "no_speech_prob": 0.1515277773141861
        },
        {
            "id": 422,
            "seek": 224490,
            "start": 2244.9,
            "end": 2266.9,
            "text": " Now when we plot this entire distribution of taking an action, giving a state, you can see basically a very simple illustration of that right here. This distribution has most of its mass over, or sorry, it has all of its mass over the entire real number line, first of all, it has most of its mass, right, in the optimal action space that we want to take.",
            "tokens": [
                50364,
                823,
                562,
                321,
                7542,
                341,
                2302,
                7316,
                295,
                1940,
                364,
                3069,
                11,
                2902,
                257,
                1785,
                11,
                291,
                393,
                536,
                1936,
                257,
                588,
                2199,
                22645,
                295,
                300,
                558,
                510,
                13,
                639,
                7316,
                575,
                881,
                295,
                1080,
                2758,
                670,
                11,
                420,
                2597,
                11,
                309,
                575,
                439,
                295,
                1080,
                2758,
                670,
                264,
                2302,
                957,
                1230,
                1622,
                11,
                700,
                295,
                439,
                11,
                309,
                575,
                881,
                295,
                1080,
                2758,
                11,
                558,
                11,
                294,
                264,
                16252,
                3069,
                1901,
                300,
                321,
                528,
                281,
                747,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10118838054377859,
            "compression_ratio": 1.7574257425742574,
            "no_speech_prob": 0.030173256993293762
        },
        {
            "id": 423,
            "seek": 226690,
            "start": 2266.9,
            "end": 2277.9,
            "text": " So if we want to determine the best action to take, we would simply take the mode of this distribution, right, the highest point, that would be the speed at which we should move and the direction that we should move in.",
            "tokens": [
                50364,
                407,
                498,
                321,
                528,
                281,
                6997,
                264,
                1151,
                3069,
                281,
                747,
                11,
                321,
                576,
                2935,
                747,
                264,
                4391,
                295,
                341,
                7316,
                11,
                558,
                11,
                264,
                6343,
                935,
                11,
                300,
                576,
                312,
                264,
                3073,
                412,
                597,
                321,
                820,
                1286,
                293,
                264,
                3513,
                300,
                321,
                820,
                1286,
                294,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07864339177201433,
            "compression_ratio": 1.75,
            "no_speech_prob": 0.4285060465335846
        },
        {
            "id": 424,
            "seek": 226690,
            "start": 2277.9,
            "end": 2286.9,
            "text": " If we wanted to also try out different things and explore our space, we could sample from this distribution and still obtain some stochasticity.",
            "tokens": [
                50914,
                759,
                321,
                1415,
                281,
                611,
                853,
                484,
                819,
                721,
                293,
                6839,
                527,
                1901,
                11,
                321,
                727,
                6889,
                490,
                341,
                7316,
                293,
                920,
                12701,
                512,
                342,
                8997,
                2750,
                507,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07864339177201433,
            "compression_ratio": 1.75,
            "no_speech_prob": 0.4285060465335846
        },
        {
            "id": 425,
            "seek": 228690,
            "start": 2286.9,
            "end": 2302.9,
            "text": " Now let's look at an example of how we could actually model these continuous distributions and actually we've already seen some examples of this in the previous two lectures, like I mentioned, but let's take a look specifically in the context of reinforcement learning and policy gradient learning.",
            "tokens": [
                50364,
                823,
                718,
                311,
                574,
                412,
                364,
                1365,
                295,
                577,
                321,
                727,
                767,
                2316,
                613,
                10957,
                37870,
                293,
                767,
                321,
                600,
                1217,
                1612,
                512,
                5110,
                295,
                341,
                294,
                264,
                3894,
                732,
                16564,
                11,
                411,
                286,
                2835,
                11,
                457,
                718,
                311,
                747,
                257,
                574,
                4682,
                294,
                264,
                4319,
                295,
                29280,
                2539,
                293,
                3897,
                16235,
                2539,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09977017599960854,
            "compression_ratio": 1.6021505376344085,
            "no_speech_prob": 0.24432876706123352
        },
        {
            "id": 426,
            "seek": 230290,
            "start": 2303.9,
            "end": 2319.9,
            "text": " So instead of predicting this probability of taking an action, giving all possible states, which in this case there is now an infinite number of, because we're in the continuous domain, we can't simply predict a single probability for every possible action, because there is an infinite number of them.",
            "tokens": [
                50414,
                407,
                2602,
                295,
                32884,
                341,
                8482,
                295,
                1940,
                364,
                3069,
                11,
                2902,
                439,
                1944,
                4368,
                11,
                597,
                294,
                341,
                1389,
                456,
                307,
                586,
                364,
                13785,
                1230,
                295,
                11,
                570,
                321,
                434,
                294,
                264,
                10957,
                9274,
                11,
                321,
                393,
                380,
                2935,
                6069,
                257,
                2167,
                8482,
                337,
                633,
                1944,
                3069,
                11,
                570,
                456,
                307,
                364,
                13785,
                1230,
                295,
                552,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10280903710259331,
            "compression_ratio": 1.7966804979253113,
            "no_speech_prob": 0.7390050888061523
        },
        {
            "id": 427,
            "seek": 230290,
            "start": 2319.9,
            "end": 2328.9,
            "text": " So instead, what if we parameterized our action space by distribution, right, so let's take for example the Gaussian distribution.",
            "tokens": [
                51214,
                407,
                2602,
                11,
                437,
                498,
                321,
                13075,
                1602,
                527,
                3069,
                1901,
                538,
                7316,
                11,
                558,
                11,
                370,
                718,
                311,
                747,
                337,
                1365,
                264,
                39148,
                7316,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10280903710259331,
            "compression_ratio": 1.7966804979253113,
            "no_speech_prob": 0.7390050888061523
        },
        {
            "id": 428,
            "seek": 232890,
            "start": 2329.9,
            "end": 2344.9,
            "text": " To parameterize a Gaussian distribution, we only need two outputs, right, we need a mean and a variance, given the mean and a variance, we can actually have a probability mass and we can compute a probability over any possible action that we may want to take just from those two numbers.",
            "tokens": [
                50414,
                1407,
                13075,
                1125,
                257,
                39148,
                7316,
                11,
                321,
                787,
                643,
                732,
                23930,
                11,
                558,
                11,
                321,
                643,
                257,
                914,
                293,
                257,
                21977,
                11,
                2212,
                264,
                914,
                293,
                257,
                21977,
                11,
                321,
                393,
                767,
                362,
                257,
                8482,
                2758,
                293,
                321,
                393,
                14722,
                257,
                8482,
                670,
                604,
                1944,
                3069,
                300,
                321,
                815,
                528,
                281,
                747,
                445,
                490,
                729,
                732,
                3547,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09764409443688771,
            "compression_ratio": 1.6123595505617978,
            "no_speech_prob": 0.14369206130504608
        },
        {
            "id": 429,
            "seek": 234490,
            "start": 2345.9,
            "end": 2363.9,
            "text": " So for example, in this image here, we may want to output a Gaussian that looks like this, right, its mean is centered at, let's see, negative 0.8 indicating that we should move basically left with a speed of 0.8 meters per second, for example.",
            "tokens": [
                50414,
                407,
                337,
                1365,
                11,
                294,
                341,
                3256,
                510,
                11,
                321,
                815,
                528,
                281,
                5598,
                257,
                39148,
                300,
                1542,
                411,
                341,
                11,
                558,
                11,
                1080,
                914,
                307,
                18988,
                412,
                11,
                718,
                311,
                536,
                11,
                3671,
                1958,
                13,
                23,
                25604,
                300,
                321,
                820,
                1286,
                1936,
                1411,
                365,
                257,
                3073,
                295,
                1958,
                13,
                23,
                8146,
                680,
                1150,
                11,
                337,
                1365,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0731953497855894,
            "compression_ratio": 1.4186046511627908,
            "no_speech_prob": 0.5821996331214905
        },
        {
            "id": 430,
            "seek": 236390,
            "start": 2363.9,
            "end": 2384.9,
            "text": " And again, we can see that because this is a probability distribution, because of the format of policy networks, right, we're enforcing that this is a probability distribution, that means that the integral now of this of this outputs, right, by definition of it being a Gaussian must also integrate to 1.",
            "tokens": [
                50364,
                400,
                797,
                11,
                321,
                393,
                536,
                300,
                570,
                341,
                307,
                257,
                8482,
                7316,
                11,
                570,
                295,
                264,
                7877,
                295,
                3897,
                9590,
                11,
                558,
                11,
                321,
                434,
                25495,
                2175,
                300,
                341,
                307,
                257,
                8482,
                7316,
                11,
                300,
                1355,
                300,
                264,
                11573,
                586,
                295,
                341,
                295,
                341,
                23930,
                11,
                558,
                11,
                538,
                7123,
                295,
                309,
                885,
                257,
                39148,
                1633,
                611,
                13365,
                281,
                502,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0989797187573982,
            "compression_ratio": 1.7471264367816093,
            "no_speech_prob": 0.05311833322048187
        },
        {
            "id": 431,
            "seek": 238490,
            "start": 2385.9,
            "end": 2405.9,
            "text": " Okay, great. So now let's maybe take a look at how policy gradient networks can be trained and you know step through that process as well as we look at a very concrete example and maybe let's start by just revisiting this reinforcement learning loop that we've started this class with.",
            "tokens": [
                50414,
                1033,
                11,
                869,
                13,
                407,
                586,
                718,
                311,
                1310,
                747,
                257,
                574,
                412,
                577,
                3897,
                16235,
                9590,
                393,
                312,
                8895,
                293,
                291,
                458,
                1823,
                807,
                300,
                1399,
                382,
                731,
                382,
                321,
                574,
                412,
                257,
                588,
                9859,
                1365,
                293,
                1310,
                718,
                311,
                722,
                538,
                445,
                20767,
                1748,
                341,
                29280,
                2539,
                6367,
                300,
                321,
                600,
                1409,
                341,
                1508,
                365,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12701858243634623,
            "compression_ratio": 1.5240641711229947,
            "no_speech_prob": 0.0153565164655447
        },
        {
            "id": 432,
            "seek": 240590,
            "start": 2406.9,
            "end": 2425.9,
            "text": " Now, let's specifically consider the example of training an autonomous vehicle since I think that this is a particularly very intuitive example that we can walk through the agent here is the vehicle, right, the state could be obtained through many sensors that could be mounted on the vehicle itself.",
            "tokens": [
                50414,
                823,
                11,
                718,
                311,
                4682,
                1949,
                264,
                1365,
                295,
                3097,
                364,
                23797,
                5864,
                1670,
                286,
                519,
                300,
                341,
                307,
                257,
                4098,
                588,
                21769,
                1365,
                300,
                321,
                393,
                1792,
                807,
                264,
                9461,
                510,
                307,
                264,
                5864,
                11,
                558,
                11,
                264,
                1785,
                727,
                312,
                14879,
                807,
                867,
                14840,
                300,
                727,
                312,
                19138,
                322,
                264,
                5864,
                2564,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10036453150086484,
            "compression_ratio": 1.5957446808510638,
            "no_speech_prob": 0.12347869575023651
        },
        {
            "id": 433,
            "seek": 242590,
            "start": 2425.9,
            "end": 2436.9,
            "text": " So, for example, autonomous vehicles are typically equipped with sensors like cameras, light hours, radars, etc. All of these are giving observational inputs to the, to the vehicle.",
            "tokens": [
                50364,
                407,
                11,
                337,
                1365,
                11,
                23797,
                8948,
                366,
                5850,
                15218,
                365,
                14840,
                411,
                8622,
                11,
                1442,
                2496,
                11,
                2843,
                685,
                11,
                5183,
                13,
                1057,
                295,
                613,
                366,
                2902,
                9951,
                1478,
                15743,
                281,
                264,
                11,
                281,
                264,
                5864,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1382771005817488,
            "compression_ratio": 1.709433962264151,
            "no_speech_prob": 0.43164488673210144
        },
        {
            "id": 434,
            "seek": 242590,
            "start": 2436.9,
            "end": 2445.9,
            "text": " The action that we could take is a steer angle, this is not a discrete variable, this is a continuous variable, it's actually an angle that could take any real number.",
            "tokens": [
                50914,
                440,
                3069,
                300,
                321,
                727,
                747,
                307,
                257,
                30814,
                5802,
                11,
                341,
                307,
                406,
                257,
                27706,
                7006,
                11,
                341,
                307,
                257,
                10957,
                7006,
                11,
                309,
                311,
                767,
                364,
                5802,
                300,
                727,
                747,
                604,
                957,
                1230,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1382771005817488,
            "compression_ratio": 1.709433962264151,
            "no_speech_prob": 0.43164488673210144
        },
        {
            "id": 435,
            "seek": 242590,
            "start": 2445.9,
            "end": 2453.9,
            "text": " And finally, the reward in this very simplistic example is the distance that we travel before we crash.",
            "tokens": [
                51364,
                400,
                2721,
                11,
                264,
                7782,
                294,
                341,
                588,
                44199,
                1365,
                307,
                264,
                4560,
                300,
                321,
                3147,
                949,
                321,
                8252,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1382771005817488,
            "compression_ratio": 1.709433962264151,
            "no_speech_prob": 0.43164488673210144
        },
        {
            "id": 436,
            "seek": 245390,
            "start": 2453.9,
            "end": 2462.9,
            "text": " So now let's take a look at how we could train a policy gradient neural network to solve this task of self driving cars as a concrete example.",
            "tokens": [
                50364,
                407,
                586,
                718,
                311,
                747,
                257,
                574,
                412,
                577,
                321,
                727,
                3847,
                257,
                3897,
                16235,
                18161,
                3209,
                281,
                5039,
                341,
                5633,
                295,
                2698,
                4840,
                5163,
                382,
                257,
                9859,
                1365,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09876041534619454,
            "compression_ratio": 1.5905172413793103,
            "no_speech_prob": 7.71832128521055e-05
        },
        {
            "id": 437,
            "seek": 245390,
            "start": 2462.9,
            "end": 2475.9,
            "text": " So we start by initializing our agent, right, remember that we have no training data, right. So we have to think about actually reinforcement learning is almost like a data acquisition plus learning pipeline combined together.",
            "tokens": [
                50814,
                407,
                321,
                722,
                538,
                5883,
                3319,
                527,
                9461,
                11,
                558,
                11,
                1604,
                300,
                321,
                362,
                572,
                3097,
                1412,
                11,
                558,
                13,
                407,
                321,
                362,
                281,
                519,
                466,
                767,
                29280,
                2539,
                307,
                1920,
                411,
                257,
                1412,
                21668,
                1804,
                2539,
                15517,
                9354,
                1214,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09876041534619454,
            "compression_ratio": 1.5905172413793103,
            "no_speech_prob": 7.71832128521055e-05
        },
        {
            "id": 438,
            "seek": 247590,
            "start": 2475.9,
            "end": 2483.9,
            "text": " So the first part of that data acquisition pipeline is first to initialize our agent to go out and collect some data.",
            "tokens": [
                50364,
                407,
                264,
                700,
                644,
                295,
                300,
                1412,
                21668,
                15517,
                307,
                700,
                281,
                5883,
                1125,
                527,
                9461,
                281,
                352,
                484,
                293,
                2500,
                512,
                1412,
                13,
                50764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08348858524376238,
            "compression_ratio": 1.5816326530612246,
            "no_speech_prob": 0.37580567598342896
        },
        {
            "id": 439,
            "seek": 247590,
            "start": 2483.9,
            "end": 2494.9,
            "text": " So we start our vehicle, our agent, and in the beginning, of course, it knows nothing about driving. It's never been exposed to any of these rules of the environment or the observation before.",
            "tokens": [
                50764,
                407,
                321,
                722,
                527,
                5864,
                11,
                527,
                9461,
                11,
                293,
                294,
                264,
                2863,
                11,
                295,
                1164,
                11,
                309,
                3255,
                1825,
                466,
                4840,
                13,
                467,
                311,
                1128,
                668,
                9495,
                281,
                604,
                295,
                613,
                4474,
                295,
                264,
                2823,
                420,
                264,
                14816,
                949,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08348858524376238,
            "compression_ratio": 1.5816326530612246,
            "no_speech_prob": 0.37580567598342896
        },
        {
            "id": 440,
            "seek": 249490,
            "start": 2494.9,
            "end": 2509.9,
            "text": " So it runs its policy, which right now is untrained entirely until it terminates, right, until it goes outside of some bounds that we define, we measure basically the reward as the distance that we traveled before it terminated.",
            "tokens": [
                50364,
                407,
                309,
                6676,
                1080,
                3897,
                11,
                597,
                558,
                586,
                307,
                1701,
                31774,
                7696,
                1826,
                309,
                10761,
                1024,
                11,
                558,
                11,
                1826,
                309,
                1709,
                2380,
                295,
                512,
                29905,
                300,
                321,
                6964,
                11,
                321,
                3481,
                1936,
                264,
                7782,
                382,
                264,
                4560,
                300,
                321,
                16147,
                949,
                309,
                1433,
                5410,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11337877511978149,
            "compression_ratio": 1.7412935323383085,
            "no_speech_prob": 0.7131907939910889
        },
        {
            "id": 441,
            "seek": 249490,
            "start": 2509.9,
            "end": 2518.9,
            "text": " And we record all of the states, all of the actions, and the final reward that it obtained until that termination, right.",
            "tokens": [
                51114,
                400,
                321,
                2136,
                439,
                295,
                264,
                4368,
                11,
                439,
                295,
                264,
                5909,
                11,
                293,
                264,
                2572,
                7782,
                300,
                309,
                14879,
                1826,
                300,
                1433,
                2486,
                11,
                558,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11337877511978149,
            "compression_ratio": 1.7412935323383085,
            "no_speech_prob": 0.7131907939910889
        },
        {
            "id": 442,
            "seek": 251890,
            "start": 2518.9,
            "end": 2523.9,
            "text": " This becomes our mini data set that we'll use for the first round of training.",
            "tokens": [
                50364,
                639,
                3643,
                527,
                8382,
                1412,
                992,
                300,
                321,
                603,
                764,
                337,
                264,
                700,
                3098,
                295,
                3097,
                13,
                50614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1073670809782004,
            "compression_ratio": 1.7333333333333334,
            "no_speech_prob": 0.030597452074289322
        },
        {
            "id": 443,
            "seek": 251890,
            "start": 2523.9,
            "end": 2544.9,
            "text": " Let's take those data sets and now we'll do one step of training. The first step of training that we'll do is to take, excuse me, to take the later half of our trajectory that our agent ran and decrease the probability of actions that resulted in low rewards.",
            "tokens": [
                50614,
                961,
                311,
                747,
                729,
                1412,
                6352,
                293,
                586,
                321,
                603,
                360,
                472,
                1823,
                295,
                3097,
                13,
                440,
                700,
                1823,
                295,
                3097,
                300,
                321,
                603,
                360,
                307,
                281,
                747,
                11,
                8960,
                385,
                11,
                281,
                747,
                264,
                1780,
                1922,
                295,
                527,
                21512,
                300,
                527,
                9461,
                5872,
                293,
                11514,
                264,
                8482,
                295,
                5909,
                300,
                18753,
                294,
                2295,
                17203,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1073670809782004,
            "compression_ratio": 1.7333333333333334,
            "no_speech_prob": 0.030597452074289322
        },
        {
            "id": 444,
            "seek": 254490,
            "start": 2544.9,
            "end": 2557.9,
            "text": " Now, because the vehicle, we know the vehicle terminated, we can assume that all of the actions that occurred in the later half of this trajectory were probably not very good actions because they came very close to termination.",
            "tokens": [
                50364,
                823,
                11,
                570,
                264,
                5864,
                11,
                321,
                458,
                264,
                5864,
                1433,
                5410,
                11,
                321,
                393,
                6552,
                300,
                439,
                295,
                264,
                5909,
                300,
                11068,
                294,
                264,
                1780,
                1922,
                295,
                341,
                21512,
                645,
                1391,
                406,
                588,
                665,
                5909,
                570,
                436,
                1361,
                588,
                1998,
                281,
                1433,
                2486,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07918035152346589,
            "compression_ratio": 1.8461538461538463,
            "no_speech_prob": 0.018772805109620094
        },
        {
            "id": 445,
            "seek": 254490,
            "start": 2557.9,
            "end": 2566.9,
            "text": " So let's decrease the probability of all of those things happening again in the future and we'll take all of the things that happened in the beginning half of our training episode.",
            "tokens": [
                51014,
                407,
                718,
                311,
                11514,
                264,
                8482,
                295,
                439,
                295,
                729,
                721,
                2737,
                797,
                294,
                264,
                2027,
                293,
                321,
                603,
                747,
                439,
                295,
                264,
                721,
                300,
                2011,
                294,
                264,
                2863,
                1922,
                295,
                527,
                3097,
                3500,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07918035152346589,
            "compression_ratio": 1.8461538461538463,
            "no_speech_prob": 0.018772805109620094
        },
        {
            "id": 446,
            "seek": 256690,
            "start": 2566.9,
            "end": 2578.9,
            "text": " And we will increase their probabilities. Now, again, there's no reason why there shouldn't necessarily be a good action that we took in the first half of this trajectory and a bad action in the later half.",
            "tokens": [
                50364,
                400,
                321,
                486,
                3488,
                641,
                33783,
                13,
                823,
                11,
                797,
                11,
                456,
                311,
                572,
                1778,
                983,
                456,
                4659,
                380,
                4725,
                312,
                257,
                665,
                3069,
                300,
                321,
                1890,
                294,
                264,
                700,
                1922,
                295,
                341,
                21512,
                293,
                257,
                1578,
                3069,
                294,
                264,
                1780,
                1922,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05964693912239962,
            "compression_ratio": 1.7236842105263157,
            "no_speech_prob": 0.6658660173416138
        },
        {
            "id": 447,
            "seek": 256690,
            "start": 2578.9,
            "end": 2590.9,
            "text": " But it's simply because actions that are in the later half were closer to a failure and closer determination that we can assume, for example, that these were probably suboptimal actions.",
            "tokens": [
                50964,
                583,
                309,
                311,
                2935,
                570,
                5909,
                300,
                366,
                294,
                264,
                1780,
                1922,
                645,
                4966,
                281,
                257,
                7763,
                293,
                4966,
                18432,
                300,
                321,
                393,
                6552,
                11,
                337,
                1365,
                11,
                300,
                613,
                645,
                1391,
                1422,
                5747,
                10650,
                5909,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.05964693912239962,
            "compression_ratio": 1.7236842105263157,
            "no_speech_prob": 0.6658660173416138
        },
        {
            "id": 448,
            "seek": 259090,
            "start": 2590.9,
            "end": 2603.9,
            "text": " But it's very possible that these are noisy rewards as well because it's such a sparse signal. It's very possible that you had some good actions at the end and you were actually trying to recover your car, but you were just too late.",
            "tokens": [
                50364,
                583,
                309,
                311,
                588,
                1944,
                300,
                613,
                366,
                24518,
                17203,
                382,
                731,
                570,
                309,
                311,
                1270,
                257,
                637,
                11668,
                6358,
                13,
                467,
                311,
                588,
                1944,
                300,
                291,
                632,
                512,
                665,
                5909,
                412,
                264,
                917,
                293,
                291,
                645,
                767,
                1382,
                281,
                8114,
                428,
                1032,
                11,
                457,
                291,
                645,
                445,
                886,
                3469,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09315327361777977,
            "compression_ratio": 1.7640449438202248,
            "no_speech_prob": 0.18832609057426453
        },
        {
            "id": 449,
            "seek": 259090,
            "start": 2603.9,
            "end": 2614.9,
            "text": " Now, repeat this process again. Re-initialize the agent one more time and run it until completion. Now the agent goes a bit farther, right? Because you've decreased the probabilities at the end, increased the probabilities of the future.",
            "tokens": [
                51014,
                823,
                11,
                7149,
                341,
                1399,
                797,
                13,
                1300,
                12,
                259,
                270,
                831,
                1125,
                264,
                9461,
                472,
                544,
                565,
                293,
                1190,
                309,
                1826,
                19372,
                13,
                823,
                264,
                9461,
                1709,
                257,
                857,
                20344,
                11,
                558,
                30,
                1436,
                291,
                600,
                24436,
                264,
                33783,
                412,
                264,
                917,
                11,
                6505,
                264,
                33783,
                295,
                264,
                2027,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09315327361777977,
            "compression_ratio": 1.7640449438202248,
            "no_speech_prob": 0.18832609057426453
        }
    ],
    [
        {
            "id": 450,
            "seek": 261490,
            "start": 2614.9,
            "end": 2633.9,
            "text": " And you keep repeating this over and over again until you notice that the agent learns to perform better and better every time until it finally converges. And at the end, the agent is able to basically follow lanes, usually swarving a bit side to side while it does that, without crashing.",
            "tokens": [
                50364,
                400,
                291,
                1066,
                18617,
                341,
                670,
                293,
                670,
                797,
                1826,
                291,
                3449,
                300,
                264,
                9461,
                27152,
                281,
                2042,
                1101,
                293,
                1101,
                633,
                565,
                1826,
                309,
                2721,
                9652,
                2880,
                13,
                400,
                412,
                264,
                917,
                11,
                264,
                9461,
                307,
                1075,
                281,
                1936,
                1524,
                25397,
                11,
                2673,
                1693,
                289,
                798,
                257,
                857,
                1252,
                281,
                1252,
                1339,
                309,
                775,
                300,
                11,
                1553,
                26900,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10196557641029358,
            "compression_ratio": 1.6327683615819208,
            "no_speech_prob": 0.685928463935852
        },
        {
            "id": 451,
            "seek": 263390,
            "start": 2633.9,
            "end": 2645.9,
            "text": " And this is actually really fascinating because this is a self-driving car that we never taught anything about what a lane marker means or what are the rules of the road, anything about that, right?",
            "tokens": [
                50364,
                400,
                341,
                307,
                767,
                534,
                10343,
                570,
                341,
                307,
                257,
                2698,
                12,
                47094,
                1032,
                300,
                321,
                1128,
                5928,
                1340,
                466,
                437,
                257,
                12705,
                15247,
                1355,
                420,
                437,
                366,
                264,
                4474,
                295,
                264,
                3060,
                11,
                1340,
                466,
                300,
                11,
                558,
                30,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06432714341562006,
            "compression_ratio": 1.6862745098039216,
            "no_speech_prob": 0.785470187664032
        },
        {
            "id": 452,
            "seek": 263390,
            "start": 2645.9,
            "end": 2655.9,
            "text": " This was a car that learned entirely just by going out, crashing a lot, and trying to figure out what to do to not keep doing that in the future.",
            "tokens": [
                50964,
                639,
                390,
                257,
                1032,
                300,
                3264,
                7696,
                445,
                538,
                516,
                484,
                11,
                26900,
                257,
                688,
                11,
                293,
                1382,
                281,
                2573,
                484,
                437,
                281,
                360,
                281,
                406,
                1066,
                884,
                300,
                294,
                264,
                2027,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06432714341562006,
            "compression_ratio": 1.6862745098039216,
            "no_speech_prob": 0.785470187664032
        },
        {
            "id": 453,
            "seek": 265590,
            "start": 2655.9,
            "end": 2684.9,
            "text": " And the remaining question is actually how we can update that policy as part of this algorithm that I'm showing you on the left-hand side. How can we basically formulate that same algorithm and specifically the update equation steps four and five right here? These are the two really important steps of how we can use those two steps to train our policy and decrease the probability of bad events while promoting these likelihoods of all these good events.",
            "tokens": [
                50364,
                400,
                264,
                8877,
                1168,
                307,
                767,
                577,
                321,
                393,
                5623,
                300,
                3897,
                382,
                644,
                295,
                341,
                9284,
                300,
                286,
                478,
                4099,
                291,
                322,
                264,
                1411,
                12,
                5543,
                1252,
                13,
                1012,
                393,
                321,
                1936,
                47881,
                300,
                912,
                9284,
                293,
                4682,
                264,
                5623,
                5367,
                4439,
                1451,
                293,
                1732,
                558,
                510,
                30,
                1981,
                366,
                264,
                732,
                534,
                1021,
                4439,
                295,
                577,
                321,
                393,
                764,
                729,
                732,
                4439,
                281,
                3847,
                527,
                3897,
                293,
                11514,
                264,
                8482,
                295,
                1578,
                3931,
                1339,
                16383,
                613,
                22119,
                82,
                295,
                439,
                613,
                665,
                3931,
                13,
                51814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.104783386654324,
            "compression_ratio": 1.7674418604651163,
            "no_speech_prob": 0.35368338227272034
        },
        {
            "id": 454,
            "seek": 268490,
            "start": 2684.9,
            "end": 2698.9,
            "text": " So let's assume the, let's look at the loss function, first of all, the loss function for a policy gradient neural network looks like this and then we'll start by dissecting it to understand why this works the way it does.",
            "tokens": [
                50364,
                407,
                718,
                311,
                6552,
                264,
                11,
                718,
                311,
                574,
                412,
                264,
                4470,
                2445,
                11,
                700,
                295,
                439,
                11,
                264,
                4470,
                2445,
                337,
                257,
                3897,
                16235,
                18161,
                3209,
                1542,
                411,
                341,
                293,
                550,
                321,
                603,
                722,
                538,
                48332,
                278,
                309,
                281,
                1223,
                983,
                341,
                1985,
                264,
                636,
                309,
                775,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07543353059075096,
            "compression_ratio": 1.7239819004524888,
            "no_speech_prob": 0.002883921843022108
        },
        {
            "id": 455,
            "seek": 268490,
            "start": 2698.9,
            "end": 2708.9,
            "text": " So here we can see that the loss consists of two terms. The first term is this term in green, just called the log likelihood of selecting a particular action.",
            "tokens": [
                51064,
                407,
                510,
                321,
                393,
                536,
                300,
                264,
                4470,
                14689,
                295,
                732,
                2115,
                13,
                440,
                700,
                1433,
                307,
                341,
                1433,
                294,
                3092,
                11,
                445,
                1219,
                264,
                3565,
                22119,
                295,
                18182,
                257,
                1729,
                3069,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07543353059075096,
            "compression_ratio": 1.7239819004524888,
            "no_speech_prob": 0.002883921843022108
        },
        {
            "id": 456,
            "seek": 270890,
            "start": 2708.9,
            "end": 2720.9,
            "text": " The second term is something that all of you are very familiar with already. This is simply the return at a specific time, right? So that's the expected return on the words that you would get after this time point.",
            "tokens": [
                50364,
                440,
                1150,
                1433,
                307,
                746,
                300,
                439,
                295,
                291,
                366,
                588,
                4963,
                365,
                1217,
                13,
                639,
                307,
                2935,
                264,
                2736,
                412,
                257,
                2685,
                565,
                11,
                558,
                30,
                407,
                300,
                311,
                264,
                5176,
                2736,
                322,
                264,
                2283,
                300,
                291,
                576,
                483,
                934,
                341,
                565,
                935,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08429636710729355,
            "compression_ratio": 1.5694444444444444,
            "no_speech_prob": 0.17976951599121094
        },
        {
            "id": 457,
            "seek": 270890,
            "start": 2720.9,
            "end": 2730.9,
            "text": " Now, let's assume that we got a lot of reward for a particular action that had a high log probability or a high probability.",
            "tokens": [
                50964,
                823,
                11,
                718,
                311,
                6552,
                300,
                321,
                658,
                257,
                688,
                295,
                7782,
                337,
                257,
                1729,
                3069,
                300,
                632,
                257,
                1090,
                3565,
                8482,
                420,
                257,
                1090,
                8482,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08429636710729355,
            "compression_ratio": 1.5694444444444444,
            "no_speech_prob": 0.17976951599121094
        },
        {
            "id": 458,
            "seek": 273090,
            "start": 2730.9,
            "end": 2744.9,
            "text": " Right, if we got a lot of reward for a particular action that had high probability, that means that we want to increase that probability even further. So we do it even more or even more likelihood, we sampled that action again into the future.",
            "tokens": [
                50364,
                1779,
                11,
                498,
                321,
                658,
                257,
                688,
                295,
                7782,
                337,
                257,
                1729,
                3069,
                300,
                632,
                1090,
                8482,
                11,
                300,
                1355,
                300,
                321,
                528,
                281,
                3488,
                300,
                8482,
                754,
                3052,
                13,
                407,
                321,
                360,
                309,
                754,
                544,
                420,
                754,
                544,
                22119,
                11,
                321,
                3247,
                15551,
                300,
                3069,
                797,
                666,
                264,
                2027,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0995308186145539,
            "compression_ratio": 1.7929515418502202,
            "no_speech_prob": 0.019690461456775665
        },
        {
            "id": 459,
            "seek": 273090,
            "start": 2744.9,
            "end": 2755.9,
            "text": " On the other hand, if we selected or let's say if we obtained a reward that was very low for an action that had high likelihood, we want the inverse effect, right?",
            "tokens": [
                51064,
                1282,
                264,
                661,
                1011,
                11,
                498,
                321,
                8209,
                420,
                718,
                311,
                584,
                498,
                321,
                14879,
                257,
                7782,
                300,
                390,
                588,
                2295,
                337,
                364,
                3069,
                300,
                632,
                1090,
                22119,
                11,
                321,
                528,
                264,
                17340,
                1802,
                11,
                558,
                30,
                51614
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0995308186145539,
            "compression_ratio": 1.7929515418502202,
            "no_speech_prob": 0.019690461456775665
        },
        {
            "id": 460,
            "seek": 275590,
            "start": 2755.9,
            "end": 2773.9,
            "text": " We never want to sample that action again in the future because it resulted in a low reward. Right, and you'll notice that this loss function right here by including this negative, we're going to minimize the likelihood of achieving any action that had low rewards in this trajectory.",
            "tokens": [
                50364,
                492,
                1128,
                528,
                281,
                6889,
                300,
                3069,
                797,
                294,
                264,
                2027,
                570,
                309,
                18753,
                294,
                257,
                2295,
                7782,
                13,
                1779,
                11,
                293,
                291,
                603,
                3449,
                300,
                341,
                4470,
                2445,
                558,
                510,
                538,
                3009,
                341,
                3671,
                11,
                321,
                434,
                516,
                281,
                17522,
                264,
                22119,
                295,
                19626,
                604,
                3069,
                300,
                632,
                2295,
                17203,
                294,
                341,
                21512,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07314564009844246,
            "compression_ratio": 1.5351351351351352,
            "no_speech_prob": 0.5791872143745422
        },
        {
            "id": 461,
            "seek": 277390,
            "start": 2773.9,
            "end": 2789.9,
            "text": " Now, in our simplified example on the car example, all the things that had low rewards were exactly those actions that came closest to the termination part of the of the vehicle, right? All the things that had high rewards were the things that came in the beginning.",
            "tokens": [
                50364,
                823,
                11,
                294,
                527,
                26335,
                1365,
                322,
                264,
                1032,
                1365,
                11,
                439,
                264,
                721,
                300,
                632,
                2295,
                17203,
                645,
                2293,
                729,
                5909,
                300,
                1361,
                13699,
                281,
                264,
                1433,
                2486,
                644,
                295,
                264,
                295,
                264,
                5864,
                11,
                558,
                30,
                1057,
                264,
                721,
                300,
                632,
                1090,
                17203,
                645,
                264,
                721,
                300,
                1361,
                294,
                264,
                2863,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09139873530413653,
            "compression_ratio": 1.7538461538461538,
            "no_speech_prob": 0.48989832401275635
        },
        {
            "id": 462,
            "seek": 277390,
            "start": 2789.9,
            "end": 2793.9,
            "text": " That's just the assumption that we make when defining our reward structure.",
            "tokens": [
                51164,
                663,
                311,
                445,
                264,
                15302,
                300,
                321,
                652,
                562,
                17827,
                527,
                7782,
                3877,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09139873530413653,
            "compression_ratio": 1.7538461538461538,
            "no_speech_prob": 0.48989832401275635
        },
        {
            "id": 463,
            "seek": 279390,
            "start": 2793.9,
            "end": 2805.9,
            "text": " Now, we can plug this into the loss of gradient descent algorithm to train our neural network when we see this policy gradient algorithm, which you can see highlighted here.",
            "tokens": [
                50364,
                823,
                11,
                321,
                393,
                5452,
                341,
                666,
                264,
                4470,
                295,
                16235,
                23475,
                9284,
                281,
                3847,
                527,
                18161,
                3209,
                562,
                321,
                536,
                341,
                3897,
                16235,
                9284,
                11,
                597,
                291,
                393,
                536,
                17173,
                510,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08005667466383715,
            "compression_ratio": 1.6577540106951871,
            "no_speech_prob": 0.16366569697856903
        },
        {
            "id": 464,
            "seek": 279390,
            "start": 2805.9,
            "end": 2814.9,
            "text": " This gradient is exactly of the policy part of the neural network. That's the probability of selecting an action given a specific state.",
            "tokens": [
                50964,
                639,
                16235,
                307,
                2293,
                295,
                264,
                3897,
                644,
                295,
                264,
                18161,
                3209,
                13,
                663,
                311,
                264,
                8482,
                295,
                18182,
                364,
                3069,
                2212,
                257,
                2685,
                1785,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08005667466383715,
            "compression_ratio": 1.6577540106951871,
            "no_speech_prob": 0.16366569697856903
        },
        {
            "id": 465,
            "seek": 281490,
            "start": 2814.9,
            "end": 2828.9,
            "text": " And if you remember before when we defined, what does it mean to be a policy function? That's exactly what it means, right? Given a particular state that you find yourself in, what is the probability of selecting a particular action with the highest likelihood?",
            "tokens": [
                50364,
                400,
                498,
                291,
                1604,
                949,
                562,
                321,
                7642,
                11,
                437,
                775,
                309,
                914,
                281,
                312,
                257,
                3897,
                2445,
                30,
                663,
                311,
                2293,
                437,
                309,
                1355,
                11,
                558,
                30,
                18600,
                257,
                1729,
                1785,
                300,
                291,
                915,
                1803,
                294,
                11,
                437,
                307,
                264,
                8482,
                295,
                18182,
                257,
                1729,
                3069,
                365,
                264,
                6343,
                22119,
                30,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10370553897905953,
            "compression_ratio": 1.6531531531531531,
            "no_speech_prob": 0.3690614700317383
        },
        {
            "id": 466,
            "seek": 281490,
            "start": 2828.9,
            "end": 2837.9,
            "text": " And that's exactly where this method gets its name from this policy gradient piece that you can see here.",
            "tokens": [
                51064,
                400,
                300,
                311,
                2293,
                689,
                341,
                3170,
                2170,
                1080,
                1315,
                490,
                341,
                3897,
                16235,
                2522,
                300,
                291,
                393,
                536,
                510,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10370553897905953,
            "compression_ratio": 1.6531531531531531,
            "no_speech_prob": 0.3690614700317383
        },
        {
            "id": 467,
            "seek": 283790,
            "start": 2837.9,
            "end": 2854.9,
            "text": " Now, I want to take maybe just a very brief second towards the end of the class here just to talk about some of the challenges and keep you in line with the first lecture today, some of the challenges of deploying these types of algorithms in the context of the real world, right?",
            "tokens": [
                50364,
                823,
                11,
                286,
                528,
                281,
                747,
                1310,
                445,
                257,
                588,
                5353,
                1150,
                3030,
                264,
                917,
                295,
                264,
                1508,
                510,
                445,
                281,
                751,
                466,
                512,
                295,
                264,
                4759,
                293,
                1066,
                291,
                294,
                1622,
                365,
                264,
                700,
                7991,
                965,
                11,
                512,
                295,
                264,
                4759,
                295,
                34198,
                613,
                3467,
                295,
                14642,
                294,
                264,
                4319,
                295,
                264,
                957,
                1002,
                11,
                558,
                30,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07399088336575416,
            "compression_ratio": 1.6184971098265897,
            "no_speech_prob": 0.16579583287239075
        },
        {
            "id": 468,
            "seek": 285490,
            "start": 2854.9,
            "end": 2872.9,
            "text": " What do you think when you look at this training algorithm that you can see here, right? What do you think are the shortcomings of this training algorithm? And which step, I guess specifically, if we wanted to deploy this approach into reality?",
            "tokens": [
                50364,
                708,
                360,
                291,
                519,
                562,
                291,
                574,
                412,
                341,
                3097,
                9284,
                300,
                291,
                393,
                536,
                510,
                11,
                558,
                30,
                708,
                360,
                291,
                519,
                366,
                264,
                2099,
                49886,
                295,
                341,
                3097,
                9284,
                30,
                400,
                597,
                1823,
                11,
                286,
                2041,
                4682,
                11,
                498,
                321,
                1415,
                281,
                7274,
                341,
                3109,
                666,
                4103,
                30,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1162085974657977,
            "compression_ratio": 1.5741935483870968,
            "no_speech_prob": 0.17492082715034485
        },
        {
            "id": 469,
            "seek": 287290,
            "start": 2872.9,
            "end": 2886.9,
            "text": " Yeah, exactly. So it's step two, right? If you wanted to do this in reality, right? That essentially means that you want to go out, collect your car, crashing it a bunch of times just to learn how to not crash it.",
            "tokens": [
                50364,
                865,
                11,
                2293,
                13,
                407,
                309,
                311,
                1823,
                732,
                11,
                558,
                30,
                759,
                291,
                1415,
                281,
                360,
                341,
                294,
                4103,
                11,
                558,
                30,
                663,
                4476,
                1355,
                300,
                291,
                528,
                281,
                352,
                484,
                11,
                2500,
                428,
                1032,
                11,
                26900,
                309,
                257,
                3840,
                295,
                1413,
                445,
                281,
                1466,
                577,
                281,
                406,
                8252,
                309,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09538799327808423,
            "compression_ratio": 1.5794392523364487,
            "no_speech_prob": 0.49035516381263733
        },
        {
            "id": 470,
            "seek": 287290,
            "start": 2886.9,
            "end": 2893.9,
            "text": " Right? And that's, you know, that's simply not feasible, right? Number one, it's also, you know, very dangerous. Number two.",
            "tokens": [
                51064,
                1779,
                30,
                400,
                300,
                311,
                11,
                291,
                458,
                11,
                300,
                311,
                2935,
                406,
                26648,
                11,
                558,
                30,
                5118,
                472,
                11,
                309,
                311,
                611,
                11,
                291,
                458,
                11,
                588,
                5795,
                13,
                5118,
                732,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09538799327808423,
            "compression_ratio": 1.5794392523364487,
            "no_speech_prob": 0.49035516381263733
        },
        {
            "id": 471,
            "seek": 289390,
            "start": 2893.9,
            "end": 2904.9,
            "text": " So there are ways around this, right? The number one way around this is that people try to train these types of models in simulation, right?",
            "tokens": [
                50364,
                407,
                456,
                366,
                2098,
                926,
                341,
                11,
                558,
                30,
                440,
                1230,
                472,
                636,
                926,
                341,
                307,
                300,
                561,
                853,
                281,
                3847,
                613,
                3467,
                295,
                5245,
                294,
                16575,
                11,
                558,
                30,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10766079782069414,
            "compression_ratio": 1.648068669527897,
            "no_speech_prob": 0.20639684796333313
        },
        {
            "id": 472,
            "seek": 289390,
            "start": 2904.9,
            "end": 2916.9,
            "text": " Simulation is very safe because, you know, we're not going to actually be damaging anything real. It's still very inefficient because we have to run these algorithms a bunch of times and crash them a bunch of times just learn how not to crash.",
            "tokens": [
                50914,
                3998,
                2776,
                307,
                588,
                3273,
                570,
                11,
                291,
                458,
                11,
                321,
                434,
                406,
                516,
                281,
                767,
                312,
                25342,
                1340,
                957,
                13,
                467,
                311,
                920,
                588,
                43495,
                570,
                321,
                362,
                281,
                1190,
                613,
                14642,
                257,
                3840,
                295,
                1413,
                293,
                8252,
                552,
                257,
                3840,
                295,
                1413,
                445,
                1466,
                577,
                406,
                281,
                8252,
                13,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10766079782069414,
            "compression_ratio": 1.648068669527897,
            "no_speech_prob": 0.20639684796333313
        },
        {
            "id": 473,
            "seek": 291690,
            "start": 2916.9,
            "end": 2936.9,
            "text": " But at least now, at least from a safety point of view, it's much safer. But, you know, the problem is that modern simulation engines for reinforcement learning and generally very broadly speaking, modern simulators for vision specifically do not at all capture reality very accurately.",
            "tokens": [
                50364,
                583,
                412,
                1935,
                586,
                11,
                412,
                1935,
                490,
                257,
                4514,
                935,
                295,
                1910,
                11,
                309,
                311,
                709,
                15856,
                13,
                583,
                11,
                291,
                458,
                11,
                264,
                1154,
                307,
                300,
                4363,
                16575,
                12982,
                337,
                29280,
                2539,
                293,
                5101,
                588,
                19511,
                4124,
                11,
                4363,
                1034,
                39265,
                337,
                5201,
                4682,
                360,
                406,
                412,
                439,
                7983,
                4103,
                588,
                20095,
                13,
                51364
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09746894998065496,
            "compression_ratio": 1.5714285714285714,
            "no_speech_prob": 0.22496335208415985
        },
        {
            "id": 474,
            "seek": 293690,
            "start": 2936.9,
            "end": 2953.9,
            "text": " In fact, there's a very famous notion called the sim-to-real gap, which is a gap that exists when you train algorithms in simulation, and they don't extend to a lot of the phenomena that we see and the patterns that we see in reality.",
            "tokens": [
                50364,
                682,
                1186,
                11,
                456,
                311,
                257,
                588,
                4618,
                10710,
                1219,
                264,
                1034,
                12,
                1353,
                12,
                9342,
                7417,
                11,
                597,
                307,
                257,
                7417,
                300,
                8198,
                562,
                291,
                3847,
                14642,
                294,
                16575,
                11,
                293,
                436,
                500,
                380,
                10101,
                281,
                257,
                688,
                295,
                264,
                22004,
                300,
                321,
                536,
                293,
                264,
                8294,
                300,
                321,
                536,
                294,
                4103,
                13,
                51214
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07709572487270709,
            "compression_ratio": 1.716,
            "no_speech_prob": 0.2470398098230362
        },
        {
            "id": 475,
            "seek": 293690,
            "start": 2953.9,
            "end": 2962.9,
            "text": " And one really cool result that I want to just highlight here is that when we're training reinforcement learning algorithms, we ultimately want them to be, you know, not operating in simulation.",
            "tokens": [
                51214,
                400,
                472,
                534,
                1627,
                1874,
                300,
                286,
                528,
                281,
                445,
                5078,
                510,
                307,
                300,
                562,
                321,
                434,
                3097,
                29280,
                2539,
                14642,
                11,
                321,
                6284,
                528,
                552,
                281,
                312,
                11,
                291,
                458,
                11,
                406,
                7447,
                294,
                16575,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07709572487270709,
            "compression_ratio": 1.716,
            "no_speech_prob": 0.2470398098230362
        },
        {
            "id": 476,
            "seek": 296290,
            "start": 2962.9,
            "end": 2984.9,
            "text": " And we want them to be in reality. And as part of our lab here at MIT, we've been developing this very, very cool brand new photorealistic simulation engine that goes beyond basically the paradigm of how simulators work today, which is basically defining a model of their environment and trying to, you know, synthesize that model.",
            "tokens": [
                50364,
                400,
                321,
                528,
                552,
                281,
                312,
                294,
                4103,
                13,
                400,
                382,
                644,
                295,
                527,
                2715,
                510,
                412,
                13100,
                11,
                321,
                600,
                668,
                6416,
                341,
                588,
                11,
                588,
                1627,
                3360,
                777,
                2409,
                418,
                304,
                3142,
                16575,
                2848,
                300,
                1709,
                4399,
                1936,
                264,
                24709,
                295,
                577,
                1034,
                39265,
                589,
                965,
                11,
                597,
                307,
                1936,
                17827,
                257,
                2316,
                295,
                641,
                2823,
                293,
                1382,
                281,
                11,
                291,
                458,
                11,
                26617,
                1125,
                300,
                2316,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12226597038475243,
            "compression_ratio": 1.5253456221198156,
            "no_speech_prob": 0.09647772461175919
        },
        {
            "id": 477,
            "seek": 298490,
            "start": 2984.9,
            "end": 3002.9,
            "text": " These simulators are like glorified game engines, right? They all look very game-like when you look at them. But one thing that we've done is taken a data-driven approach using real data of the real world, can we build up synthetic environments that are super photorealistic and look like this?",
            "tokens": [
                50364,
                1981,
                1034,
                39265,
                366,
                411,
                26623,
                2587,
                1216,
                12982,
                11,
                558,
                30,
                814,
                439,
                574,
                588,
                1216,
                12,
                4092,
                562,
                291,
                574,
                412,
                552,
                13,
                583,
                472,
                551,
                300,
                321,
                600,
                1096,
                307,
                2726,
                257,
                1412,
                12,
                25456,
                3109,
                1228,
                957,
                1412,
                295,
                264,
                957,
                1002,
                11,
                393,
                321,
                1322,
                493,
                23420,
                12388,
                300,
                366,
                1687,
                2409,
                418,
                304,
                3142,
                293,
                574,
                411,
                341,
                30,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1043592121290124,
            "compression_ratio": 1.5076923076923077,
            "no_speech_prob": 0.21154305338859558
        },
        {
            "id": 478,
            "seek": 300290,
            "start": 3002.9,
            "end": 3017.9,
            "text": " So this is a cool result that we created here at MIT, developing this photorealistic simulation engine. This is actually an autonomous agent, not a real car, driving through our virtual simulator in a bunch of different types of different scenarios.",
            "tokens": [
                50364,
                407,
                341,
                307,
                257,
                1627,
                1874,
                300,
                321,
                2942,
                510,
                412,
                13100,
                11,
                6416,
                341,
                2409,
                418,
                304,
                3142,
                16575,
                2848,
                13,
                639,
                307,
                767,
                364,
                23797,
                9461,
                11,
                406,
                257,
                957,
                1032,
                11,
                4840,
                807,
                527,
                6374,
                32974,
                294,
                257,
                3840,
                295,
                819,
                3467,
                295,
                819,
                15077,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06870375098762932,
            "compression_ratio": 1.6916666666666667,
            "no_speech_prob": 0.2142249494791031
        },
        {
            "id": 479,
            "seek": 300290,
            "start": 3017.9,
            "end": 3026.9,
            "text": " So this simulator is called Vista. It allows us to basically use real data that we do collect in the real world, but then re-simulate those same real roads.",
            "tokens": [
                51114,
                407,
                341,
                32974,
                307,
                1219,
                691,
                5236,
                13,
                467,
                4045,
                505,
                281,
                1936,
                764,
                957,
                1412,
                300,
                321,
                360,
                2500,
                294,
                264,
                957,
                1002,
                11,
                457,
                550,
                319,
                12,
                30937,
                5256,
                729,
                912,
                957,
                11344,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.06870375098762932,
            "compression_ratio": 1.6916666666666667,
            "no_speech_prob": 0.2142249494791031
        }
    ],
    [
        {
            "id": 480,
            "seek": 302690,
            "start": 3026.9,
            "end": 3047.9,
            "text": " So for example, let's say you take your car, you drive out on Massab, you collect data of Massab, you can now drop a virtual agent into that same simulated environment observing new viewpoints of what that scene might have looked like from different types of perturbations or types of angles that it might be exposed to.",
            "tokens": [
                50364,
                407,
                337,
                1365,
                11,
                718,
                311,
                584,
                291,
                747,
                428,
                1032,
                11,
                291,
                3332,
                484,
                322,
                10482,
                455,
                11,
                291,
                2500,
                1412,
                295,
                10482,
                455,
                11,
                291,
                393,
                586,
                3270,
                257,
                6374,
                9461,
                666,
                300,
                912,
                41713,
                2823,
                22107,
                777,
                1910,
                20552,
                295,
                437,
                300,
                4145,
                1062,
                362,
                2956,
                411,
                490,
                819,
                3467,
                295,
                40468,
                763,
                420,
                3467,
                295,
                14708,
                300,
                309,
                1062,
                312,
                9495,
                281,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08549585476727553,
            "compression_ratio": 1.5841584158415842,
            "no_speech_prob": 0.16403928399085999
        },
        {
            "id": 481,
            "seek": 304790,
            "start": 3047.9,
            "end": 3060.9,
            "text": " And that allows us to train these agents now entirely using reinforcement learning, no human labels, but importantly allow them to be transferred into reality because there's no sim to real gap anymore.",
            "tokens": [
                50364,
                400,
                300,
                4045,
                505,
                281,
                3847,
                613,
                12554,
                586,
                7696,
                1228,
                29280,
                2539,
                11,
                572,
                1952,
                16949,
                11,
                457,
                8906,
                2089,
                552,
                281,
                312,
                15809,
                666,
                4103,
                570,
                456,
                311,
                572,
                1034,
                281,
                957,
                7417,
                3602,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08491212725639344,
            "compression_ratio": 1.6540084388185654,
            "no_speech_prob": 0.14176985621452332
        },
        {
            "id": 482,
            "seek": 304790,
            "start": 3060.9,
            "end": 3071.9,
            "text": " So in fact, we did exactly this. We placed agents into our simulator. We trained them using the exact algorithms that you learned about in today's lecture, these policy gradient algorithms.",
            "tokens": [
                51014,
                407,
                294,
                1186,
                11,
                321,
                630,
                2293,
                341,
                13,
                492,
                7074,
                12554,
                666,
                527,
                32974,
                13,
                492,
                8895,
                552,
                1228,
                264,
                1900,
                14642,
                300,
                291,
                3264,
                466,
                294,
                965,
                311,
                7991,
                11,
                613,
                3897,
                16235,
                14642,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08491212725639344,
            "compression_ratio": 1.6540084388185654,
            "no_speech_prob": 0.14176985621452332
        },
        {
            "id": 483,
            "seek": 307190,
            "start": 3071.9,
            "end": 3083.9,
            "text": " And all of the training was done entirely in simulation. Then we took these policies and we deployed them on board our full scale autonomous vehicle. This is now in the real world, no longer in simulation.",
            "tokens": [
                50364,
                400,
                439,
                295,
                264,
                3097,
                390,
                1096,
                7696,
                294,
                16575,
                13,
                1396,
                321,
                1890,
                613,
                7657,
                293,
                321,
                17826,
                552,
                322,
                3150,
                527,
                1577,
                4373,
                23797,
                5864,
                13,
                639,
                307,
                586,
                294,
                264,
                957,
                1002,
                11,
                572,
                2854,
                294,
                16575,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.087162446975708,
            "compression_ratio": 1.7357723577235773,
            "no_speech_prob": 0.340465784072876
        },
        {
            "id": 484,
            "seek": 307190,
            "start": 3083.9,
            "end": 3097.9,
            "text": " And on the left hand side, you can see basically this car driving through this environment completely autonomous in the real world. No transfer learning is done here. There is no augmentation of data from real world data.",
            "tokens": [
                50964,
                400,
                322,
                264,
                1411,
                1011,
                1252,
                11,
                291,
                393,
                536,
                1936,
                341,
                1032,
                4840,
                807,
                341,
                2823,
                2584,
                23797,
                294,
                264,
                957,
                1002,
                13,
                883,
                5003,
                2539,
                307,
                1096,
                510,
                13,
                821,
                307,
                572,
                14501,
                19631,
                295,
                1412,
                490,
                957,
                1002,
                1412,
                13,
                51664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.087162446975708,
            "compression_ratio": 1.7357723577235773,
            "no_speech_prob": 0.340465784072876
        },
        {
            "id": 485,
            "seek": 309790,
            "start": 3097.9,
            "end": 3109.9,
            "text": " This is entirely trained using simulation and this represented actually the first time ever that reinforcement learning was used to train a policy end to end for an autonomous vehicle that could be deployed in reality.",
            "tokens": [
                50364,
                639,
                307,
                7696,
                8895,
                1228,
                16575,
                293,
                341,
                10379,
                767,
                264,
                700,
                565,
                1562,
                300,
                29280,
                2539,
                390,
                1143,
                281,
                3847,
                257,
                3897,
                917,
                281,
                917,
                337,
                364,
                23797,
                5864,
                300,
                727,
                312,
                17826,
                294,
                4103,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08741043372587724,
            "compression_ratio": 1.748091603053435,
            "no_speech_prob": 0.06535213440656662
        },
        {
            "id": 486,
            "seek": 309790,
            "start": 3109.9,
            "end": 3125.9,
            "text": " So that was something really cool that we created here at MIT. But now that we covered all of this foundations of reinforcement learning and policy learning, I want to touch on some other maybe very exciting applications that we're seeing.",
            "tokens": [
                50964,
                407,
                300,
                390,
                746,
                534,
                1627,
                300,
                321,
                2942,
                510,
                412,
                13100,
                13,
                583,
                586,
                300,
                321,
                5343,
                439,
                295,
                341,
                22467,
                295,
                29280,
                2539,
                293,
                3897,
                2539,
                11,
                286,
                528,
                281,
                2557,
                322,
                512,
                661,
                1310,
                588,
                4670,
                5821,
                300,
                321,
                434,
                2577,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08741043372587724,
            "compression_ratio": 1.748091603053435,
            "no_speech_prob": 0.06535213440656662
        },
        {
            "id": 487,
            "seek": 312590,
            "start": 3125.9,
            "end": 3141.9,
            "text": " And one very popular application that a lot of people will tell you about and talk about is the game of go. So here reinforcement learning agents could be actually tried to put against the test against, you know, grand master level go players.",
            "tokens": [
                50364,
                400,
                472,
                588,
                3743,
                3861,
                300,
                257,
                688,
                295,
                561,
                486,
                980,
                291,
                466,
                293,
                751,
                466,
                307,
                264,
                1216,
                295,
                352,
                13,
                407,
                510,
                29280,
                2539,
                12554,
                727,
                312,
                767,
                3031,
                281,
                829,
                1970,
                264,
                1500,
                1970,
                11,
                291,
                458,
                11,
                2697,
                4505,
                1496,
                352,
                4150,
                13,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11542437626765324,
            "compression_ratio": 1.4727272727272727,
            "no_speech_prob": 0.013184850104153156
        },
        {
            "id": 488,
            "seek": 314190,
            "start": 3141.9,
            "end": 3152.9,
            "text": " And you know, at the time, achieved incredibly impressive results. So for those of you who are not familiar with the game of go, the game of go is played on a 19 by 19 board.",
            "tokens": [
                50364,
                400,
                291,
                458,
                11,
                412,
                264,
                565,
                11,
                11042,
                6252,
                8992,
                3542,
                13,
                407,
                337,
                729,
                295,
                291,
                567,
                366,
                406,
                4963,
                365,
                264,
                1216,
                295,
                352,
                11,
                264,
                1216,
                295,
                352,
                307,
                3737,
                322,
                257,
                1294,
                538,
                1294,
                3150,
                13,
                50914
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14013740149411288,
            "compression_ratio": 1.646788990825688,
            "no_speech_prob": 0.6483667492866516
        },
        {
            "id": 489,
            "seek": 314190,
            "start": 3152.9,
            "end": 3165.9,
            "text": " The rough objective of go is to claim basically more board pieces than your opponent, right. And through the grid of, sorry, through the grid that you can see here, this 19 by 19 grid.",
            "tokens": [
                50914,
                440,
                5903,
                10024,
                295,
                352,
                307,
                281,
                3932,
                1936,
                544,
                3150,
                3755,
                813,
                428,
                10620,
                11,
                558,
                13,
                400,
                807,
                264,
                10748,
                295,
                11,
                2597,
                11,
                807,
                264,
                10748,
                300,
                291,
                393,
                536,
                510,
                11,
                341,
                1294,
                538,
                1294,
                10748,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14013740149411288,
            "compression_ratio": 1.646788990825688,
            "no_speech_prob": 0.6483667492866516
        },
        {
            "id": 490,
            "seek": 316590,
            "start": 3165.9,
            "end": 3179.9,
            "text": " And while the game itself, the logical rules are actually quite simple, the number of possible action spaces and possible states that this board could be placed into is greater than the number of atoms in the universe.",
            "tokens": [
                50364,
                400,
                1339,
                264,
                1216,
                2564,
                11,
                264,
                14978,
                4474,
                366,
                767,
                1596,
                2199,
                11,
                264,
                1230,
                295,
                1944,
                3069,
                7673,
                293,
                1944,
                4368,
                300,
                341,
                3150,
                727,
                312,
                7074,
                666,
                307,
                5044,
                813,
                264,
                1230,
                295,
                16871,
                294,
                264,
                6445,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.09930969874064127,
            "compression_ratio": 1.5244755244755244,
            "no_speech_prob": 0.07793634384870529
        },
        {
            "id": 491,
            "seek": 317990,
            "start": 3179.9,
            "end": 3191.9,
            "text": " So this game, even though the rules are very simple in their logical definitions, is an extraordinarily complex game for an artificial algorithm to try and master.",
            "tokens": [
                50364,
                407,
                341,
                1216,
                11,
                754,
                1673,
                264,
                4474,
                366,
                588,
                2199,
                294,
                641,
                14978,
                21988,
                11,
                307,
                364,
                34557,
                3997,
                1216,
                337,
                364,
                11677,
                9284,
                281,
                853,
                293,
                4505,
                13,
                50964
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0846692215312611,
            "compression_ratio": 1.6761133603238867,
            "no_speech_prob": 0.5061125159263611
        },
        {
            "id": 492,
            "seek": 317990,
            "start": 3191.9,
            "end": 3206.9,
            "text": " So the objective here was to build a reinforcement learning algorithm to master the game of go, not only beating, you know, these gold standard softwares, but also what was at the time like an amazing result was to beat the grand master level player.",
            "tokens": [
                50964,
                407,
                264,
                10024,
                510,
                390,
                281,
                1322,
                257,
                29280,
                2539,
                9284,
                281,
                4505,
                264,
                1216,
                295,
                352,
                11,
                406,
                787,
                13497,
                11,
                291,
                458,
                11,
                613,
                3821,
                3832,
                2787,
                4151,
                495,
                11,
                457,
                611,
                437,
                390,
                412,
                264,
                565,
                411,
                364,
                2243,
                1874,
                390,
                281,
                4224,
                264,
                2697,
                4505,
                1496,
                4256,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.0846692215312611,
            "compression_ratio": 1.6761133603238867,
            "no_speech_prob": 0.5061125159263611
        },
        {
            "id": 493,
            "seek": 320690,
            "start": 3206.9,
            "end": 3212.9,
            "text": " So the number one player in the world of go was a human, the human champion, obviously.",
            "tokens": [
                50364,
                407,
                264,
                1230,
                472,
                4256,
                294,
                264,
                1002,
                295,
                352,
                390,
                257,
                1952,
                11,
                264,
                1952,
                10971,
                11,
                2745,
                13,
                50664
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10396744484125181,
            "compression_ratio": 1.6144578313253013,
            "no_speech_prob": 0.21128515899181366
        },
        {
            "id": 494,
            "seek": 320690,
            "start": 3212.9,
            "end": 3234.9,
            "text": " So Google deep mind rose to this challenge. They created a couple years ago, developing this solution, which is very much based in the exact same algorithms that you learned about in today's lecture, combining both the value part of this network with residual layers, which will cover in the next lecture tomorrow.",
            "tokens": [
                50664,
                407,
                3329,
                2452,
                1575,
                10895,
                281,
                341,
                3430,
                13,
                814,
                2942,
                257,
                1916,
                924,
                2057,
                11,
                6416,
                341,
                3827,
                11,
                597,
                307,
                588,
                709,
                2361,
                294,
                264,
                1900,
                912,
                14642,
                300,
                291,
                3264,
                466,
                294,
                965,
                311,
                7991,
                11,
                21928,
                1293,
                264,
                2158,
                644,
                295,
                341,
                3209,
                365,
                27980,
                7914,
                11,
                597,
                486,
                2060,
                294,
                264,
                958,
                7991,
                4153,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.10396744484125181,
            "compression_ratio": 1.6144578313253013,
            "no_speech_prob": 0.21128515899181366
        },
        {
            "id": 495,
            "seek": 323490,
            "start": 3234.9,
            "end": 3243.9,
            "text": " And using a reinforcement learning pipeline, they were able to defeat the grand champion human players. And the idea that's core was actually very simple.",
            "tokens": [
                50364,
                400,
                1228,
                257,
                29280,
                2539,
                15517,
                11,
                436,
                645,
                1075,
                281,
                11785,
                264,
                2697,
                10971,
                1952,
                4150,
                13,
                400,
                264,
                1558,
                300,
                311,
                4965,
                390,
                767,
                588,
                2199,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1357639661202064,
            "compression_ratio": 1.4186046511627908,
            "no_speech_prob": 0.026694411411881447
        },
        {
            "id": 496,
            "seek": 323490,
            "start": 3243.9,
            "end": 3249.9,
            "text": " The first step is that you train a neural network to basically watch human level experts.",
            "tokens": [
                50814,
                440,
                700,
                1823,
                307,
                300,
                291,
                3847,
                257,
                18161,
                3209,
                281,
                1936,
                1159,
                1952,
                1496,
                8572,
                13,
                51114
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1357639661202064,
            "compression_ratio": 1.4186046511627908,
            "no_speech_prob": 0.026694411411881447
        },
        {
            "id": 497,
            "seek": 324990,
            "start": 3249.9,
            "end": 3256.9,
            "text": " So this is not using reinforcement learning is using supervised learning using the techniques that we covered in lectures one, two, and three.",
            "tokens": [
                50364,
                407,
                341,
                307,
                406,
                1228,
                29280,
                2539,
                307,
                1228,
                46533,
                2539,
                1228,
                264,
                7512,
                300,
                321,
                5343,
                294,
                16564,
                472,
                11,
                732,
                11,
                293,
                1045,
                13,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11668689162642867,
            "compression_ratio": 1.6798245614035088,
            "no_speech_prob": 0.6417977809906006
        },
        {
            "id": 498,
            "seek": 324990,
            "start": 3256.9,
            "end": 3270.9,
            "text": " And from this first step, the goal is to build like a policy that would imitate some of the rough patterns that a human type of player or human grand master would take based on given board state, the type of actions that they might execute.",
            "tokens": [
                50714,
                400,
                490,
                341,
                700,
                1823,
                11,
                264,
                3387,
                307,
                281,
                1322,
                411,
                257,
                3897,
                300,
                576,
                35556,
                512,
                295,
                264,
                5903,
                8294,
                300,
                257,
                1952,
                2010,
                295,
                4256,
                420,
                1952,
                2697,
                4505,
                576,
                747,
                2361,
                322,
                2212,
                3150,
                1785,
                11,
                264,
                2010,
                295,
                5909,
                300,
                436,
                1062,
                14483,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11668689162642867,
            "compression_ratio": 1.6798245614035088,
            "no_speech_prob": 0.6417977809906006
        },
        {
            "id": 499,
            "seek": 327090,
            "start": 3270.9,
            "end": 3284.9,
            "text": " But then given this pre trained model, essentially, you could use it to bootstrap in reinforcement learning algorithm that would play against itself in order to learn how to improve even beyond the human levels.",
            "tokens": [
                50364,
                583,
                550,
                2212,
                341,
                659,
                8895,
                2316,
                11,
                4476,
                11,
                291,
                727,
                764,
                309,
                281,
                11450,
                372,
                4007,
                294,
                29280,
                2539,
                9284,
                300,
                576,
                862,
                1970,
                2564,
                294,
                1668,
                281,
                1466,
                577,
                281,
                3470,
                754,
                4399,
                264,
                1952,
                4358,
                13,
                51064
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12063430656086314,
            "compression_ratio": 1.4161073825503356,
            "no_speech_prob": 0.500576913356781
        },
        {
            "id": 500,
            "seek": 328490,
            "start": 3284.9,
            "end": 3297.9,
            "text": " So it would take its human understandings, try to imitate the humans first of all, but then from that imitation, they would pin these two neural networks against themselves, play a game against themselves, and the winners would be receiving a reward.",
            "tokens": [
                50364,
                407,
                309,
                576,
                747,
                1080,
                1952,
                1223,
                1109,
                11,
                853,
                281,
                35556,
                264,
                6255,
                700,
                295,
                439,
                11,
                457,
                550,
                490,
                300,
                47624,
                11,
                436,
                576,
                5447,
                613,
                732,
                18161,
                9590,
                1970,
                2969,
                11,
                862,
                257,
                1216,
                1970,
                2969,
                11,
                293,
                264,
                17193,
                576,
                312,
                10040,
                257,
                7782,
                13,
                51014
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08903302296553509,
            "compression_ratio": 1.874074074074074,
            "no_speech_prob": 0.7927569150924683
        },
        {
            "id": 501,
            "seek": 328490,
            "start": 3297.9,
            "end": 3312.9,
            "text": " The losers would try to negate all of the actions that they may have acquired from their human counterparts and try to actually learn new types of rules and new types of actions basically that might be very beneficial to achieving super human performance.",
            "tokens": [
                51014,
                440,
                37713,
                576,
                853,
                281,
                2485,
                473,
                439,
                295,
                264,
                5909,
                300,
                436,
                815,
                362,
                17554,
                490,
                641,
                1952,
                33287,
                293,
                853,
                281,
                767,
                1466,
                777,
                3467,
                295,
                4474,
                293,
                777,
                3467,
                295,
                5909,
                1936,
                300,
                1062,
                312,
                588,
                14072,
                281,
                19626,
                1687,
                1952,
                3389,
                13,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08903302296553509,
            "compression_ratio": 1.874074074074074,
            "no_speech_prob": 0.7927569150924683
        },
        {
            "id": 502,
            "seek": 331290,
            "start": 3312.9,
            "end": 3336.9,
            "text": " And one of the very important auxiliary tricks that brought this idea to be possible was the usage of this second network, this auxiliary network, which took as input the state of the board and tried to predict, you know, what are all of the different possible board states that might emerge from this particular state, and what would their values be?",
            "tokens": [
                50364,
                400,
                472,
                295,
                264,
                588,
                1021,
                43741,
                11733,
                300,
                3038,
                341,
                1558,
                281,
                312,
                1944,
                390,
                264,
                14924,
                295,
                341,
                1150,
                3209,
                11,
                341,
                43741,
                3209,
                11,
                597,
                1890,
                382,
                4846,
                264,
                1785,
                295,
                264,
                3150,
                293,
                3031,
                281,
                6069,
                11,
                291,
                458,
                11,
                437,
                366,
                439,
                295,
                264,
                819,
                1944,
                3150,
                4368,
                300,
                1062,
                21511,
                490,
                341,
                1729,
                1785,
                11,
                293,
                437,
                576,
                641,
                4190,
                312,
                30,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07703943385018243,
            "compression_ratio": 1.7205882352941178,
            "no_speech_prob": 0.057373955845832825
        },
        {
            "id": 503,
            "seek": 333690,
            "start": 3336.9,
            "end": 3343.9,
            "text": " What would their potential returns and their outcomes be? So this network was an auxiliary network that was almost hallucinating, right?",
            "tokens": [
                50364,
                708,
                576,
                641,
                3995,
                11247,
                293,
                641,
                10070,
                312,
                30,
                407,
                341,
                3209,
                390,
                364,
                43741,
                3209,
                300,
                390,
                1920,
                35212,
                8205,
                11,
                558,
                30,
                50714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08110788785494291,
            "compression_ratio": 1.5588235294117647,
            "no_speech_prob": 0.31225141882896423
        },
        {
            "id": 504,
            "seek": 333690,
            "start": 3343.9,
            "end": 3355.9,
            "text": " Different board states that it could take from this particular state and using those predicted values to guide its planning of, you know, what action should it take into the future.",
            "tokens": [
                50714,
                20825,
                3150,
                4368,
                300,
                309,
                727,
                747,
                490,
                341,
                1729,
                1785,
                293,
                1228,
                729,
                19147,
                4190,
                281,
                5934,
                1080,
                5038,
                295,
                11,
                291,
                458,
                11,
                437,
                3069,
                820,
                309,
                747,
                666,
                264,
                2027,
                13,
                51314
            ],
            "temperature": 0.0,
            "avg_logprob": -0.08110788785494291,
            "compression_ratio": 1.5588235294117647,
            "no_speech_prob": 0.31225141882896423
        },
        {
            "id": 505,
            "seek": 335590,
            "start": 3355.9,
            "end": 3365.9,
            "text": " And finally, very much more recently, they extended this algorithm and showed that they could not even use the human grandmasters in the beginning to imitate from in the beginning and bootstrapped these algorithms.",
            "tokens": [
                50364,
                400,
                2721,
                11,
                588,
                709,
                544,
                3938,
                11,
                436,
                10913,
                341,
                9284,
                293,
                4712,
                300,
                436,
                727,
                406,
                754,
                764,
                264,
                1952,
                2697,
                3799,
                1559,
                294,
                264,
                2863,
                281,
                35556,
                490,
                294,
                264,
                2863,
                293,
                11450,
                19639,
                3320,
                613,
                14642,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11299948090488471,
            "compression_ratio": 1.8076923076923077,
            "no_speech_prob": 0.22100745141506195
        },
        {
            "id": 506,
            "seek": 335590,
            "start": 3365.9,
            "end": 3383.9,
            "text": " What if they just started entirely from scratch and just had two neural networks never trained before they start pinning themselves against each other, and you could actually see that you could, without any human supervision at all, have a neural network, learn to not only outperform the solution that",
            "tokens": [
                50864,
                708,
                498,
                436,
                445,
                1409,
                7696,
                490,
                8459,
                293,
                445,
                632,
                732,
                18161,
                9590,
                1128,
                8895,
                949,
                436,
                722,
                5447,
                773,
                2969,
                1970,
                1184,
                661,
                11,
                293,
                291,
                727,
                767,
                536,
                300,
                291,
                727,
                11,
                1553,
                604,
                1952,
                32675,
                412,
                439,
                11,
                362,
                257,
                18161,
                3209,
                11,
                1466,
                281,
                406,
                787,
                484,
                26765,
                264,
                3827,
                300,
                51764
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11299948090488471,
            "compression_ratio": 1.8076923076923077,
            "no_speech_prob": 0.22100745141506195
        },
        {
            "id": 507,
            "seek": 338390,
            "start": 3383.9,
            "end": 3393.9,
            "text": " or outperform the humans, but also outperform the solution that was created, which was bootstrapped by humans as well.",
            "tokens": [
                50364,
                420,
                484,
                26765,
                264,
                6255,
                11,
                457,
                611,
                484,
                26765,
                264,
                3827,
                300,
                390,
                2942,
                11,
                597,
                390,
                11450,
                19639,
                3320,
                538,
                6255,
                382,
                731,
                13,
                50864
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1155273842089104,
            "compression_ratio": 1.5714285714285714,
            "no_speech_prob": 0.022576982155442238
        },
        {
            "id": 508,
            "seek": 338390,
            "start": 3393.9,
            "end": 3404.9,
            "text": " So with that all summarized very quickly what we've learned today and conclude for the day. So we've talked a lot about really the foundational algorithms underlying reinforcement learning.",
            "tokens": [
                50864,
                407,
                365,
                300,
                439,
                14611,
                1602,
                588,
                2661,
                437,
                321,
                600,
                3264,
                965,
                293,
                16886,
                337,
                264,
                786,
                13,
                407,
                321,
                600,
                2825,
                257,
                688,
                466,
                534,
                264,
                32195,
                14642,
                14217,
                29280,
                2539,
                13,
                51414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1155273842089104,
            "compression_ratio": 1.5714285714285714,
            "no_speech_prob": 0.022576982155442238
        },
        {
            "id": 509,
            "seek": 340490,
            "start": 3404.9,
            "end": 3431.9,
            "text": " We saw two different types of reinforcement learning approaches of how we could optimize these solutions first being Q learning where we're trying to actually estimate given a state, you know, what is the value that we might expect for any possible action in the second way was to take a much more end to end approach and say how given a state that we see ourselves in what is the likelihood that I should take any given action to maximize the potential that I have in this particular state.",
            "tokens": [
                50364,
                492,
                1866,
                732,
                819,
                3467,
                295,
                29280,
                2539,
                11587,
                295,
                577,
                321,
                727,
                19719,
                613,
                6547,
                700,
                885,
                1249,
                2539,
                689,
                321,
                434,
                1382,
                281,
                767,
                12539,
                2212,
                257,
                1785,
                11,
                291,
                458,
                11,
                437,
                307,
                264,
                2158,
                300,
                321,
                1062,
                2066,
                337,
                604,
                1944,
                3069,
                294,
                264,
                1150,
                636,
                390,
                281,
                747,
                257,
                709,
                544,
                917,
                281,
                917,
                3109,
                293,
                584,
                577,
                2212,
                257,
                1785,
                300,
                321,
                536,
                4175,
                294,
                437,
                307,
                264,
                22119,
                300,
                286,
                820,
                747,
                604,
                2212,
                3069,
                281,
                19874,
                264,
                3995,
                300,
                286,
                362,
                294,
                341,
                1729,
                1785,
                13,
                51714
            ],
            "temperature": 0.0,
            "avg_logprob": -0.12371497251549546,
            "compression_ratio": 1.7411347517730495,
            "no_speech_prob": 0.8058342337608337
        }
    ],
    [
        {
            "id": 510,
            "seek": 343190,
            "start": 3431.9,
            "end": 3449.9,
            "text": " And I hope that all of this was very exciting to you today we have a very exciting lab and kick off for the competition and the deadline for these competitions will be well it was originally set to be Thursday, which is tomorrow at 11 p.m. Thank you.",
            "tokens": [
                50364,
                400,
                286,
                1454,
                300,
                439,
                295,
                341,
                390,
                588,
                4670,
                281,
                291,
                965,
                321,
                362,
                257,
                588,
                4670,
                2715,
                293,
                4437,
                766,
                337,
                264,
                6211,
                293,
                264,
                20615,
                337,
                613,
                26185,
                486,
                312,
                731,
                309,
                390,
                7993,
                992,
                281,
                312,
                10383,
                11,
                597,
                307,
                4153,
                412,
                2975,
                280,
                13,
                76,
                13,
                1044,
                291,
                13,
                51264
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1004391302142227,
            "compression_ratio": 1.5060240963855422,
            "no_speech_prob": 0.06652354449033737
        }
    ]
]